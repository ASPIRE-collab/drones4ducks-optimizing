{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of image factors on annotation consensus-- Zooniverse\n",
    "Start date: 09/26/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis annotations\n",
    "path = \"E:\\\\imagefactors\\\\data\\\\consensusLabels_agreementIndex.csv\"\n",
    "with open(path) as f:\n",
    "  df = pd.read_csv(f)\n",
    "\n",
    "#Fixing how bounding boxes are read for the analysis labels\n",
    "def eval_bbox_refined(row):\n",
    "    if pd.notnull(row['consensus_bbox']):\n",
    "        return ast.literal_eval(row['consensus_bbox'])\n",
    "    else:\n",
    "        return None\n",
    "# Apply the function to the 'bbox_refined' column and save the results\n",
    "df['consensus_bbox'] = df.apply(eval_bbox_refined, axis=1)\n",
    "\n",
    "#Creating a base file column to match tiles to full images later\n",
    "df[\"basefile\"] = [x[:-10] for x in df['filename']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IF RESUMING FROM A SAVED POINT\n",
    "path = \"E:/imagefactors/data/crowdsourced_imagefactors.csv\"\n",
    "with open(path) as f:\n",
    "  df = pd.read_csv(f)\n",
    "#Fixing how bounding boxes are read for the analysis labels\n",
    "def eval_bbox_refined(row):\n",
    "    if pd.notnull(row['consensus_bbox']):\n",
    "        return ast.literal_eval(row['consensus_bbox'])\n",
    "    else:\n",
    "        return None\n",
    "# Apply the function to the 'bbox_refined' column and save the results\n",
    "df['consensus_bbox'] = df.apply(eval_bbox_refined, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DERIVE IMAGE/ANNOTATION FACTORS FOR ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BBOX AREA\n",
    "\n",
    "def calc_area(row):\n",
    "    bbox = row['consensus_bbox']\n",
    "    xmin, ymin, w, h = bbox\n",
    "    return w * h\n",
    "\n",
    "df['area'] = df.apply(calc_area, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % AREA BBOX\n",
    "# Percent area of the bounding box of the total image area\n",
    "\n",
    "# Define a function to calculate percentage area\n",
    "def calculate_percentage_area(image_filename, bbox_area):\n",
    "    image_path = os.path.join(\"E:\\\\imagefactors\\\\data\\\\zooniverse\", image_filename)\n",
    "    \n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "    except FileNotFoundError:\n",
    "        # Handle the case where the image is not found\n",
    "        print(f\"Image not found: {image_path}\")\n",
    "        return None  # You can return a special value, such as None, to indicate the image wasn't found\n",
    "    \n",
    "    image_width, image_height = image.size\n",
    "    image_area = image_width * image_height\n",
    "\n",
    "    percentage_area = (bbox_area / image_area) * 100\n",
    "    return percentage_area\n",
    "\n",
    "# Calculate percentage area and add it as a new\n",
    "df['bbox_percent_area'] = df.apply(lambda row: calculate_percentage_area(row['filename'], row['area']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAME CLASS %\n",
    "# % of targets of the same class as the analysis target (in the same image)\n",
    "\n",
    "# Define a function to calculate the percentage of same-class neighbors for a given row\n",
    "def calculate_same_class_percentage(row, df):\n",
    "    # Get the filename and class ID of the target bounding box\n",
    "    filename = row['filename']\n",
    "    class_id = row['consensus_class_ID']\n",
    "    \n",
    "    # Filter the DataFrame to include only rows with matching filenames\n",
    "    matching_rows = df[df['filename'] == filename]\n",
    "    \n",
    "    # Calculate the total number of neighbors in the same image\n",
    "    total_neighbors = len(matching_rows) - 1  # Subtract 1 to exclude the target bounding box\n",
    "    \n",
    "    if total_neighbors == 0:\n",
    "        return 0  # Avoid division by zero\n",
    "    \n",
    "    # Calculate the number of same-class neighbors\n",
    "    same_class_neighbors = len(matching_rows[matching_rows['consensus_class_ID'] == class_id]) - 1  # Subtract 1 to exclude the target bounding box\n",
    "    \n",
    "    # Calculate the percentage of same-class neighbors\n",
    "    same_class_percentage = (same_class_neighbors / total_neighbors) * 100\n",
    "    \n",
    "    return same_class_percentage\n",
    "\n",
    "# Calculate the same-class percentage for each row and add the results as a new column\n",
    "df['same_class_percent'] = df.apply(lambda row: calculate_same_class_percentage(row, df), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUMBER OF NEIGHBORS \n",
    "# Number of annotations within 2x maximum of bbox width or height (to account for positional differences)\n",
    "\n",
    "# Define a function to calculate the number of neighbors for a given row\n",
    "def count_neighbors(row, df):\n",
    "    # Extract 'bbox' values from the 'consensus_bbox' column as a list [xmin, ymin, width, height]\n",
    "    bbox = row['consensus_bbox']  # Use ast.literal_eval() to safely evaluate the string\n",
    "    \n",
    "    # Define the search radius as 2 times the maximum of width and height\n",
    "    search_radius = 2 * max(bbox[2], bbox[3])\n",
    "    \n",
    "    # Calculate the center coordinates of the bounding box\n",
    "    x_center = bbox[0] + bbox[2] / 2\n",
    "    y_center = bbox[1] + bbox[3] / 2\n",
    "    \n",
    "    # Initialize a count for neighbors\n",
    "    num_neighbors = 0\n",
    "    \n",
    "    # Iterate through rows with matching filenames\n",
    "    matching_rows = df[df['filename'] == row['filename']]\n",
    "    \n",
    "    for _, neighbor_row in matching_rows.iterrows():\n",
    "        if neighbor_row.name != row.name:\n",
    "            # Extract 'bbox' values for the neighbor as a list [xmin, ymin, width, height]\n",
    "            neighbor_bbox = neighbor_row['consensus_bbox']\n",
    "            \n",
    "            # Calculate the center coordinates of the potential neighbor\n",
    "            neighbor_x_center = neighbor_bbox[0] + neighbor_bbox[2] / 2\n",
    "            neighbor_y_center = neighbor_bbox[1] + neighbor_bbox[3] / 2\n",
    "            \n",
    "            # Calculate the Euclidean distance between centers\n",
    "            distance = np.sqrt((x_center - neighbor_x_center)**2 + (y_center - neighbor_y_center)**2)\n",
    "            \n",
    "            # Check if the neighbor is within the search radius\n",
    "            if distance <= search_radius:\n",
    "                num_neighbors += 1\n",
    "    \n",
    "    return num_neighbors\n",
    "\n",
    "# Calculate the number of neighbors for each row and add the results as a new column\n",
    "df['num_neighbors'] = df.apply(lambda row: count_neighbors(row, df), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOTAL NUMBER OF BIRDS PER IMAGE\n",
    "df['density'] = df.groupby('filename')['consensus_bbox'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISTANCE OF TARGET FROM IMAGE CENTER-- in meters\n",
    "\n",
    "path1 = \"E:\\\\imagefactors\\\\data\\\\crowdsourced_gsd.csv\"\n",
    "with open(path1) as f1:\n",
    "  gsd_df = pd.read_csv(f1)\n",
    "\n",
    "gsd_df[\"basefile\"] = gsd_df[\"filename\"].apply(lambda x: os.path.splitext(x)[0])\n",
    "\n",
    "merged_df = pd.merge(df, gsd_df, on=\"basefile\", how=\"left\")\n",
    "merged_df = merged_df.rename(columns={\"filename_x\": \"filename\"})\n",
    "merged_df = merged_df.drop(columns=[\"filename_y\", \"filename_base\"])\n",
    "\n",
    "# Function to calculate distance from center\n",
    "def calculate_distance_from_center(row):\n",
    "    image_path = os.path.join(\"E:\\\\imagefactors\\\\data\\\\zooniverse\", row[\"filename\"])\n",
    "    \n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "    except FileNotFoundError:\n",
    "        # Handle the case where the image is not found\n",
    "        print(f\"Image not found: {image_path}\")\n",
    "        return None  # You can return a special value, such as None, to indicate the image wasn't found\n",
    "    \n",
    "    image_width, image_height = image.size\n",
    "    center_x_px = image_width/2 \n",
    "    center_y_px = image_height/2\n",
    "    gsd_m = row['gsd'] / 100\n",
    "\n",
    "    row['center_x_m'] = center_x_px * gsd_m\n",
    "    row['center_y_m'] = center_y_px * gsd_m\n",
    "    \n",
    "    # Get the coordinates of the bounding box (x, y, width, height)\n",
    "    x, y, width, height = row['consensus_bbox']\n",
    "\n",
    "    # Calculate the center point of the bounding box in pixels\n",
    "    bbox_center_x_px = x + (width / 2)\n",
    "    bbox_center_y_px = y + (height / 2)\n",
    "\n",
    "    # Calculate the center point of the bounding box in meters\n",
    "    bbox_center_x_m = bbox_center_x_px * gsd_m\n",
    "    bbox_center_y_m = bbox_center_y_px * gsd_m\n",
    "\n",
    "    # Calculate the distance from the center of the image in meters\n",
    "    distance_m = ((row['center_x_m'] - bbox_center_x_m)**2 + (row['center_y_m'] - bbox_center_y_m)**2)**0.5\n",
    "\n",
    "    return distance_m\n",
    "\n",
    "# Apply the function to the merged dataframe\n",
    "merged_df['distance_from_center'] = merged_df.apply(calculate_distance_from_center, axis=1)\n",
    "df = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Image 'E:\\imagefactors\\data\\zooniverse\\data_train2.txt' not found or cannot be loaded.\n",
      "Warning: Image 'E:\\imagefactors\\data\\zooniverse\\README.txt' not found or cannot be loaded.\n"
     ]
    }
   ],
   "source": [
    "#TEXTURE METRICS- GLCM\n",
    "#Bounding box and \"donut\" (buffer region directly around bbox)\n",
    "\n",
    "def calculate_gclm_derivatives(image, bbox):\n",
    "    # Convert bounding box coordinates to integers\n",
    "    x, y, width, height = map(int, bbox)\n",
    "    \n",
    "    # Extract the region of interest (ROI) from the image using the bounding box\n",
    "    roi = image[y:y+height, x:x+width]\n",
    "    \n",
    "    # Check if the ROI is empty or None\n",
    "    if roi is None or roi.size == 0:\n",
    "        print(\"Warning: ROI is empty or None\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # Convert the ROI to grayscale\n",
    "    roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate GCLM features for the grayscale ROI\n",
    "    distances = [1, 2]  # Define the distances for GCLM\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]  # Define the angles for GCLM\n",
    "    gclm = graycomatrix(roi_gray, distances=distances, angles=angles, levels=256,\n",
    "                        symmetric=True, normed=True)\n",
    "    \n",
    "    # Calculate GCLM derivatives (contrast, dissimilarity, homogeneity, energy)\n",
    "    contrast = graycoprops(gclm, 'contrast').mean()\n",
    "    dissimilarity = graycoprops(gclm, 'dissimilarity').mean()\n",
    "    homogeneity = graycoprops(gclm, 'homogeneity').mean()\n",
    "    energy = graycoprops(gclm, 'energy').mean()\n",
    "    \n",
    "    return contrast, dissimilarity, homogeneity, energy\n",
    "\n",
    "def adjust_bbox_to_image(image, bbox):\n",
    "    # Get image dimensions\n",
    "    image_height, image_width, _ = image.shape\n",
    "    \n",
    "    # Adjust bounding box coordinates if they exceed image boundaries\n",
    "    x, y, width, height = bbox\n",
    "    \n",
    "    # Ensure the bounding box does not go beyond the image boundaries\n",
    "    x = max(x, 0)\n",
    "    y = max(y, 0)\n",
    "    width = min(width, image_width - x)\n",
    "    height = min(height, image_height - y)\n",
    "    \n",
    "    return x, y, width, height\n",
    "\n",
    "def calculate_texture_metrics_for_directory(image_dir, csv_file):\n",
    "    # Initialize an empty dataframe to store the texture metrics\n",
    "    texture_metrics_df = pd.DataFrame()\n",
    "    \n",
    "    # List all files in the specified directory\n",
    "    image_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        try:\n",
    "            # Construct the full path to the image file\n",
    "            image_path = os.path.join(image_dir, image_file)\n",
    "            \n",
    "            # Load the image\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            if image is None:\n",
    "                print(f\"Warning: Image '{image_path}' not found or cannot be loaded.\")\n",
    "                continue\n",
    "            \n",
    "            # Read the CSV file\n",
    "            csv_data = pd.read_csv(csv_file)\n",
    "            \n",
    "            # Find the corresponding image filename\n",
    "            image_filename = os.path.basename(image_path)\n",
    "            \n",
    "            # Filter annotations based on the image filename\n",
    "            annotations = csv_data[csv_data['filename'] == image_filename]\n",
    "            \n",
    "            # Initialize lists to store the texture metrics\n",
    "            bbox_contrast_list = []\n",
    "            bbox_dissimilarity_list = []\n",
    "            bbox_homogeneity_list = []\n",
    "            bbox_energy_list = []\n",
    "            donut_contrast_list = []\n",
    "            donut_dissimilarity_list = []\n",
    "            donut_homogeneity_list = []\n",
    "            donut_energy_list = []\n",
    "            \n",
    "            # Iterate through annotations and calculate texture metrics\n",
    "            for _, row in annotations.iterrows():\n",
    "                bbox = ast.literal_eval(row['consensus_bbox'])  # Parse bbox values from string to list\n",
    "                \n",
    "                # Adjust bounding box to stay within image boundaries\n",
    "                bbox = adjust_bbox_to_image(image, bbox)\n",
    "                \n",
    "                # Calculate GCLM derivatives for bounding box\n",
    "                bbox_contrast, bbox_dissimilarity, bbox_homogeneity, bbox_energy = calculate_gclm_derivatives(image, bbox)\n",
    "                \n",
    "                donut_left = max(0, bbox[0] - 20)  # Adjust the buffer size as needed\n",
    "                donut_top = max(0, bbox[1] - 20)\n",
    "                donut_right = min(image.shape[1], bbox[0] + bbox[2] + 20)\n",
    "                donut_bottom = min(image.shape[0], bbox[1] + bbox[3] + 20)\n",
    "                donut_bbox = [donut_left, donut_top, donut_right - donut_left, donut_bottom - donut_top]\n",
    "                donut_contrast, donut_dissimilarity, donut_homogeneity, donut_energy = calculate_gclm_derivatives(image, donut_bbox)\n",
    "\n",
    "                # Append the calculated texture metrics to the lists\n",
    "                bbox_contrast_list.append(bbox_contrast)\n",
    "                bbox_dissimilarity_list.append(bbox_dissimilarity)\n",
    "                bbox_homogeneity_list.append(bbox_homogeneity)\n",
    "                bbox_energy_list.append(bbox_energy)\n",
    "                donut_contrast_list.append(donut_contrast)\n",
    "                donut_dissimilarity_list.append(donut_dissimilarity)\n",
    "                donut_homogeneity_list.append(donut_homogeneity)\n",
    "                donut_energy_list.append(donut_energy)\n",
    "            \n",
    "            # Add texture metrics as columns to a temporary dataframe\n",
    "            temp_df = pd.DataFrame({\n",
    "                'ID': annotations[\"id\"],\n",
    "                'filename': [image_filename] * len(annotations),\n",
    "                'bbox_contrast': bbox_contrast_list,\n",
    "                'bbox_dissimilarity': bbox_dissimilarity_list,\n",
    "                'bbox_homogeneity': bbox_homogeneity_list,\n",
    "                'bbox_energy': bbox_energy_list,\n",
    "                'donut_contrast': donut_contrast_list,\n",
    "                'donut_dissimilarity': donut_dissimilarity_list,\n",
    "                'donut_homogeneity': donut_homogeneity_list,\n",
    "                'donut_energy': donut_energy_list\n",
    "            })\n",
    "            \n",
    "            # Append the temporary dataframe to the main dataframe\n",
    "            texture_metrics_df = pd.concat([texture_metrics_df, temp_df], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image '{image_path}': {e}\")\n",
    "    \n",
    "    # Save the main dataframe with texture metrics to a CSV file\n",
    "    texture_metrics_df.to_csv('E:\\\\imagefactors\\\\data\\\\gclm_crowd.csv', index=False)\n",
    "\n",
    "# Example usage with a directory containing images\n",
    "image_dir = 'E:\\\\imagefactors\\\\data\\\\zooniverse'\n",
    "csv_file = 'E:\\\\imagefactors\\\\data\\\\crowdsourced_imagefactors.csv'  # Replace with the actual path to your CSV file containing the annotations\n",
    "\n",
    "calculate_texture_metrics_for_directory(image_dir, csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>consensus_class_ID</th>\n",
       "      <th>consensus_bbox</th>\n",
       "      <th>pielou_index</th>\n",
       "      <th>basefile</th>\n",
       "      <th>area</th>\n",
       "      <th>bbox_percent_area</th>\n",
       "      <th>same_class_percent</th>\n",
       "      <th>num_neighbors</th>\n",
       "      <th>...</th>\n",
       "      <th>distance_from_center</th>\n",
       "      <th>density</th>\n",
       "      <th>bbox_contrast</th>\n",
       "      <th>bbox_dissimilarity</th>\n",
       "      <th>bbox_homogeneity</th>\n",
       "      <th>bbox_energy</th>\n",
       "      <th>donut_contrast</th>\n",
       "      <th>donut_dissimilarity</th>\n",
       "      <th>donut_homogeneity</th>\n",
       "      <th>donut_energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[634.05224609375, 260.4735412597656, 49.0, 80....</td>\n",
       "      <td>0.764205</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>3920.061310</td>\n",
       "      <td>1.100016</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.163344</td>\n",
       "      <td>9</td>\n",
       "      <td>708.546349</td>\n",
       "      <td>18.148248</td>\n",
       "      <td>0.086465</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>669.094110</td>\n",
       "      <td>17.871651</td>\n",
       "      <td>0.084550</td>\n",
       "      <td>0.014223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[555.4261474609375, 216.25, 53.0, 69.0]</td>\n",
       "      <td>0.764205</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>3657.000000</td>\n",
       "      <td>1.026198</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.628098</td>\n",
       "      <td>9</td>\n",
       "      <td>658.630723</td>\n",
       "      <td>17.472776</td>\n",
       "      <td>0.089489</td>\n",
       "      <td>0.017060</td>\n",
       "      <td>650.098199</td>\n",
       "      <td>17.941989</td>\n",
       "      <td>0.081127</td>\n",
       "      <td>0.013212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[266.75, 120.83124542236328, 60.33087158203125...</td>\n",
       "      <td>0.764205</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>5188.454956</td>\n",
       "      <td>1.455943</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.723215</td>\n",
       "      <td>9</td>\n",
       "      <td>624.725403</td>\n",
       "      <td>17.631852</td>\n",
       "      <td>0.077243</td>\n",
       "      <td>0.014419</td>\n",
       "      <td>553.768272</td>\n",
       "      <td>16.981959</td>\n",
       "      <td>0.073528</td>\n",
       "      <td>0.012126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[176.8125, 22.46035385131836, 52.0, 84.0]</td>\n",
       "      <td>0.764205</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>4368.000000</td>\n",
       "      <td>1.225713</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.630146</td>\n",
       "      <td>9</td>\n",
       "      <td>463.748687</td>\n",
       "      <td>14.682327</td>\n",
       "      <td>0.093184</td>\n",
       "      <td>0.016236</td>\n",
       "      <td>477.028835</td>\n",
       "      <td>15.441471</td>\n",
       "      <td>0.082321</td>\n",
       "      <td>0.012909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[101.36946105957031, 170.06580352783203, 62.24...</td>\n",
       "      <td>0.721928</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>5135.498171</td>\n",
       "      <td>1.441082</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.459121</td>\n",
       "      <td>9</td>\n",
       "      <td>475.779931</td>\n",
       "      <td>15.135325</td>\n",
       "      <td>0.091384</td>\n",
       "      <td>0.015773</td>\n",
       "      <td>465.466953</td>\n",
       "      <td>15.483350</td>\n",
       "      <td>0.080959</td>\n",
       "      <td>0.012942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                         filename consensus_class_ID  \\\n",
       "0   1  20211201_Atrisco_0459_01_01.png              Goose   \n",
       "1   2  20211201_Atrisco_0459_01_01.png              Goose   \n",
       "2   3  20211201_Atrisco_0459_01_01.png              Goose   \n",
       "3   4  20211201_Atrisco_0459_01_01.png              Goose   \n",
       "4   5  20211201_Atrisco_0459_01_01.png              Goose   \n",
       "\n",
       "                                      consensus_bbox  pielou_index  \\\n",
       "0  [634.05224609375, 260.4735412597656, 49.0, 80....      0.764205   \n",
       "1            [555.4261474609375, 216.25, 53.0, 69.0]      0.764205   \n",
       "2  [266.75, 120.83124542236328, 60.33087158203125...      0.764205   \n",
       "3          [176.8125, 22.46035385131836, 52.0, 84.0]      0.764205   \n",
       "4  [101.36946105957031, 170.06580352783203, 62.24...      0.721928   \n",
       "\n",
       "                basefile         area  bbox_percent_area  same_class_percent  \\\n",
       "0  20211201_Atrisco_0459  3920.061310           1.100016               100.0   \n",
       "1  20211201_Atrisco_0459  3657.000000           1.026198               100.0   \n",
       "2  20211201_Atrisco_0459  5188.454956           1.455943               100.0   \n",
       "3  20211201_Atrisco_0459  4368.000000           1.225713               100.0   \n",
       "4  20211201_Atrisco_0459  5135.498171           1.441082               100.0   \n",
       "\n",
       "   num_neighbors  ...  distance_from_center  density  bbox_contrast  \\\n",
       "0              1  ...              2.163344        9     708.546349   \n",
       "1              1  ...              1.628098        9     658.630723   \n",
       "2              4  ...              0.723215        9     624.725403   \n",
       "3              2  ...              1.630146        9     463.748687   \n",
       "4              1  ...              1.459121        9     475.779931   \n",
       "\n",
       "   bbox_dissimilarity  bbox_homogeneity  bbox_energy  donut_contrast  \\\n",
       "0           18.148248          0.086465     0.016047      669.094110   \n",
       "1           17.472776          0.089489     0.017060      650.098199   \n",
       "2           17.631852          0.077243     0.014419      553.768272   \n",
       "3           14.682327          0.093184     0.016236      477.028835   \n",
       "4           15.135325          0.091384     0.015773      465.466953   \n",
       "\n",
       "   donut_dissimilarity  donut_homogeneity  donut_energy  \n",
       "0            17.871651           0.084550      0.014223  \n",
       "1            17.941989           0.081127      0.013212  \n",
       "2            16.981959           0.073528      0.012126  \n",
       "3            15.441471           0.082321      0.012909  \n",
       "4            15.483350           0.080959      0.012942  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge the basic GCLM to the main dataframe\n",
    "path1 = \"E:\\\\imagefactors\\\\data\\\\gclm_crowd.csv\"\n",
    "with open(path1) as f1:\n",
    "  gclm_crowd = pd.read_csv(f1)\n",
    "\n",
    "df = pd.merge(df, gclm_crowd, on=[\"id\", \"filename\"], how=\"left\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the differences for each GCLM statistic\n",
    "df['contrast_difference'] = df['donut_contrast'] - df['bbox_contrast']\n",
    "df['energy_difference'] = df['donut_energy'] - df['bbox_energy']\n",
    "df['homogeneity_difference'] = df['donut_homogeneity'] - df['bbox_homogeneity']\n",
    "df['dissimilarity_difference'] = df['donut_dissimilarity'] - df['bbox_dissimilarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save \n",
    "df.to_csv('E:/imagefactors/data/crowdsourced_imagefactors.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELING IMPACT OF IMAGE FACTORS ON LABELING DIFFICULTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           pielou_index   R-squared:                       0.126\n",
      "Model:                            OLS   Adj. R-squared:                  0.126\n",
      "Method:                 Least Squares   F-statistic:                     1963.\n",
      "Date:                Tue, 10 Oct 2023   Prob (F-statistic):               0.00\n",
      "Time:                        22:11:49   Log-Likelihood:                -29946.\n",
      "No. Observations:              136447   AIC:                         5.991e+04\n",
      "Df Residuals:                  136436   BIC:                         6.002e+04\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "============================================================================================\n",
      "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------\n",
      "const                        0.2695      0.005     50.971      0.000       0.259       0.280\n",
      "gsd                          0.2828      0.004     78.789      0.000       0.276       0.290\n",
      "bbox_percent_area           -0.0455      0.001    -30.567      0.000      -0.048      -0.043\n",
      "same_class_percent          -0.0014   3.82e-05    -36.584      0.000      -0.001      -0.001\n",
      "num_neighbors                0.0028      0.001      4.618      0.000       0.002       0.004\n",
      "distance_from_center        -0.0114      0.001    -11.319      0.000      -0.013      -0.009\n",
      "density                     -0.0038   8.58e-05    -43.939      0.000      -0.004      -0.004\n",
      "contrast_difference          0.0002   1.73e-05      8.661      0.000       0.000       0.000\n",
      "energy_difference            8.7215      0.158     55.335      0.000       8.413       9.030\n",
      "homogeneity_difference      -1.8028      0.085    -21.225      0.000      -1.969      -1.636\n",
      "dissimilarity_difference    -0.0133      0.002     -8.002      0.000      -0.017      -0.010\n",
      "==============================================================================\n",
      "Omnibus:                    28471.136   Durbin-Watson:                   0.775\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            14377.091\n",
      "Skew:                           0.650   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.083   Cond. No.                     6.06e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 6.06e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "#Multiple linear regression \n",
    "\n",
    "y = df['pielou_index']\n",
    "X = df[['gsd', 'bbox_percent_area', 'same_class_percent', 'num_neighbors', 'distance_from_center', 'density', 'contrast_difference', 'energy_difference', 'homogeneity_difference', 'dissimilarity_difference']]\n",
    "\n",
    "# Add a constant term to the independent variables (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the regression summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISUALIZATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot with regression lines\n",
    "sns.pairplot(df, x_vars=['gsd', 'bbox_percent_area', 'same_class_percent', 'num_neighbors', 'distance_from_center', 'density'], y_vars=['pielou_index'], kind='reg', height=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample visualization of donut + bounding boxes just to make sure it all looks good\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "def visualize_bounding_boxes_with_donuts(image_path, csv_file):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB\n",
    "    \n",
    "    # Read the CSV file\n",
    "    csv_data = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Find the corresponding image filename\n",
    "    image_filename = os.path.basename(image_path)\n",
    "    \n",
    "    # Filter annotations based on the image filename\n",
    "    annotations = csv_data[csv_data['filename'] == image_filename]\n",
    "    \n",
    "    # Plot the image with bounding boxes and donut regions\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Iterate through annotations and draw bounding boxes and donut regions\n",
    "    for _, row in annotations.iterrows():\n",
    "        bbox = ast.literal_eval(row['consensus_bbox'])  # Parse bbox values from string to list\n",
    "        \n",
    "        # Draw bounding box\n",
    "        rectangle = Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rectangle)\n",
    "        \n",
    "        # Draw donut region\n",
    "        donut_left = max(0, bbox[0] - 20)  # Adjust the buffer size as needed\n",
    "        donut_top = max(0, bbox[1] - 20)\n",
    "        donut_right = min(image.shape[1], bbox[0] + bbox[2] + 20)\n",
    "        donut_bottom = min(image.shape[0], bbox[1] + bbox[3] + 20)\n",
    "        donut_rectangle = Rectangle((donut_left, donut_top), (donut_right - donut_left),\n",
    "                                   (donut_bottom - donut_top), linewidth=1, edgecolor='g', facecolor='none')\n",
    "        ax.add_patch(donut_rectangle)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "image_path = 'E:\\\\imagefactors\\\\data\\\\zooniverse\\\\20211201_Atrisco_0459_01_01.png'\n",
    "csv_file = path\n",
    "\n",
    "visualize_bounding_boxes_with_donuts(image_path, csv_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEXTURE METRICS-- GCLM\n",
    "# annotation + \"donut\" area (interior + exterior buffer)-- SINGLE IMAGE ONLY\n",
    "\n",
    "def calculate_gclm_derivatives(image, bbox):\n",
    "    # Convert bounding box coordinates to integers\n",
    "    x, y, width, height = map(int, bbox)\n",
    "    \n",
    "    # Extract the region of interest (ROI) from the image using the bounding box\n",
    "    roi = image[y:y+height, x:x+width]\n",
    "    \n",
    "    # Convert the ROI to grayscale\n",
    "    roi_gray = cv2.cvtColor(roi, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Calculate GCLM features for the grayscale ROI\n",
    "    distances = [1, 2]  # Define the distances for GCLM\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]  # Define the angles for GCLM\n",
    "    gclm = graycomatrix(roi_gray, distances=distances, angles=angles, levels=256,\n",
    "                        symmetric=True, normed=True)\n",
    "    \n",
    "    # Calculate GCLM derivatives (contrast, dissimilarity, homogeneity, energy)\n",
    "    contrast = graycoprops(gclm, 'contrast').mean()\n",
    "    dissimilarity = graycoprops(gclm, 'dissimilarity').mean()\n",
    "    homogeneity = graycoprops(gclm, 'homogeneity').mean()\n",
    "    energy = graycoprops(gclm, 'energy').mean()\n",
    "    \n",
    "    return contrast, dissimilarity, homogeneity, energy\n",
    "\n",
    "def calculate_texture_metrics_for_csv(image_path, csv_file):\n",
    "        # Load the image\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        # Read the CSV file\n",
    "        csv_data = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Find the corresponding image filename\n",
    "        image_filename = os.path.basename(image_path)\n",
    "        \n",
    "        # Filter annotations based on the image filename\n",
    "        annotations = csv_data[csv_data['filename'] == image_filename]\n",
    "        \n",
    "        # Initialize lists to store the texture metrics\n",
    "        bbox_contrast_list = []\n",
    "        bbox_dissimilarity_list = []\n",
    "        bbox_homogeneity_list = []\n",
    "        bbox_energy_list = []\n",
    "        donut_contrast_list = []\n",
    "        donut_dissimilarity_list = []\n",
    "        donut_homogeneity_list = []\n",
    "        donut_energy_list = []\n",
    "        \n",
    "        # Iterate through annotations and calculate texture metrics\n",
    "        for _, row in annotations.iterrows():\n",
    "            bbox = ast.literal_eval(row['consensus_bbox'])  # Parse bbox values from string to list\n",
    "            \n",
    "            # Calculate GCLM derivatives for bounding box and donut region\n",
    "            bbox_contrast, bbox_dissimilarity, bbox_homogeneity, bbox_energy = calculate_gclm_derivatives(image, bbox)\n",
    "            \n",
    "            donut_left = max(0, bbox[0] - 20)  # Adjust the buffer size as needed\n",
    "            donut_top = max(0, bbox[1] - 20)\n",
    "            donut_right = min(image.shape[1], bbox[0] + bbox[2] + 20)\n",
    "            donut_bottom = min(image.shape[0], bbox[1] + bbox[3] + 20)\n",
    "            donut_bbox = [donut_left, donut_top, donut_right - donut_left, donut_bottom - donut_top]\n",
    "            donut_contrast, donut_dissimilarity, donut_homogeneity, donut_energy = calculate_gclm_derivatives(image, donut_bbox)\n",
    "            \n",
    "            # Append the calculated texture metrics to the lists\n",
    "            bbox_contrast_list.append(bbox_contrast)\n",
    "            bbox_dissimilarity_list.append(bbox_dissimilarity)\n",
    "            bbox_homogeneity_list.append(bbox_homogeneity)\n",
    "            bbox_energy_list.append(bbox_energy)\n",
    "            \n",
    "            donut_contrast_list.append(donut_contrast)\n",
    "            donut_dissimilarity_list.append(donut_dissimilarity)\n",
    "            donut_homogeneity_list.append(donut_homogeneity)\n",
    "            donut_energy_list.append(donut_energy)\n",
    "        \n",
    "        # Add texture metrics as new columns in the dataframe\n",
    "        annotations['bbox_contrast'] = bbox_contrast_list\n",
    "        annotations['bbox_dissimilarity'] = bbox_dissimilarity_list\n",
    "        annotations['bbox_homogeneity'] = bbox_homogeneity_list\n",
    "        annotations['bbox_energy'] = bbox_energy_list\n",
    "        \n",
    "        annotations['donut_contrast'] = donut_contrast_list\n",
    "        annotations['donut_dissimilarity'] = donut_dissimilarity_list\n",
    "        annotations['donut_homogeneity'] = donut_homogeneity_list\n",
    "        annotations['donut_energy'] = donut_energy_list\n",
    "        \n",
    "        # Save the modified dataframe if needed\n",
    "        annotations.to_csv('E:\\\\imagefactors\\\\data\\\\gclm.csv', index=False)\n",
    "    \n",
    "# Example usage\n",
    "image_path = 'E:\\\\imagefactors\\\\data\\\\zooniverse\\\\20211212_Alameda_0285_07_08.png'\n",
    "csv_file = path  # Replace with the actual path to your CSV file containing the annotations\n",
    "\n",
    "calculate_texture_metrics_for_csv(image_path, csv_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dronesforducks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
