{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of image factors on annotation consensus-- Zooniverse\n",
    "Start date: 09/26/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis annotations\n",
    "path = \"E:\\\\imagefactors\\\\data\\\\consensusLabels_agreementIndex.csv\"\n",
    "with open(path) as f:\n",
    "  df = pd.read_csv(f)\n",
    "\n",
    "#Fixing how bounding boxes are read for the analysis labels\n",
    "def eval_bbox_refined(row):\n",
    "    if pd.notnull(row['consensus_bbox']):\n",
    "        return ast.literal_eval(row['consensus_bbox'])\n",
    "    else:\n",
    "        return None\n",
    "# Apply the function to the 'bbox_refined' column and save the results\n",
    "df['consensus_bbox'] = df.apply(eval_bbox_refined, axis=1)\n",
    "\n",
    "#Creating a base file column to match tiles to full images later\n",
    "df[\"basefile\"] = [x[:-10] for x in df['filename']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IF RESUMING FROM A SAVED POINT\n",
    "path = \"E:/imagefactors/data/crowdsourced_imagefactors.csv\"\n",
    "with open(path) as f:\n",
    "  df = pd.read_csv(f)\n",
    "#Fixing how bounding boxes are read for the analysis labels\n",
    "def eval_bbox_refined(row):\n",
    "    if pd.notnull(row['consensus_bbox']):\n",
    "        return ast.literal_eval(row['consensus_bbox'])\n",
    "    else:\n",
    "        return None\n",
    "# Apply the function to the 'bbox_refined' column and save the results\n",
    "df['consensus_bbox'] = df.apply(eval_bbox_refined, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DERIVE IMAGE/ANNOTATION FACTORS FOR ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BBOX AREA\n",
    "\n",
    "def calc_area(row):\n",
    "    bbox = row['consensus_bbox']\n",
    "    xmin, ymin, w, h = bbox\n",
    "    return w * h\n",
    "\n",
    "df['area'] = df.apply(calc_area, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % AREA BBOX\n",
    "# Percent area of the bounding box of the total image area\n",
    "\n",
    "# Define a function to calculate percentage area\n",
    "def calculate_percentage_area(image_filename, bbox_area):\n",
    "    image_path = os.path.join(\"E:\\\\imagefactors\\\\data\\\\zooniverse\", image_filename)\n",
    "    \n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "    except FileNotFoundError:\n",
    "        # Handle the case where the image is not found\n",
    "        print(f\"Image not found: {image_path}\")\n",
    "        return None  # You can return a special value, such as None, to indicate the image wasn't found\n",
    "    \n",
    "    image_width, image_height = image.size\n",
    "    image_area = image_width * image_height\n",
    "\n",
    "    percentage_area = (bbox_area / image_area) * 100\n",
    "    return percentage_area\n",
    "\n",
    "# Calculate percentage area and add it as a new\n",
    "df['bbox_percent_area'] = df.apply(lambda row: calculate_percentage_area(row['filename'], row['area']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAME CLASS %\n",
    "# % of targets of the same class as the analysis target (in the same image)\n",
    "\n",
    "# Define a function to calculate the percentage of same-class neighbors for a given row\n",
    "def calculate_same_class_percentage(row, df):\n",
    "    # Get the filename and class ID of the target bounding box\n",
    "    filename = row['filename']\n",
    "    class_id = row['consensus_class_ID']\n",
    "    \n",
    "    # Filter the DataFrame to include only rows with matching filenames\n",
    "    matching_rows = df[df['filename'] == filename]\n",
    "    \n",
    "    # Calculate the total number of neighbors in the same image\n",
    "    total_neighbors = len(matching_rows) - 1  # Subtract 1 to exclude the target bounding box\n",
    "    \n",
    "    if total_neighbors == 0:\n",
    "        return 0  # Avoid division by zero\n",
    "    \n",
    "    # Calculate the number of same-class neighbors\n",
    "    same_class_neighbors = len(matching_rows[matching_rows['consensus_class_ID'] == class_id]) - 1  # Subtract 1 to exclude the target bounding box\n",
    "    \n",
    "    # Calculate the percentage of same-class neighbors\n",
    "    same_class_percentage = (same_class_neighbors / total_neighbors) * 100\n",
    "    \n",
    "    return same_class_percentage\n",
    "\n",
    "# Calculate the same-class percentage for each row and add the results as a new column\n",
    "df['same_class_percent'] = df.apply(lambda row: calculate_same_class_percentage(row, df), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUMBER OF NEIGHBORS \n",
    "# Number of annotations within 2x maximum of bbox width or height (to account for positional differences)\n",
    "\n",
    "# Define a function to calculate the number of neighbors for a given row\n",
    "def count_neighbors(row, df):\n",
    "    # Extract 'bbox' values from the 'consensus_bbox' column as a list [xmin, ymin, width, height]\n",
    "    bbox = row['consensus_bbox']  # Use ast.literal_eval() to safely evaluate the string\n",
    "    \n",
    "    # Define the search radius as 2 times the maximum of width and height\n",
    "    search_radius = 2 * max(bbox[2], bbox[3])\n",
    "    \n",
    "    # Calculate the center coordinates of the bounding box\n",
    "    x_center = bbox[0] + bbox[2] / 2\n",
    "    y_center = bbox[1] + bbox[3] / 2\n",
    "    \n",
    "    # Initialize a count for neighbors\n",
    "    num_neighbors = 0\n",
    "    \n",
    "    # Iterate through rows with matching filenames\n",
    "    matching_rows = df[df['filename'] == row['filename']]\n",
    "    \n",
    "    for _, neighbor_row in matching_rows.iterrows():\n",
    "        if neighbor_row.name != row.name:\n",
    "            # Extract 'bbox' values for the neighbor as a list [xmin, ymin, width, height]\n",
    "            neighbor_bbox = neighbor_row['consensus_bbox']\n",
    "            \n",
    "            # Calculate the center coordinates of the potential neighbor\n",
    "            neighbor_x_center = neighbor_bbox[0] + neighbor_bbox[2] / 2\n",
    "            neighbor_y_center = neighbor_bbox[1] + neighbor_bbox[3] / 2\n",
    "            \n",
    "            # Calculate the Euclidean distance between centers\n",
    "            distance = np.sqrt((x_center - neighbor_x_center)**2 + (y_center - neighbor_y_center)**2)\n",
    "            \n",
    "            # Check if the neighbor is within the search radius\n",
    "            if distance <= search_radius:\n",
    "                num_neighbors += 1\n",
    "    \n",
    "    return num_neighbors\n",
    "\n",
    "# Calculate the number of neighbors for each row and add the results as a new column\n",
    "df['num_neighbors'] = df.apply(lambda row: count_neighbors(row, df), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOTAL NUMBER OF BIRDS PER IMAGE\n",
    "df['density'] = df.groupby('filename')['consensus_bbox'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISTANCE OF TARGET FROM IMAGE CENTER-- in meters\n",
    "\n",
    "path1 = \"E:\\\\imagefactors\\\\data\\\\crowdsourced_gsd.csv\"\n",
    "with open(path1) as f1:\n",
    "  gsd_df = pd.read_csv(f1)\n",
    "\n",
    "gsd_df[\"basefile\"] = gsd_df[\"filename\"].apply(lambda x: os.path.splitext(x)[0])\n",
    "\n",
    "merged_df = pd.merge(df, gsd_df, on=\"basefile\", how=\"left\")\n",
    "merged_df = merged_df.rename(columns={\"filename_x\": \"filename\"})\n",
    "merged_df = merged_df.drop(columns=[\"filename_y\", \"filename_base\"])\n",
    "\n",
    "# Function to calculate distance from center\n",
    "def calculate_distance_from_center(row):\n",
    "    image_path = os.path.join(\"E:\\\\imagefactors\\\\data\\\\zooniverse\", row[\"filename\"])\n",
    "    \n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "    except FileNotFoundError:\n",
    "        # Handle the case where the image is not found\n",
    "        print(f\"Image not found: {image_path}\")\n",
    "        return None  # You can return a special value, such as None, to indicate the image wasn't found\n",
    "    \n",
    "    image_width, image_height = image.size\n",
    "    center_x_px = image_width/2 \n",
    "    center_y_px = image_height/2\n",
    "    gsd_m = row['gsd'] / 100\n",
    "\n",
    "    row['center_x_m'] = center_x_px * gsd_m\n",
    "    row['center_y_m'] = center_y_px * gsd_m\n",
    "    \n",
    "    # Get the coordinates of the bounding box (x, y, width, height)\n",
    "    x, y, width, height = row['consensus_bbox']\n",
    "\n",
    "    # Calculate the center point of the bounding box in pixels\n",
    "    bbox_center_x_px = x + (width / 2)\n",
    "    bbox_center_y_px = y + (height / 2)\n",
    "\n",
    "    # Calculate the center point of the bounding box in meters\n",
    "    bbox_center_x_m = bbox_center_x_px * gsd_m\n",
    "    bbox_center_y_m = bbox_center_y_px * gsd_m\n",
    "\n",
    "    # Calculate the distance from the center of the image in meters\n",
    "    distance_m = ((row['center_x_m'] - bbox_center_x_m)**2 + (row['center_y_m'] - bbox_center_y_m)**2)**0.5\n",
    "\n",
    "    return distance_m\n",
    "\n",
    "# Apply the function to the merged dataframe\n",
    "merged_df['distance_from_center'] = merged_df.apply(calculate_distance_from_center, axis=1)\n",
    "df = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Image 'E:\\imagefactors\\data\\zooniverse\\data_train2.txt' not found or cannot be loaded.\n",
      "Warning: Image 'E:\\imagefactors\\data\\zooniverse\\README.txt' not found or cannot be loaded.\n"
     ]
    }
   ],
   "source": [
    "#TEXTURE METRICS- GLCM\n",
    "#Bounding box and \"donut\" (buffer region directly around bbox)\n",
    "\n",
    "def calculate_gclm_derivatives(image, bbox):\n",
    "    # Convert bounding box coordinates to integers\n",
    "    x, y, width, height = map(int, bbox)\n",
    "    \n",
    "    # Extract the region of interest (ROI) from the image using the bounding box\n",
    "    roi = image[y:y+height, x:x+width]\n",
    "    \n",
    "    # Check if the ROI is empty or None\n",
    "    if roi is None or roi.size == 0:\n",
    "        print(\"Warning: ROI is empty or None\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # Convert the ROI to grayscale\n",
    "    roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate GCLM features for the grayscale ROI\n",
    "    distances = [1, 2]  # Define the distances for GCLM\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]  # Define the angles for GCLM\n",
    "    gclm = graycomatrix(roi_gray, distances=distances, angles=angles, levels=256,\n",
    "                        symmetric=True, normed=True)\n",
    "    \n",
    "    # Calculate GCLM derivatives (contrast, dissimilarity, homogeneity, energy)\n",
    "    contrast = graycoprops(gclm, 'contrast').mean()\n",
    "    dissimilarity = graycoprops(gclm, 'dissimilarity').mean()\n",
    "    homogeneity = graycoprops(gclm, 'homogeneity').mean()\n",
    "    energy = graycoprops(gclm, 'energy').mean()\n",
    "    \n",
    "    return contrast, dissimilarity, homogeneity, energy\n",
    "\n",
    "def adjust_bbox_to_image(image, bbox):\n",
    "    # Get image dimensions\n",
    "    image_height, image_width, _ = image.shape\n",
    "    \n",
    "    # Adjust bounding box coordinates if they exceed image boundaries\n",
    "    x, y, width, height = bbox\n",
    "    \n",
    "    # Ensure the bounding box does not go beyond the image boundaries\n",
    "    x = max(x, 0)\n",
    "    y = max(y, 0)\n",
    "    width = min(width, image_width - x)\n",
    "    height = min(height, image_height - y)\n",
    "    \n",
    "    return x, y, width, height\n",
    "\n",
    "def calculate_texture_metrics_for_directory(image_dir, csv_file):\n",
    "    # Initialize an empty dataframe to store the texture metrics\n",
    "    texture_metrics_df = pd.DataFrame()\n",
    "    \n",
    "    # List all files in the specified directory\n",
    "    image_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        try:\n",
    "            # Construct the full path to the image file\n",
    "            image_path = os.path.join(image_dir, image_file)\n",
    "            \n",
    "            # Load the image\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            if image is None:\n",
    "                print(f\"Warning: Image '{image_path}' not found or cannot be loaded.\")\n",
    "                continue\n",
    "            \n",
    "            # Read the CSV file\n",
    "            csv_data = pd.read_csv(csv_file)\n",
    "            \n",
    "            # Find the corresponding image filename\n",
    "            image_filename = os.path.basename(image_path)\n",
    "            \n",
    "            # Filter annotations based on the image filename\n",
    "            annotations = csv_data[csv_data['filename'] == image_filename]\n",
    "            \n",
    "            # Initialize lists to store the texture metrics\n",
    "            bbox_contrast_list = []\n",
    "            bbox_dissimilarity_list = []\n",
    "            bbox_homogeneity_list = []\n",
    "            bbox_energy_list = []\n",
    "            donut_contrast_list = []\n",
    "            donut_dissimilarity_list = []\n",
    "            donut_homogeneity_list = []\n",
    "            donut_energy_list = []\n",
    "            \n",
    "            # Iterate through annotations and calculate texture metrics\n",
    "            for _, row in annotations.iterrows():\n",
    "                bbox = ast.literal_eval(row['consensus_bbox'])  # Parse bbox values from string to list\n",
    "                \n",
    "                # Adjust bounding box to stay within image boundaries\n",
    "                bbox = adjust_bbox_to_image(image, bbox)\n",
    "                \n",
    "                # Calculate GCLM derivatives for bounding box\n",
    "                bbox_contrast, bbox_dissimilarity, bbox_homogeneity, bbox_energy = calculate_gclm_derivatives(image, bbox)\n",
    "                \n",
    "                donut_left = max(0, bbox[0] - 20)  # Adjust the buffer size as needed\n",
    "                donut_top = max(0, bbox[1] - 20)\n",
    "                donut_right = min(image.shape[1], bbox[0] + bbox[2] + 20)\n",
    "                donut_bottom = min(image.shape[0], bbox[1] + bbox[3] + 20)\n",
    "                donut_bbox = [donut_left, donut_top, donut_right - donut_left, donut_bottom - donut_top]\n",
    "                donut_contrast, donut_dissimilarity, donut_homogeneity, donut_energy = calculate_gclm_derivatives(image, donut_bbox)\n",
    "\n",
    "                # Append the calculated texture metrics to the lists\n",
    "                bbox_contrast_list.append(bbox_contrast)\n",
    "                bbox_dissimilarity_list.append(bbox_dissimilarity)\n",
    "                bbox_homogeneity_list.append(bbox_homogeneity)\n",
    "                bbox_energy_list.append(bbox_energy)\n",
    "                donut_contrast_list.append(donut_contrast)\n",
    "                donut_dissimilarity_list.append(donut_dissimilarity)\n",
    "                donut_homogeneity_list.append(donut_homogeneity)\n",
    "                donut_energy_list.append(donut_energy)\n",
    "            \n",
    "            # Add texture metrics as columns to a temporary dataframe\n",
    "            temp_df = pd.DataFrame({\n",
    "                'ID': annotations[\"id\"],\n",
    "                'filename': [image_filename] * len(annotations),\n",
    "                'bbox_contrast': bbox_contrast_list,\n",
    "                'bbox_dissimilarity': bbox_dissimilarity_list,\n",
    "                'bbox_homogeneity': bbox_homogeneity_list,\n",
    "                'bbox_energy': bbox_energy_list,\n",
    "                'donut_contrast': donut_contrast_list,\n",
    "                'donut_dissimilarity': donut_dissimilarity_list,\n",
    "                'donut_homogeneity': donut_homogeneity_list,\n",
    "                'donut_energy': donut_energy_list\n",
    "            })\n",
    "            \n",
    "            # Append the temporary dataframe to the main dataframe\n",
    "            texture_metrics_df = pd.concat([texture_metrics_df, temp_df], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image '{image_path}': {e}\")\n",
    "    \n",
    "    # Save the main dataframe with texture metrics to a CSV file\n",
    "    texture_metrics_df.to_csv('E:\\\\imagefactors\\\\data\\\\gclm_crowd.csv', index=False)\n",
    "\n",
    "# Example usage with a directory containing images\n",
    "image_dir = 'E:\\\\imagefactors\\\\data\\\\zooniverse'\n",
    "csv_file = 'E:\\\\imagefactors\\\\data\\\\crowdsourced_imagefactors.csv'  # Replace with the actual path to your CSV file containing the annotations\n",
    "\n",
    "calculate_texture_metrics_for_directory(image_dir, csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>consensus_class_ID</th>\n",
       "      <th>consensus_bbox</th>\n",
       "      <th>pielou_index</th>\n",
       "      <th>basefile</th>\n",
       "      <th>area</th>\n",
       "      <th>bbox_percent_area</th>\n",
       "      <th>same_class_percent</th>\n",
       "      <th>num_neighbors</th>\n",
       "      <th>...</th>\n",
       "      <th>distance_from_center</th>\n",
       "      <th>density</th>\n",
       "      <th>bbox_contrast</th>\n",
       "      <th>bbox_dissimilarity</th>\n",
       "      <th>bbox_homogeneity</th>\n",
       "      <th>bbox_energy</th>\n",
       "      <th>donut_contrast</th>\n",
       "      <th>donut_dissimilarity</th>\n",
       "      <th>donut_homogeneity</th>\n",
       "      <th>donut_energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[634.05224609375, 260.4735412597656, 49.0, 80....</td>\n",
       "      <td>0.764205</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>3920.061310</td>\n",
       "      <td>1.100016</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.163344</td>\n",
       "      <td>9</td>\n",
       "      <td>708.546349</td>\n",
       "      <td>18.148248</td>\n",
       "      <td>0.086465</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>669.094110</td>\n",
       "      <td>17.871651</td>\n",
       "      <td>0.084550</td>\n",
       "      <td>0.014223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[555.4261474609375, 216.25, 53.0, 69.0]</td>\n",
       "      <td>0.764205</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>3657.000000</td>\n",
       "      <td>1.026198</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.628098</td>\n",
       "      <td>9</td>\n",
       "      <td>658.630723</td>\n",
       "      <td>17.472776</td>\n",
       "      <td>0.089489</td>\n",
       "      <td>0.017060</td>\n",
       "      <td>650.098199</td>\n",
       "      <td>17.941989</td>\n",
       "      <td>0.081127</td>\n",
       "      <td>0.013212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[266.75, 120.83124542236328, 60.33087158203125...</td>\n",
       "      <td>0.764205</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>5188.454956</td>\n",
       "      <td>1.455943</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.723215</td>\n",
       "      <td>9</td>\n",
       "      <td>624.725403</td>\n",
       "      <td>17.631852</td>\n",
       "      <td>0.077243</td>\n",
       "      <td>0.014419</td>\n",
       "      <td>553.768272</td>\n",
       "      <td>16.981959</td>\n",
       "      <td>0.073528</td>\n",
       "      <td>0.012126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[176.8125, 22.46035385131836, 52.0, 84.0]</td>\n",
       "      <td>0.764205</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>4368.000000</td>\n",
       "      <td>1.225713</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.630146</td>\n",
       "      <td>9</td>\n",
       "      <td>463.748687</td>\n",
       "      <td>14.682327</td>\n",
       "      <td>0.093184</td>\n",
       "      <td>0.016236</td>\n",
       "      <td>477.028835</td>\n",
       "      <td>15.441471</td>\n",
       "      <td>0.082321</td>\n",
       "      <td>0.012909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[101.36946105957031, 170.06580352783203, 62.24...</td>\n",
       "      <td>0.721928</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>5135.498171</td>\n",
       "      <td>1.441082</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.459121</td>\n",
       "      <td>9</td>\n",
       "      <td>475.779931</td>\n",
       "      <td>15.135325</td>\n",
       "      <td>0.091384</td>\n",
       "      <td>0.015773</td>\n",
       "      <td>465.466953</td>\n",
       "      <td>15.483350</td>\n",
       "      <td>0.080959</td>\n",
       "      <td>0.012942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                         filename consensus_class_ID  \\\n",
       "0   1  20211201_Atrisco_0459_01_01.png              Goose   \n",
       "1   2  20211201_Atrisco_0459_01_01.png              Goose   \n",
       "2   3  20211201_Atrisco_0459_01_01.png              Goose   \n",
       "3   4  20211201_Atrisco_0459_01_01.png              Goose   \n",
       "4   5  20211201_Atrisco_0459_01_01.png              Goose   \n",
       "\n",
       "                                      consensus_bbox  pielou_index  \\\n",
       "0  [634.05224609375, 260.4735412597656, 49.0, 80....      0.764205   \n",
       "1            [555.4261474609375, 216.25, 53.0, 69.0]      0.764205   \n",
       "2  [266.75, 120.83124542236328, 60.33087158203125...      0.764205   \n",
       "3          [176.8125, 22.46035385131836, 52.0, 84.0]      0.764205   \n",
       "4  [101.36946105957031, 170.06580352783203, 62.24...      0.721928   \n",
       "\n",
       "                basefile         area  bbox_percent_area  same_class_percent  \\\n",
       "0  20211201_Atrisco_0459  3920.061310           1.100016               100.0   \n",
       "1  20211201_Atrisco_0459  3657.000000           1.026198               100.0   \n",
       "2  20211201_Atrisco_0459  5188.454956           1.455943               100.0   \n",
       "3  20211201_Atrisco_0459  4368.000000           1.225713               100.0   \n",
       "4  20211201_Atrisco_0459  5135.498171           1.441082               100.0   \n",
       "\n",
       "   num_neighbors  ...  distance_from_center  density  bbox_contrast  \\\n",
       "0              1  ...              2.163344        9     708.546349   \n",
       "1              1  ...              1.628098        9     658.630723   \n",
       "2              4  ...              0.723215        9     624.725403   \n",
       "3              2  ...              1.630146        9     463.748687   \n",
       "4              1  ...              1.459121        9     475.779931   \n",
       "\n",
       "   bbox_dissimilarity  bbox_homogeneity  bbox_energy  donut_contrast  \\\n",
       "0           18.148248          0.086465     0.016047      669.094110   \n",
       "1           17.472776          0.089489     0.017060      650.098199   \n",
       "2           17.631852          0.077243     0.014419      553.768272   \n",
       "3           14.682327          0.093184     0.016236      477.028835   \n",
       "4           15.135325          0.091384     0.015773      465.466953   \n",
       "\n",
       "   donut_dissimilarity  donut_homogeneity  donut_energy  \n",
       "0            17.871651           0.084550      0.014223  \n",
       "1            17.941989           0.081127      0.013212  \n",
       "2            16.981959           0.073528      0.012126  \n",
       "3            15.441471           0.082321      0.012909  \n",
       "4            15.483350           0.080959      0.012942  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge the basic GCLM to the main dataframe\n",
    "path1 = \"E:\\\\imagefactors\\\\data\\\\gclm_crowd.csv\"\n",
    "with open(path1) as f1:\n",
    "  gclm_crowd = pd.read_csv(f1)\n",
    "\n",
    "df = pd.merge(df, gclm_crowd, on=[\"id\", \"filename\"], how=\"left\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the differences for each GCLM statistic\n",
    "df['contrast_difference'] = df['donut_contrast'] - df['bbox_contrast']\n",
    "df['energy_difference'] = df['donut_energy'] - df['bbox_energy']\n",
    "df['homogeneity_difference'] = df['donut_homogeneity'] - df['bbox_homogeneity']\n",
    "df['dissimilarity_difference'] = df['donut_dissimilarity'] - df['bbox_dissimilarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save \n",
    "df.to_csv('E:/imagefactors/data/crowdsourced_imagefactors.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename_x</th>\n",
       "      <th>consensus_class_ID_x</th>\n",
       "      <th>consensus_bbox_x</th>\n",
       "      <th>pielou_index</th>\n",
       "      <th>basefile</th>\n",
       "      <th>area</th>\n",
       "      <th>bbox_percent_area</th>\n",
       "      <th>same_class_percent</th>\n",
       "      <th>num_neighbors</th>\n",
       "      <th>...</th>\n",
       "      <th>energy_difference</th>\n",
       "      <th>homogeneity_difference</th>\n",
       "      <th>dissimilarity_difference</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>filename_y</th>\n",
       "      <th>consensus_class_ID_y</th>\n",
       "      <th>consensus_bbox_y</th>\n",
       "      <th>num_annotations</th>\n",
       "      <th>consensus_guesses</th>\n",
       "      <th>correct_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[634.05224609375, 260.4735412597656, 49.0, 80....</td>\n",
       "      <td>0.764205</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>3920.061310</td>\n",
       "      <td>1.100016</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001824</td>\n",
       "      <td>-0.001915</td>\n",
       "      <td>-0.276598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[634.05224609375, 260.4735412597656, 49.0, 80....</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[555.4261474609375, 216.25, 53.0, 69.0]</td>\n",
       "      <td>0.764205</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>3657.000000</td>\n",
       "      <td>1.026198</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003848</td>\n",
       "      <td>-0.008362</td>\n",
       "      <td>0.469213</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[555.4261474609375, 216.25, 53.0, 69.0]</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[266.75, 120.83124542236328, 60.33087158203125...</td>\n",
       "      <td>0.764205</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>5188.454956</td>\n",
       "      <td>1.455943</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002293</td>\n",
       "      <td>-0.003715</td>\n",
       "      <td>-0.649892</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[266.75, 120.83124542236328, 60.33087158203125...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[176.8125, 22.46035385131836, 52.0, 84.0]</td>\n",
       "      <td>0.764205</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>4368.000000</td>\n",
       "      <td>1.225713</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003327</td>\n",
       "      <td>-0.010862</td>\n",
       "      <td>0.759144</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[176.8125, 22.46035385131836, 52.0, 84.0]</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[101.36946105957031, 170.06580352783203, 62.24...</td>\n",
       "      <td>0.721928</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>5135.498171</td>\n",
       "      <td>1.441082</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002831</td>\n",
       "      <td>-0.010425</td>\n",
       "      <td>0.348026</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[101.36946105957031, 170.06580352783203, 62.24...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                       filename_x consensus_class_ID_x  \\\n",
       "0   1  20211201_Atrisco_0459_01_01.png                Goose   \n",
       "1   2  20211201_Atrisco_0459_01_01.png                Goose   \n",
       "2   3  20211201_Atrisco_0459_01_01.png                Goose   \n",
       "3   4  20211201_Atrisco_0459_01_01.png                Goose   \n",
       "4   5  20211201_Atrisco_0459_01_01.png                Goose   \n",
       "\n",
       "                                    consensus_bbox_x  pielou_index  \\\n",
       "0  [634.05224609375, 260.4735412597656, 49.0, 80....      0.764205   \n",
       "1            [555.4261474609375, 216.25, 53.0, 69.0]      0.764205   \n",
       "2  [266.75, 120.83124542236328, 60.33087158203125...      0.764205   \n",
       "3          [176.8125, 22.46035385131836, 52.0, 84.0]      0.764205   \n",
       "4  [101.36946105957031, 170.06580352783203, 62.24...      0.721928   \n",
       "\n",
       "                basefile         area  bbox_percent_area  same_class_percent  \\\n",
       "0  20211201_Atrisco_0459  3920.061310           1.100016               100.0   \n",
       "1  20211201_Atrisco_0459  3657.000000           1.026198               100.0   \n",
       "2  20211201_Atrisco_0459  5188.454956           1.455943               100.0   \n",
       "3  20211201_Atrisco_0459  4368.000000           1.225713               100.0   \n",
       "4  20211201_Atrisco_0459  5135.498171           1.441082               100.0   \n",
       "\n",
       "   num_neighbors  ...  energy_difference  homogeneity_difference  \\\n",
       "0              1  ...          -0.001824               -0.001915   \n",
       "1              1  ...          -0.003848               -0.008362   \n",
       "2              4  ...          -0.002293               -0.003715   \n",
       "3              2  ...          -0.003327               -0.010862   \n",
       "4              1  ...          -0.002831               -0.010425   \n",
       "\n",
       "   dissimilarity_difference  cluster_id                       filename_y  \\\n",
       "0                 -0.276598         0.0  20211201_Atrisco_0459_01_01.png   \n",
       "1                  0.469213         1.0  20211201_Atrisco_0459_01_01.png   \n",
       "2                 -0.649892         2.0  20211201_Atrisco_0459_01_01.png   \n",
       "3                  0.759144         3.0  20211201_Atrisco_0459_01_01.png   \n",
       "4                  0.348026         4.0  20211201_Atrisco_0459_01_01.png   \n",
       "\n",
       "   consensus_class_ID_y                                   consensus_bbox_y  \\\n",
       "0                 Goose  [634.05224609375, 260.4735412597656, 49.0, 80....   \n",
       "1                 Goose            [555.4261474609375, 216.25, 53.0, 69.0]   \n",
       "2                 Goose  [266.75, 120.83124542236328, 60.33087158203125...   \n",
       "3                 Goose          [176.8125, 22.46035385131836, 52.0, 84.0]   \n",
       "4                 Goose  [101.36946105957031, 170.06580352783203, 62.24...   \n",
       "\n",
       "   num_annotations  consensus_guesses  correct_fraction  \n",
       "0              9.0                7.0          0.777778  \n",
       "1              9.0                7.0          0.777778  \n",
       "2              9.0                7.0          0.777778  \n",
       "3              9.0                7.0          0.777778  \n",
       "4             10.0                8.0          0.800000  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge with new file that has the simplified dependent variable\n",
    "import pandas as pd\n",
    "\n",
    "path1 = \"E:\\\\imagefactors\\\\data\\\\crowdsourced_imagefactors.csv\"\n",
    "with open(path1) as f1:\n",
    "  img = pd.read_csv(f1)\n",
    "\n",
    "path2 = \"E:\\\\imagefactors\\\\data\\\\consensusLabels_simple.csv\"\n",
    "with open(path2) as f2:\n",
    "  simple = pd.read_csv(f2)\n",
    "\n",
    "df = pd.merge(img, simple, on=[\"id\"], how=\"left\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>consensus_class_ID</th>\n",
       "      <th>consensus_bbox</th>\n",
       "      <th>pielou_index</th>\n",
       "      <th>basefile</th>\n",
       "      <th>area</th>\n",
       "      <th>bbox_percent_area</th>\n",
       "      <th>same_class_percent</th>\n",
       "      <th>num_neighbors</th>\n",
       "      <th>...</th>\n",
       "      <th>donut_energy</th>\n",
       "      <th>contrast_difference</th>\n",
       "      <th>energy_difference</th>\n",
       "      <th>homogeneity_difference</th>\n",
       "      <th>dissimilarity_difference</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>num_annotations</th>\n",
       "      <th>consensus_guesses</th>\n",
       "      <th>correct_fraction</th>\n",
       "      <th>n-k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[634.05224609375, 260.4735412597656, 49.0, 80....</td>\n",
       "      <td>0.764205</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>3920.061310</td>\n",
       "      <td>1.100016</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014223</td>\n",
       "      <td>-39.452239</td>\n",
       "      <td>-0.001824</td>\n",
       "      <td>-0.001915</td>\n",
       "      <td>-0.276598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[555.4261474609375, 216.25, 53.0, 69.0]</td>\n",
       "      <td>0.764205</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>3657.000000</td>\n",
       "      <td>1.026198</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013212</td>\n",
       "      <td>-8.532524</td>\n",
       "      <td>-0.003848</td>\n",
       "      <td>-0.008362</td>\n",
       "      <td>0.469213</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[266.75, 120.83124542236328, 60.33087158203125...</td>\n",
       "      <td>0.764205</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>5188.454956</td>\n",
       "      <td>1.455943</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012126</td>\n",
       "      <td>-70.957132</td>\n",
       "      <td>-0.002293</td>\n",
       "      <td>-0.003715</td>\n",
       "      <td>-0.649892</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[176.8125, 22.46035385131836, 52.0, 84.0]</td>\n",
       "      <td>0.764205</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>4368.000000</td>\n",
       "      <td>1.225713</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012909</td>\n",
       "      <td>13.280148</td>\n",
       "      <td>-0.003327</td>\n",
       "      <td>-0.010862</td>\n",
       "      <td>0.759144</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[101.36946105957031, 170.06580352783203, 62.24...</td>\n",
       "      <td>0.721928</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>5135.498171</td>\n",
       "      <td>1.441082</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012942</td>\n",
       "      <td>-10.312978</td>\n",
       "      <td>-0.002831</td>\n",
       "      <td>-0.010425</td>\n",
       "      <td>0.348026</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                         filename consensus_class_ID  \\\n",
       "0   1  20211201_Atrisco_0459_01_01.png              Goose   \n",
       "1   2  20211201_Atrisco_0459_01_01.png              Goose   \n",
       "2   3  20211201_Atrisco_0459_01_01.png              Goose   \n",
       "3   4  20211201_Atrisco_0459_01_01.png              Goose   \n",
       "4   5  20211201_Atrisco_0459_01_01.png              Goose   \n",
       "\n",
       "                                      consensus_bbox  pielou_index  \\\n",
       "0  [634.05224609375, 260.4735412597656, 49.0, 80....      0.764205   \n",
       "1            [555.4261474609375, 216.25, 53.0, 69.0]      0.764205   \n",
       "2  [266.75, 120.83124542236328, 60.33087158203125...      0.764205   \n",
       "3          [176.8125, 22.46035385131836, 52.0, 84.0]      0.764205   \n",
       "4  [101.36946105957031, 170.06580352783203, 62.24...      0.721928   \n",
       "\n",
       "                basefile         area  bbox_percent_area  same_class_percent  \\\n",
       "0  20211201_Atrisco_0459  3920.061310           1.100016               100.0   \n",
       "1  20211201_Atrisco_0459  3657.000000           1.026198               100.0   \n",
       "2  20211201_Atrisco_0459  5188.454956           1.455943               100.0   \n",
       "3  20211201_Atrisco_0459  4368.000000           1.225713               100.0   \n",
       "4  20211201_Atrisco_0459  5135.498171           1.441082               100.0   \n",
       "\n",
       "   num_neighbors  ...  donut_energy  contrast_difference  energy_difference  \\\n",
       "0              1  ...      0.014223           -39.452239          -0.001824   \n",
       "1              1  ...      0.013212            -8.532524          -0.003848   \n",
       "2              4  ...      0.012126           -70.957132          -0.002293   \n",
       "3              2  ...      0.012909            13.280148          -0.003327   \n",
       "4              1  ...      0.012942           -10.312978          -0.002831   \n",
       "\n",
       "   homogeneity_difference  dissimilarity_difference  cluster_id  \\\n",
       "0               -0.001915                 -0.276598         0.0   \n",
       "1               -0.008362                  0.469213         1.0   \n",
       "2               -0.003715                 -0.649892         2.0   \n",
       "3               -0.010862                  0.759144         3.0   \n",
       "4               -0.010425                  0.348026         4.0   \n",
       "\n",
       "   num_annotations  consensus_guesses  correct_fraction  n-k  \n",
       "0              9.0                7.0          0.777778  2.0  \n",
       "1              9.0                7.0          0.777778  2.0  \n",
       "2              9.0                7.0          0.777778  2.0  \n",
       "3              9.0                7.0          0.777778  2.0  \n",
       "4             10.0                8.0          0.800000  2.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['consensus_class_ID_y', 'consensus_bbox_y', 'filename_y'], axis=1)\n",
    "df = df.rename(columns={'filename_x': 'filename', 'consensus_class_ID_x': 'consensus_class_ID', 'consensus_bbox_x': 'consensus_bbox'})\n",
    "df['n-k'] = df['num_annotations'] - df['consensus_guesses']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELING IMPACT OF IMAGE FACTORS ON LABELING DIFFICULTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>consensus_class_ID</th>\n",
       "      <th>consensus_bbox</th>\n",
       "      <th>pielou_index</th>\n",
       "      <th>basefile</th>\n",
       "      <th>area</th>\n",
       "      <th>bbox_percent_area</th>\n",
       "      <th>same_class_percent</th>\n",
       "      <th>num_neighbors</th>\n",
       "      <th>...</th>\n",
       "      <th>donut_energy</th>\n",
       "      <th>contrast_difference</th>\n",
       "      <th>energy_difference</th>\n",
       "      <th>homogeneity_difference</th>\n",
       "      <th>dissimilarity_difference</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>num_annotations</th>\n",
       "      <th>consensus_guesses</th>\n",
       "      <th>correct_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[634.05224609375, 260.4735412597656, 49.0, 80....</td>\n",
       "      <td>0.764205</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>3920.061310</td>\n",
       "      <td>1.100016</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014223</td>\n",
       "      <td>-39.452239</td>\n",
       "      <td>-0.001824</td>\n",
       "      <td>-0.001915</td>\n",
       "      <td>-0.276598</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[555.4261474609375, 216.25, 53.0, 69.0]</td>\n",
       "      <td>0.764205</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>3657.000000</td>\n",
       "      <td>1.026198</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013212</td>\n",
       "      <td>-8.532524</td>\n",
       "      <td>-0.003848</td>\n",
       "      <td>-0.008362</td>\n",
       "      <td>0.469213</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[266.75, 120.83124542236328, 60.33087158203125...</td>\n",
       "      <td>0.764205</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>5188.454956</td>\n",
       "      <td>1.455943</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012126</td>\n",
       "      <td>-70.957132</td>\n",
       "      <td>-0.002293</td>\n",
       "      <td>-0.003715</td>\n",
       "      <td>-0.649892</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[176.8125, 22.46035385131836, 52.0, 84.0]</td>\n",
       "      <td>0.764205</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>4368.000000</td>\n",
       "      <td>1.225713</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012909</td>\n",
       "      <td>13.280148</td>\n",
       "      <td>-0.003327</td>\n",
       "      <td>-0.010862</td>\n",
       "      <td>0.759144</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>Goose</td>\n",
       "      <td>[101.36946105957031, 170.06580352783203, 62.24...</td>\n",
       "      <td>0.721928</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>5135.498171</td>\n",
       "      <td>1.441082</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012942</td>\n",
       "      <td>-10.312978</td>\n",
       "      <td>-0.002831</td>\n",
       "      <td>-0.010425</td>\n",
       "      <td>0.348026</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                         filename consensus_class_ID  \\\n",
       "0   1  20211201_Atrisco_0459_01_01.png              Goose   \n",
       "1   2  20211201_Atrisco_0459_01_01.png              Goose   \n",
       "2   3  20211201_Atrisco_0459_01_01.png              Goose   \n",
       "3   4  20211201_Atrisco_0459_01_01.png              Goose   \n",
       "4   5  20211201_Atrisco_0459_01_01.png              Goose   \n",
       "\n",
       "                                      consensus_bbox  pielou_index  \\\n",
       "0  [634.05224609375, 260.4735412597656, 49.0, 80....      0.764205   \n",
       "1            [555.4261474609375, 216.25, 53.0, 69.0]      0.764205   \n",
       "2  [266.75, 120.83124542236328, 60.33087158203125...      0.764205   \n",
       "3          [176.8125, 22.46035385131836, 52.0, 84.0]      0.764205   \n",
       "4  [101.36946105957031, 170.06580352783203, 62.24...      0.721928   \n",
       "\n",
       "                basefile         area  bbox_percent_area  same_class_percent  \\\n",
       "0  20211201_Atrisco_0459  3920.061310           1.100016               100.0   \n",
       "1  20211201_Atrisco_0459  3657.000000           1.026198               100.0   \n",
       "2  20211201_Atrisco_0459  5188.454956           1.455943               100.0   \n",
       "3  20211201_Atrisco_0459  4368.000000           1.225713               100.0   \n",
       "4  20211201_Atrisco_0459  5135.498171           1.441082               100.0   \n",
       "\n",
       "   num_neighbors  ...  donut_energy  contrast_difference  energy_difference  \\\n",
       "0              1  ...      0.014223           -39.452239          -0.001824   \n",
       "1              1  ...      0.013212            -8.532524          -0.003848   \n",
       "2              4  ...      0.012126           -70.957132          -0.002293   \n",
       "3              2  ...      0.012909            13.280148          -0.003327   \n",
       "4              1  ...      0.012942           -10.312978          -0.002831   \n",
       "\n",
       "   homogeneity_difference  dissimilarity_difference  Unnamed: 0  cluster_id  \\\n",
       "0               -0.001915                 -0.276598         1.0         0.0   \n",
       "1               -0.008362                  0.469213         2.0         1.0   \n",
       "2               -0.003715                 -0.649892         3.0         2.0   \n",
       "3               -0.010862                  0.759144         4.0         3.0   \n",
       "4               -0.010425                  0.348026         5.0         4.0   \n",
       "\n",
       "   num_annotations  consensus_guesses  correct_fraction  \n",
       "0              9.0                7.0          0.777778  \n",
       "1              9.0                7.0          0.777778  \n",
       "2              9.0                7.0          0.777778  \n",
       "3              9.0                7.0          0.777778  \n",
       "4             10.0                8.0          0.800000  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge with new file that has the simplified dependent variable\n",
    "import pandas as pd\n",
    "\n",
    "path1 = \"E:\\\\imagefactors\\\\data\\\\crowdsourced_imagefactors.csv\"\n",
    "with open(path1) as f1:\n",
    "  img = pd.read_csv(f1)\n",
    "\n",
    "path2 = \"E:\\\\imagefactors\\\\data\\\\filtered_crowd.csv\"\n",
    "with open(path2) as f2:\n",
    "  simple = pd.read_csv(f2)\n",
    "\n",
    "df = pd.merge(img, simple, on=[\"consensus_bbox\"], how=\"left\")\n",
    "\n",
    "df = df.drop(columns=['consensus_class_ID_y', 'filename_y'], axis=1)\n",
    "df = df.rename(columns={'filename_x': 'filename', 'consensus_class_ID_x': 'consensus_class_ID'})\n",
    "#df['n-k'] = df['num_annotations'] - df['consensus_guesses']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107698"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>consensus_bbox</th>\n",
       "      <th>pielou_index</th>\n",
       "      <th>basefile</th>\n",
       "      <th>area</th>\n",
       "      <th>bbox_percent_area</th>\n",
       "      <th>same_class_percent</th>\n",
       "      <th>num_neighbors</th>\n",
       "      <th>agl</th>\n",
       "      <th>...</th>\n",
       "      <th>homogeneity_difference</th>\n",
       "      <th>dissimilarity_difference</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>num_annotations</th>\n",
       "      <th>consensus_guesses</th>\n",
       "      <th>correct_fraction</th>\n",
       "      <th>class_Crane</th>\n",
       "      <th>class_Duck</th>\n",
       "      <th>class_Goose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>[634.05224609375, 260.4735412597656, 49.0, 80....</td>\n",
       "      <td>0.764205</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>3920.061310</td>\n",
       "      <td>1.100016</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001915</td>\n",
       "      <td>-0.276598</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>[555.4261474609375, 216.25, 53.0, 69.0]</td>\n",
       "      <td>0.764205</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>3657.000000</td>\n",
       "      <td>1.026198</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008362</td>\n",
       "      <td>0.469213</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>[266.75, 120.83124542236328, 60.33087158203125...</td>\n",
       "      <td>0.764205</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>5188.454956</td>\n",
       "      <td>1.455943</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003715</td>\n",
       "      <td>-0.649892</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>[176.8125, 22.46035385131836, 52.0, 84.0]</td>\n",
       "      <td>0.764205</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>4368.000000</td>\n",
       "      <td>1.225713</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010862</td>\n",
       "      <td>0.759144</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20211201_Atrisco_0459_01_01.png</td>\n",
       "      <td>[101.36946105957031, 170.06580352783203, 62.24...</td>\n",
       "      <td>0.721928</td>\n",
       "      <td>20211201_Atrisco_0459</td>\n",
       "      <td>5135.498171</td>\n",
       "      <td>1.441082</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010425</td>\n",
       "      <td>0.348026</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                         filename  \\\n",
       "0   1  20211201_Atrisco_0459_01_01.png   \n",
       "1   2  20211201_Atrisco_0459_01_01.png   \n",
       "2   3  20211201_Atrisco_0459_01_01.png   \n",
       "3   4  20211201_Atrisco_0459_01_01.png   \n",
       "4   5  20211201_Atrisco_0459_01_01.png   \n",
       "\n",
       "                                      consensus_bbox  pielou_index  \\\n",
       "0  [634.05224609375, 260.4735412597656, 49.0, 80....      0.764205   \n",
       "1            [555.4261474609375, 216.25, 53.0, 69.0]      0.764205   \n",
       "2  [266.75, 120.83124542236328, 60.33087158203125...      0.764205   \n",
       "3          [176.8125, 22.46035385131836, 52.0, 84.0]      0.764205   \n",
       "4  [101.36946105957031, 170.06580352783203, 62.24...      0.721928   \n",
       "\n",
       "                basefile         area  bbox_percent_area  same_class_percent  \\\n",
       "0  20211201_Atrisco_0459  3920.061310           1.100016                 100   \n",
       "1  20211201_Atrisco_0459  3657.000000           1.026198                 100   \n",
       "2  20211201_Atrisco_0459  5188.454956           1.455943                 100   \n",
       "3  20211201_Atrisco_0459  4368.000000           1.225713                 100   \n",
       "4  20211201_Atrisco_0459  5135.498171           1.441082                 100   \n",
       "\n",
       "   num_neighbors   agl  ...  homogeneity_difference  dissimilarity_difference  \\\n",
       "0              1  30.0  ...               -0.001915                 -0.276598   \n",
       "1              1  30.0  ...               -0.008362                  0.469213   \n",
       "2              4  30.0  ...               -0.003715                 -0.649892   \n",
       "3              2  30.0  ...               -0.010862                  0.759144   \n",
       "4              1  30.0  ...               -0.010425                  0.348026   \n",
       "\n",
       "   Unnamed: 0  cluster_id  num_annotations  consensus_guesses  \\\n",
       "0         1.0         0.0              9.0                7.0   \n",
       "1         2.0         1.0              9.0                7.0   \n",
       "2         3.0         2.0              9.0                7.0   \n",
       "3         4.0         3.0              9.0                7.0   \n",
       "4         5.0         4.0             10.0                8.0   \n",
       "\n",
       "   correct_fraction  class_Crane  class_Duck  class_Goose  \n",
       "0          0.777778            0           0            1  \n",
       "1          0.777778            0           0            1  \n",
       "2          0.777778            0           0            1  \n",
       "3          0.777778            0           0            1  \n",
       "4          0.800000            0           0            1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dummy variables for class ID\n",
    "data = pd.get_dummies(df, columns=[\"consensus_class_ID\"], prefix=\"class\")\n",
    "for column in data.filter(like='class_'):\n",
    "    data[column] = data[column].astype(int)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['n-k'] = data['num_annotations'] - data['consensus_guesses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save data\n",
    "data.to_csv('E:/imagefactors/data/filtered_crowd_IF.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E:/imagefactors/data/filtered_crowd_IF.csv\"\n",
    "with open(path) as f:\n",
    "  data1 = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Variable       VIF\n",
      "0  bbox_percent_area  5.501058\n",
      "1      num_neighbors  2.441503\n",
      "2            density  2.410602\n",
      "3  energy_difference  1.152246\n",
      "4        class_Crane  3.645609\n",
      "5         class_Duck  3.436611\n",
      "6        class_Goose  1.272057\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Assuming 'data' is your DataFrame with predictor variables\n",
    "predictors = data1[[\n",
    " 'bbox_percent_area',\n",
    " #'same_class_percent',\n",
    " 'num_neighbors',\n",
    " #'agl',\n",
    " #'gsd',\n",
    " #'distance_from_center',\n",
    " 'density',\n",
    " #'bbox_contrast',\n",
    " #'bbox_dissimilarity',\n",
    " #'bbox_homogeneity',\n",
    " #'bbox_energy',\n",
    " #'donut_contrast',\n",
    " #'donut_dissimilarity',\n",
    " #'donut_homogeneity',\n",
    " #'donut_energy',\n",
    " #'contrast_difference',\n",
    " 'energy_difference',\n",
    " #'homogeneity_difference',\n",
    " #'dissimilarity_difference',\n",
    " 'class_Crane',\n",
    " 'class_Duck',\n",
    " 'class_Goose']]\n",
    "\n",
    "# Calculate VIF\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = predictors.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(predictors.values, i) for i in range(predictors.shape[1])]\n",
    "\n",
    "# Display the VIF DataFrame\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Generalized Linear Model Regression Results                       \n",
      "========================================================================================\n",
      "Dep. Variable:     ['consensus_guesses', 'n-k']   No. Observations:               107698\n",
      "Model:                                      GLM   Df Residuals:                   107691\n",
      "Model Family:                          Binomial   Df Model:                            6\n",
      "Link Function:                            Logit   Scale:                          1.0000\n",
      "Method:                                    IRLS   Log-Likelihood:                -95677.\n",
      "Date:                          Wed, 06 Dec 2023   Deviance:                   1.1190e+05\n",
      "Time:                                  08:58:50   Pearson chi2:                 1.20e+05\n",
      "No. Iterations:                               6   Pseudo R-squ. (CS):             0.1738\n",
      "Covariance Type:                      nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "const                 2.3056      0.014    163.707      0.000       2.278       2.333\n",
      "bbox_percent_area     0.2876      0.009     31.019      0.000       0.269       0.306\n",
      "num_neighbors         0.0062      0.004      1.576      0.115      -0.002       0.014\n",
      "density               0.0198      0.001     28.593      0.000       0.018       0.021\n",
      "energy_difference   -13.2221      0.371    -35.596      0.000     -13.950     -12.494\n",
      "class_Goose          -1.3972      0.012   -114.146      0.000      -1.421      -1.373\n",
      "class_Crane          -0.0330      0.015     -2.139      0.032      -0.063      -0.003\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Define the independent variables\n",
    "X = data[['bbox_percent_area', 'num_neighbors', 'density', 'energy_difference',\n",
    "          'class_Goose', 'class_Crane']]\n",
    "\n",
    "# Add a constant term to the independent variables\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Define the response variable\n",
    "y = data[['consensus_guesses', 'n-k']]\n",
    "\n",
    "# Fit logistic regression model\n",
    "model = sm.GLM(y, X, family=sm.families.Binomial()).fit()\n",
    "\n",
    "# Display the model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Variable       VIF\n",
      "0      num_neighbors  2.422707\n",
      "1            density  2.519670\n",
      "2  energy_difference  1.149683\n",
      "3    num_annotations  4.205368\n",
      "4        class_Crane  1.698305\n",
      "5         class_Duck  2.816433\n",
      "6        class_Goose  1.271071\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Assuming 'data' is your DataFrame with predictor variables\n",
    "predictors = data1[[\n",
    " #'bbox_percent_area',\n",
    " #'same_class_percent',\n",
    " 'num_neighbors',\n",
    " #'agl',\n",
    " #'gsd',\n",
    " #'distance_from_center',\n",
    " 'density',\n",
    " #'bbox_contrast',\n",
    " #'bbox_dissimilarity',\n",
    " #'bbox_homogeneity',\n",
    " #'bbox_energy',\n",
    " #'donut_contrast',\n",
    " #'donut_dissimilarity',\n",
    " #'donut_homogeneity',\n",
    " #'donut_energy',\n",
    " #'contrast_difference',\n",
    " 'energy_difference',\n",
    " #'homogeneity_difference',\n",
    " #'dissimilarity_difference',\n",
    " 'num_annotations',\n",
    " 'class_Crane',\n",
    " 'class_Duck',\n",
    " 'class_Goose']]\n",
    " #'class_Seagull']]\n",
    "\n",
    "# Calculate VIF\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = predictors.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(predictors.values, i) for i in range(predictors.shape[1])]\n",
    "\n",
    "# Display the VIF DataFrame\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    n-k   R-squared:                         nan\n",
      "Model:                            OLS   Adj. R-squared:                    nan\n",
      "Method:                 Least Squares   F-statistic:                       nan\n",
      "Date:                Tue, 31 Oct 2023   Prob (F-statistic):                nan\n",
      "Time:                        12:35:13   Log-Likelihood:                    nan\n",
      "No. Observations:              136447   AIC:                               nan\n",
      "Df Residuals:                  136432   BIC:                               nan\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "============================================================================================\n",
      "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------\n",
      "const                           nan        nan        nan        nan         nan         nan\n",
      "gsd                             nan        nan        nan        nan         nan         nan\n",
      "bbox_percent_area               nan        nan        nan        nan         nan         nan\n",
      "same_class_percent              nan        nan        nan        nan         nan         nan\n",
      "num_neighbors                   nan        nan        nan        nan         nan         nan\n",
      "distance_from_center            nan        nan        nan        nan         nan         nan\n",
      "density                         nan        nan        nan        nan         nan         nan\n",
      "contrast_difference             nan        nan        nan        nan         nan         nan\n",
      "energy_difference               nan        nan        nan        nan         nan         nan\n",
      "homogeneity_difference          nan        nan        nan        nan         nan         nan\n",
      "dissimilarity_difference        nan        nan        nan        nan         nan         nan\n",
      "class_Crane                     nan        nan        nan        nan         nan         nan\n",
      "class_Duck                      nan        nan        nan        nan         nan         nan\n",
      "class_Goose                     nan        nan        nan        nan         nan         nan\n",
      "class_Other Bird                nan        nan        nan        nan         nan         nan\n",
      "class_Seagull                   nan        nan        nan        nan         nan         nan\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                     nan\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                  nan\n",
      "Skew:                             nan   Prob(JB):                          nan\n",
      "Kurtosis:                         nan   Cond. No.                     3.12e+17\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.15e-25. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "#Multiple linear regression \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "y = data['n-k']\n",
    "X = data[['gsd', 'bbox_percent_area', 'same_class_percent', 'num_neighbors', 'distance_from_center', 'density', 'contrast_difference', 'energy_difference', 'homogeneity_difference', 'dissimilarity_difference',\n",
    "        'class_Crane', 'class_Duck', 'class_Goose', 'class_Other Bird', 'class_Seagull']]\n",
    "\n",
    "# Add a constant term to the independent variables (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the regression summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\yolo\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:1781: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "c:\\ProgramData\\anaconda3\\envs\\yolo\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Variable        VIF\n",
      "0                      const   0.000000\n",
      "1                        gsd   3.488659\n",
      "2          bbox_percent_area   2.867210\n",
      "3         same_class_percent   1.077093\n",
      "4              num_neighbors   1.385959\n",
      "5       distance_from_center   2.163836\n",
      "6                    density   2.049233\n",
      "7        contrast_difference  19.635931\n",
      "8          energy_difference   4.236287\n",
      "9     homogeneity_difference  12.530935\n",
      "10  dissimilarity_difference  36.395213\n",
      "11               class_Crane        inf\n",
      "12                class_Duck        inf\n",
      "13               class_Goose        inf\n",
      "14          class_Other Bird        inf\n",
      "15             class_Seagull        inf\n"
     ]
    }
   ],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif[\"Variable\"] = X.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gsd', 'distance_from_center'),\n",
       " ('distance_from_center', 'gsd'),\n",
       " ('contrast_difference', 'dissimilarity_difference'),\n",
       " ('energy_difference', 'homogeneity_difference'),\n",
       " ('homogeneity_difference', 'energy_difference'),\n",
       " ('homogeneity_difference', 'dissimilarity_difference'),\n",
       " ('dissimilarity_difference', 'contrast_difference'),\n",
       " ('dissimilarity_difference', 'homogeneity_difference')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix = X.corr()\n",
    "correlated_pairs = [(var1, var2) for var1 in X.columns for var2 in X.columns if var1 != var2 and abs(correlation_matrix.loc[var1, var2]) > 0.7]\n",
    "correlated_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    n-k   R-squared:                         nan\n",
      "Model:                            OLS   Adj. R-squared:                    nan\n",
      "Method:                 Least Squares   F-statistic:                       nan\n",
      "Date:                Tue, 31 Oct 2023   Prob (F-statistic):                nan\n",
      "Time:                        12:40:50   Log-Likelihood:                    nan\n",
      "No. Observations:              136447   AIC:                               nan\n",
      "Df Residuals:                  136435   BIC:                               nan\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                      nan        nan        nan        nan         nan         nan\n",
      "gsd                        nan        nan        nan        nan         nan         nan\n",
      "bbox_percent_area          nan        nan        nan        nan         nan         nan\n",
      "same_class_percent         nan        nan        nan        nan         nan         nan\n",
      "num_neighbors              nan        nan        nan        nan         nan         nan\n",
      "density                    nan        nan        nan        nan         nan         nan\n",
      "contrast_difference        nan        nan        nan        nan         nan         nan\n",
      "energy_difference          nan        nan        nan        nan         nan         nan\n",
      "class_Crane                nan        nan        nan        nan         nan         nan\n",
      "class_Duck                 nan        nan        nan        nan         nan         nan\n",
      "class_Goose                nan        nan        nan        nan         nan         nan\n",
      "class_Other Bird           nan        nan        nan        nan         nan         nan\n",
      "class_Seagull              nan        nan        nan        nan         nan         nan\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                     nan\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                  nan\n",
      "Skew:                             nan   Prob(JB):                          nan\n",
      "Kurtosis:                         nan   Cond. No.                     3.69e+17\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 8.25e-26. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "#Multiple linear regression \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "y = data['n-k']\n",
    "X = data[['gsd', 'bbox_percent_area', 'same_class_percent', 'num_neighbors', 'density', 'contrast_difference', 'energy_difference',\n",
    "        'class_Crane', 'class_Duck', 'class_Goose', 'class_Other Bird', 'class_Seagull']]\n",
    "\n",
    "# Add a constant term to the independent variables (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the regression summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    n-k   R-squared:                         nan\n",
      "Model:                            OLS   Adj. R-squared:                    nan\n",
      "Method:                 Least Squares   F-statistic:                       nan\n",
      "Date:                Thu, 02 Nov 2023   Prob (F-statistic):                nan\n",
      "Time:                        12:47:40   Log-Likelihood:                    nan\n",
      "No. Observations:              136447   AIC:                               nan\n",
      "Df Residuals:                  136432   BIC:                               nan\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "============================================================================================\n",
      "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------\n",
      "const                           nan        nan        nan        nan         nan         nan\n",
      "gsd                             nan        nan        nan        nan         nan         nan\n",
      "bbox_percent_area               nan        nan        nan        nan         nan         nan\n",
      "same_class_percent              nan        nan        nan        nan         nan         nan\n",
      "num_neighbors                   nan        nan        nan        nan         nan         nan\n",
      "distance_from_center            nan        nan        nan        nan         nan         nan\n",
      "density                         nan        nan        nan        nan         nan         nan\n",
      "contrast_difference             nan        nan        nan        nan         nan         nan\n",
      "energy_difference               nan        nan        nan        nan         nan         nan\n",
      "homogeneity_difference          nan        nan        nan        nan         nan         nan\n",
      "dissimilarity_difference        nan        nan        nan        nan         nan         nan\n",
      "class_Crane                     nan        nan        nan        nan         nan         nan\n",
      "class_Duck                      nan        nan        nan        nan         nan         nan\n",
      "class_Goose                     nan        nan        nan        nan         nan         nan\n",
      "class_Seagull                   nan        nan        nan        nan         nan         nan\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                     nan\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                  nan\n",
      "Skew:                             nan   Prob(JB):                          nan\n",
      "Kurtosis:                         nan   Cond. No.                     6.16e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 6.16e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "#Multiple linear regression \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "y = data['n-k']\n",
    "X = data[['gsd', 'bbox_percent_area', 'same_class_percent', 'num_neighbors', 'distance_from_center', 'density', 'contrast_difference', 'energy_difference', 'homogeneity_difference', 'dissimilarity_difference',\n",
    "        'class_Crane', 'class_Duck', 'class_Goose', 'class_Seagull']]\n",
    "\n",
    "# Add a constant term to the independent variables (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the regression summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISUALIZATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot with regression lines\n",
    "sns.pairplot(df, x_vars=['gsd', 'bbox_percent_area', 'same_class_percent', 'num_neighbors', 'distance_from_center', 'density'], y_vars=['pielou_index'], kind='reg', height=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample visualization of donut + bounding boxes just to make sure it all looks good\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "def visualize_bounding_boxes_with_donuts(image_path, csv_file):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB\n",
    "    \n",
    "    # Read the CSV file\n",
    "    csv_data = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Find the corresponding image filename\n",
    "    image_filename = os.path.basename(image_path)\n",
    "    \n",
    "    # Filter annotations based on the image filename\n",
    "    annotations = csv_data[csv_data['filename'] == image_filename]\n",
    "    \n",
    "    # Plot the image with bounding boxes and donut regions\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Iterate through annotations and draw bounding boxes and donut regions\n",
    "    for _, row in annotations.iterrows():\n",
    "        bbox = ast.literal_eval(row['consensus_bbox'])  # Parse bbox values from string to list\n",
    "        \n",
    "        # Draw bounding box\n",
    "        rectangle = Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rectangle)\n",
    "        \n",
    "        # Draw donut region\n",
    "        donut_left = max(0, bbox[0] - 20)  # Adjust the buffer size as needed\n",
    "        donut_top = max(0, bbox[1] - 20)\n",
    "        donut_right = min(image.shape[1], bbox[0] + bbox[2] + 20)\n",
    "        donut_bottom = min(image.shape[0], bbox[1] + bbox[3] + 20)\n",
    "        donut_rectangle = Rectangle((donut_left, donut_top), (donut_right - donut_left),\n",
    "                                   (donut_bottom - donut_top), linewidth=1, edgecolor='g', facecolor='none')\n",
    "        ax.add_patch(donut_rectangle)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "image_path = 'E:\\\\imagefactors\\\\data\\\\zooniverse\\\\20211201_Atrisco_0459_01_01.png'\n",
    "csv_file = path\n",
    "\n",
    "visualize_bounding_boxes_with_donuts(image_path, csv_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEXTURE METRICS-- GCLM\n",
    "# annotation + \"donut\" area (interior + exterior buffer)-- SINGLE IMAGE ONLY\n",
    "\n",
    "def calculate_gclm_derivatives(image, bbox):\n",
    "    # Convert bounding box coordinates to integers\n",
    "    x, y, width, height = map(int, bbox)\n",
    "    \n",
    "    # Extract the region of interest (ROI) from the image using the bounding box\n",
    "    roi = image[y:y+height, x:x+width]\n",
    "    \n",
    "    # Convert the ROI to grayscale\n",
    "    roi_gray = cv2.cvtColor(roi, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Calculate GCLM features for the grayscale ROI\n",
    "    distances = [1, 2]  # Define the distances for GCLM\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]  # Define the angles for GCLM\n",
    "    gclm = graycomatrix(roi_gray, distances=distances, angles=angles, levels=256,\n",
    "                        symmetric=True, normed=True)\n",
    "    \n",
    "    # Calculate GCLM derivatives (contrast, dissimilarity, homogeneity, energy)\n",
    "    contrast = graycoprops(gclm, 'contrast').mean()\n",
    "    dissimilarity = graycoprops(gclm, 'dissimilarity').mean()\n",
    "    homogeneity = graycoprops(gclm, 'homogeneity').mean()\n",
    "    energy = graycoprops(gclm, 'energy').mean()\n",
    "    \n",
    "    return contrast, dissimilarity, homogeneity, energy\n",
    "\n",
    "def calculate_texture_metrics_for_csv(image_path, csv_file):\n",
    "        # Load the image\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        # Read the CSV file\n",
    "        csv_data = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Find the corresponding image filename\n",
    "        image_filename = os.path.basename(image_path)\n",
    "        \n",
    "        # Filter annotations based on the image filename\n",
    "        annotations = csv_data[csv_data['filename'] == image_filename]\n",
    "        \n",
    "        # Initialize lists to store the texture metrics\n",
    "        bbox_contrast_list = []\n",
    "        bbox_dissimilarity_list = []\n",
    "        bbox_homogeneity_list = []\n",
    "        bbox_energy_list = []\n",
    "        donut_contrast_list = []\n",
    "        donut_dissimilarity_list = []\n",
    "        donut_homogeneity_list = []\n",
    "        donut_energy_list = []\n",
    "        \n",
    "        # Iterate through annotations and calculate texture metrics\n",
    "        for _, row in annotations.iterrows():\n",
    "            bbox = ast.literal_eval(row['consensus_bbox'])  # Parse bbox values from string to list\n",
    "            \n",
    "            # Calculate GCLM derivatives for bounding box and donut region\n",
    "            bbox_contrast, bbox_dissimilarity, bbox_homogeneity, bbox_energy = calculate_gclm_derivatives(image, bbox)\n",
    "            \n",
    "            donut_left = max(0, bbox[0] - 20)  # Adjust the buffer size as needed\n",
    "            donut_top = max(0, bbox[1] - 20)\n",
    "            donut_right = min(image.shape[1], bbox[0] + bbox[2] + 20)\n",
    "            donut_bottom = min(image.shape[0], bbox[1] + bbox[3] + 20)\n",
    "            donut_bbox = [donut_left, donut_top, donut_right - donut_left, donut_bottom - donut_top]\n",
    "            donut_contrast, donut_dissimilarity, donut_homogeneity, donut_energy = calculate_gclm_derivatives(image, donut_bbox)\n",
    "            \n",
    "            # Append the calculated texture metrics to the lists\n",
    "            bbox_contrast_list.append(bbox_contrast)\n",
    "            bbox_dissimilarity_list.append(bbox_dissimilarity)\n",
    "            bbox_homogeneity_list.append(bbox_homogeneity)\n",
    "            bbox_energy_list.append(bbox_energy)\n",
    "            \n",
    "            donut_contrast_list.append(donut_contrast)\n",
    "            donut_dissimilarity_list.append(donut_dissimilarity)\n",
    "            donut_homogeneity_list.append(donut_homogeneity)\n",
    "            donut_energy_list.append(donut_energy)\n",
    "        \n",
    "        # Add texture metrics as new columns in the dataframe\n",
    "        annotations['bbox_contrast'] = bbox_contrast_list\n",
    "        annotations['bbox_dissimilarity'] = bbox_dissimilarity_list\n",
    "        annotations['bbox_homogeneity'] = bbox_homogeneity_list\n",
    "        annotations['bbox_energy'] = bbox_energy_list\n",
    "        \n",
    "        annotations['donut_contrast'] = donut_contrast_list\n",
    "        annotations['donut_dissimilarity'] = donut_dissimilarity_list\n",
    "        annotations['donut_homogeneity'] = donut_homogeneity_list\n",
    "        annotations['donut_energy'] = donut_energy_list\n",
    "        \n",
    "        # Save the modified dataframe if needed\n",
    "        annotations.to_csv('E:\\\\imagefactors\\\\data\\\\gclm.csv', index=False)\n",
    "    \n",
    "# Example usage\n",
    "image_path = 'E:\\\\imagefactors\\\\data\\\\zooniverse\\\\20211212_Alameda_0285_07_08.png'\n",
    "csv_file = path  # Replace with the actual path to your CSV file containing the annotations\n",
    "\n",
    "calculate_texture_metrics_for_csv(image_path, csv_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dronesforducks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
