{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of image factors on annotation consensus-- USFWS\n",
    "Start date: 10/03/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis annotations\n",
    "path = \"E:\\\\imagefactors\\\\data\\\\expertconsensusLabels_agreementIndex_Superclass.csv\"\n",
    "with open(path) as f:\n",
    "  df = pd.read_csv(f)\n",
    "\n",
    "#path = \"E:\\\\imagefactors\\\\data\\\\expertconsensusLabels_agreementIndex_Spp.csv\"\n",
    "#with open(path) as f:\n",
    "#  df = pd.read_csv(f)\n",
    "\n",
    "def eval_bbox_refined(row):\n",
    "    if pd.notnull(row['bbox']):\n",
    "        return ast.literal_eval(row['bbox'])\n",
    "    else:\n",
    "        return None\n",
    "df['bbox'] = df.apply(eval_bbox_refined, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IF RESUMING FROM A SAVED POINT\n",
    "#path = \"E:/imagefactors/data/expert_imagefactors_superclass.csv\"\n",
    "#with open(path) as f:\n",
    "#  df = pd.read_csv(f)\n",
    "  \n",
    "path = \"E:/imagefactors/data/expert_imagefactors_SPP.csv\"\n",
    "with open(path) as f:\n",
    "  df = pd.read_csv(f)\n",
    "\n",
    "#Fixing how bounding boxes are read\n",
    "def eval_bbox_refined(row):\n",
    "    if pd.notnull(row['bbox']):\n",
    "        return ast.literal_eval(row['bbox'])\n",
    "    else:\n",
    "        return None\n",
    "df['bbox'] = df.apply(eval_bbox_refined, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DERIVE IMAGE/ANNOTATION FACTORS FOR ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BBOX AREA\n",
    "\n",
    "def calc_area(row):\n",
    "    bbox = row['bbox']\n",
    "    xmin, ymin, w, h = bbox\n",
    "    return w * h\n",
    "\n",
    "df['area'] = df.apply(calc_area, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % AREA BBOX\n",
    "# Percent area of the bounding box of the total image area\n",
    "\n",
    "# Define a function to calculate percentage area\n",
    "def calculate_percentage_area(image_filename, bbox_area):\n",
    "    image_path = os.path.join(\"E:\\\\imagefactors\\\\data\\\\usfws\", image_filename)\n",
    "    \n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "    except FileNotFoundError:\n",
    "        # Handle the case where the image is not found\n",
    "        print(f\"Image not found: {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    image_width, image_height = image.size\n",
    "    image_area = image_width * image_height\n",
    "\n",
    "    percentage_area = (bbox_area / image_area) * 100\n",
    "    return percentage_area\n",
    "\n",
    "# Implementation\n",
    "df['bbox_percent_area'] = df.apply(lambda row: calculate_percentage_area(row['filename'], row['area']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAME CLASS %\n",
    "# % of targets of the same class as the analysis target (in the same image)\n",
    "\n",
    "# Define a function to calculate the percentage of same-class neighbors for a given row\n",
    "def calculate_same_class_percentage(row, df):\n",
    "    # Get the filename and class ID of the target bounding box\n",
    "    filename = row['filename']\n",
    "    class_id = row['consensus_class_ID']\n",
    "    \n",
    "    # Filter the DataFrame to include only rows with matching filenames\n",
    "    matching_rows = df[df['filename'] == filename]\n",
    "    \n",
    "    # Calculate the total number of neighbors in the same image\n",
    "    total_neighbors = len(matching_rows) - 1  # Subtract 1 to exclude the target bounding box\n",
    "    \n",
    "    if total_neighbors == 0:\n",
    "        return 0  # Avoid division by zero\n",
    "    \n",
    "    # Calculate the number of same-class neighbors\n",
    "    same_class_neighbors = len(matching_rows[matching_rows['consensus_class_ID'] == class_id]) - 1  # Subtract 1 to exclude the target bounding box\n",
    "    \n",
    "    # Calculate the percentage of same-class neighbors\n",
    "    same_class_percentage = (same_class_neighbors / total_neighbors) * 100\n",
    "    \n",
    "    return same_class_percentage\n",
    "\n",
    "# Calculate the same-class percentage for each row and add the results as a new column\n",
    "df['same_class_percent'] = df.apply(lambda row: calculate_same_class_percentage(row, df), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUMBER OF NEIGHBORS \n",
    "# Number of annotations within 2x maximum of bbox width or height (to account for positional differences)\n",
    "\n",
    "# Define a function to calculate the number of neighbors for a given row\n",
    "def count_neighbors(row, df):\n",
    "    bbox = row['bbox']\n",
    "    # Define the search radius as 2 times the maximum of width and height\n",
    "    search_radius = 2 * max(bbox[2], bbox[3])\n",
    "    \n",
    "    # Calculate the center coordinates of the bounding box\n",
    "    x_center = bbox[0] + bbox[2] / 2\n",
    "    y_center = bbox[1] + bbox[3] / 2\n",
    "    \n",
    "    # Initialize a count for neighbors\n",
    "    num_neighbors = 0\n",
    "    \n",
    "    # Iterate through rows with matching filenames\n",
    "    matching_rows = df[df['filename'] == row['filename']]\n",
    "    for _, neighbor_row in matching_rows.iterrows():\n",
    "        if neighbor_row.name != row.name:\n",
    "            # Extract 'bbox' values for the neighbor\n",
    "            neighbor_bbox = neighbor_row['bbox']\n",
    "            \n",
    "            # Calculate the center coordinates of the potential neighbor\n",
    "            neighbor_x_center = neighbor_bbox[0] + neighbor_bbox[2] / 2\n",
    "            neighbor_y_center = neighbor_bbox[1] + neighbor_bbox[3] / 2\n",
    "            \n",
    "            # Calculate the Euclidean distance between centers\n",
    "            distance = np.sqrt((x_center - neighbor_x_center)**2 + (y_center - neighbor_y_center)**2)\n",
    "            \n",
    "            # Check if the neighbor is within the search radius\n",
    "            if distance <= search_radius:\n",
    "                num_neighbors += 1\n",
    "    \n",
    "    return num_neighbors\n",
    "\n",
    "# Calculate the number of neighbors for each row and add the results as a new column\n",
    "df['num_neighbors'] = df.apply(lambda row: count_neighbors(row, df), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOTAL NUMBER OF BIRDS PER IMAGE\n",
    "df['density'] = df.groupby('filename')['bbox'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OVERALL CLASS PREVALENCE IN THE DATASET-- SPP only\n",
    "\n",
    "class_counts = df['consensus_class_ID'].value_counts()\n",
    "class_prevalence = (class_counts / len(df)) * 100\n",
    "df['rarity'] = df['consensus_class_ID'].map(class_prevalence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISTANCE OF TARGET FROM IMAGE CENTER-- in meters\n",
    "\n",
    "#Add in AGL/GSD info derived from derive_agl_gsd.ipynb\n",
    "path1 = \"E:\\\\imagefactors\\\\data\\\\benchmark_gsd.csv\"\n",
    "with open(path1) as f1:\n",
    "  gsd_df = pd.read_csv(f1)\n",
    "\n",
    "merged_df = pd.merge(df, gsd_df, on=\"filename\", how=\"left\")\n",
    "#Remove Maxwell from analysis\n",
    "merged_df = merged_df[merged_df[\"filename\"] != \"mxw_L13_20181215_1.JPG\"]\n",
    "\n",
    "# Function to calculate distance from center\n",
    "def calculate_distance_from_center(row):\n",
    "    image_path = os.path.join(\"E:\\\\imagefactors\\\\data\\\\usfws\", row[\"filename\"])\n",
    "    \n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "    except FileNotFoundError:\n",
    "        # Handle the case where the image is not found\n",
    "        print(f\"Image not found: {image_path}\")\n",
    "        return None  # You can return a special value, such as None, to indicate the image wasn't found\n",
    "    \n",
    "    image_width, image_height = image.size\n",
    "    center_x_px = image_width/2 \n",
    "    center_y_px = image_height/2\n",
    "    gsd_m = row['gsd'] / 100\n",
    "\n",
    "    row['center_x_m'] = center_x_px * gsd_m\n",
    "    row['center_y_m'] = center_y_px * gsd_m\n",
    "    \n",
    "    # Get the coordinates of the bounding box (x, y, width, height)\n",
    "    x, y, width, height = row['bbox']\n",
    "\n",
    "    # Calculate the center point of the bounding box in pixels\n",
    "    bbox_center_x_px = x + (width / 2)\n",
    "    bbox_center_y_px = y + (height / 2)\n",
    "\n",
    "    # Calculate the center point of the bounding box in meters\n",
    "    bbox_center_x_m = bbox_center_x_px * gsd_m\n",
    "    bbox_center_y_m = bbox_center_y_px * gsd_m\n",
    "\n",
    "    # Calculate the distance from the center of the image in meters\n",
    "    distance_m = ((row['center_x_m'] - bbox_center_x_m)**2 + (row['center_y_m'] - bbox_center_y_m)**2)**0.5\n",
    "\n",
    "    return distance_m\n",
    "\n",
    "# Apply the function to the merged dataframe\n",
    "merged_df['distance_from_center'] = merged_df.apply(calculate_distance_from_center, axis=1)\n",
    "df = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEXTURE METRICS-- GCLM\n",
    "# annotation + \"donut\" area (interior + exterior buffer)\n",
    "\n",
    "def calculate_gclm_derivatives(image, bbox):\n",
    "    # Convert bounding box coordinates to integers\n",
    "    x, y, width, height = map(int, bbox)\n",
    "    \n",
    "    # Extract the region of interest (ROI) from the image using the bounding box\n",
    "    roi = image[y:y+height, x:x+width]\n",
    "    \n",
    "    # Check if the ROI is empty or None\n",
    "    if roi is None or roi.size == 0:\n",
    "        print(\"Warning: ROI is empty or None\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # Convert the ROI to grayscale\n",
    "    roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate GCLM features for the grayscale ROI\n",
    "    distances = [1, 3, 5]  # Define the distances for GCLM\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4, np.pi/8, 3*np.pi/8, 5*np.pi/8, 7*np.pi/8]  # Define the angles for GCLM\n",
    "    gclm = graycomatrix(roi_gray, distances=distances, angles=angles, levels=256,\n",
    "                        symmetric=True, normed=True)\n",
    "    \n",
    "    # Calculate GCLM derivatives (contrast, dissimilarity, homogeneity, energy)\n",
    "    contrast = graycoprops(gclm, 'contrast').mean()\n",
    "    dissimilarity = graycoprops(gclm, 'dissimilarity').mean()\n",
    "    homogeneity = graycoprops(gclm, 'homogeneity').mean()\n",
    "    energy = graycoprops(gclm, 'energy').mean()\n",
    "    \n",
    "    return contrast, dissimilarity, homogeneity, energy\n",
    "\n",
    "def calculate_texture_metrics_for_directory(image_dir, csv_file):\n",
    "    # Initialize an empty dataframe to store the texture metrics\n",
    "    texture_metrics_df = pd.DataFrame()\n",
    "    \n",
    "    # List all files in the specified directory\n",
    "    image_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        try:\n",
    "            # Construct the full path to the image file\n",
    "            image_path = os.path.join(image_dir, image_file)\n",
    "            \n",
    "            # Load the image\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            if image is None:\n",
    "                print(f\"Warning: Image '{image_path}' not found or cannot be loaded.\")\n",
    "                continue\n",
    "            \n",
    "            # Read the CSV file\n",
    "            csv_data = pd.read_csv(csv_file)\n",
    "            \n",
    "            # Find the corresponding image filename\n",
    "            image_filename = os.path.basename(image_path)\n",
    "            \n",
    "            # Filter annotations based on the image filename\n",
    "            annotations = csv_data[csv_data['filename'] == image_filename]\n",
    "            \n",
    "            # Initialize lists to store the texture metrics\n",
    "            bbox_contrast_list = []\n",
    "            bbox_dissimilarity_list = []\n",
    "            bbox_homogeneity_list = []\n",
    "            bbox_energy_list = []\n",
    "            donut_contrast_list = []\n",
    "            donut_dissimilarity_list = []\n",
    "            donut_homogeneity_list = []\n",
    "            donut_energy_list = []\n",
    "            \n",
    "            # Iterate through annotations and calculate texture metrics\n",
    "            for _, row in annotations.iterrows():\n",
    "                bbox = ast.literal_eval(row['bbox'])  # Parse bbox values from string to list\n",
    "                \n",
    "                # Calculate GCLM derivatives for bounding box and donut region\n",
    "                bbox_contrast, bbox_dissimilarity, bbox_homogeneity, bbox_energy = calculate_gclm_derivatives(image, bbox)\n",
    "                \n",
    "                donut_left = max(0, bbox[0] - 20)  # Adjust the buffer size as needed\n",
    "                donut_top = max(0, bbox[1] - 20)\n",
    "                donut_right = min(image.shape[1], bbox[0] + bbox[2] + 20)\n",
    "                donut_bottom = min(image.shape[0], bbox[1] + bbox[3] + 20)\n",
    "                donut_bbox = [donut_left, donut_top, donut_right - donut_left, donut_bottom - donut_top]\n",
    "                donut_contrast, donut_dissimilarity, donut_homogeneity, donut_energy = calculate_gclm_derivatives(image, donut_bbox)\n",
    "                \n",
    "                # Append the calculated texture metrics to the lists\n",
    "                bbox_contrast_list.append(bbox_contrast)\n",
    "                bbox_dissimilarity_list.append(bbox_dissimilarity)\n",
    "                bbox_homogeneity_list.append(bbox_homogeneity)\n",
    "                bbox_energy_list.append(bbox_energy)\n",
    "                \n",
    "                donut_contrast_list.append(donut_contrast)\n",
    "                donut_dissimilarity_list.append(donut_dissimilarity)\n",
    "                donut_homogeneity_list.append(donut_homogeneity)\n",
    "                donut_energy_list.append(donut_energy)\n",
    "            \n",
    "            # Add texture metrics as columns to a temporary dataframe\n",
    "            temp_df = pd.DataFrame({\n",
    "                'ID': annotations[\"Unnamed: 0\"],\n",
    "                'filename': [image_filename] * len(annotations),\n",
    "                'bbox_contrast': bbox_contrast_list,\n",
    "                'bbox_dissimilarity': bbox_dissimilarity_list,\n",
    "                'bbox_homogeneity': bbox_homogeneity_list,\n",
    "                'bbox_energy': bbox_energy_list,\n",
    "                'donut_contrast': donut_contrast_list,\n",
    "                'donut_dissimilarity': donut_dissimilarity_list,\n",
    "                'donut_homogeneity': donut_homogeneity_list,\n",
    "                'donut_energy': donut_energy_list\n",
    "            })\n",
    "            \n",
    "            # Append the temporary dataframe to the main dataframe\n",
    "            texture_metrics_df = pd.concat([texture_metrics_df, temp_df], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image '{image_path}': {e}\")\n",
    "    \n",
    "    # Save the main dataframe with texture metrics to a CSV file\n",
    "    texture_metrics_df.to_csv('E:\\\\imagefactors\\\\data\\\\gclm_usfws_135_8angles.csv', index=False)\n",
    "\n",
    "# Example usage with a directory containing images\n",
    "image_dir = 'E:\\\\imagefactors\\\\data\\\\usfws'\n",
    "csv_file = path  # Replace with the actual path to your CSV file containing the annotations\n",
    "\n",
    "calculate_texture_metrics_for_directory(image_dir, csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same as above, but using a PCA as the base instead of the greyscale image\n",
    "\n",
    "# Modify the function to calculate texture metrics based on PCA\n",
    "def calculate_pca_texture_metrics(image, bbox):\n",
    "    # Convert bounding box coordinates to integers\n",
    "    x, y, width, height = map(int, bbox)\n",
    "    \n",
    "    # Extract the region of interest (ROI) from the image using the bounding box\n",
    "    roi = image[y:y+height, x:x+width]\n",
    "    \n",
    "    # Check if the ROI is empty or None\n",
    "    if roi is None or roi.size == 0:\n",
    "        print(\"Warning: ROI is empty or None\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # Convert the ROI to grayscale\n",
    "    roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Perform PCA on the grayscale ROI\n",
    "    pca = PCA(n_components=3)  # Choose the number of components you want to use\n",
    "    roi_pca = pca.fit_transform(roi_gray)\n",
    "\n",
    "    # Convert the PCA-transformed ROI to unsigned integer type\n",
    "    roi_pca = roi_pca.astype(np.uint8)\n",
    "    \n",
    "    # Calculate GCLM features for the PCA-transformed ROI\n",
    "    distances = [1, 2]  # Define the distances for GCLM\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]  # Define the angles for GCLM\n",
    "    gclm = graycomatrix(roi_pca, distances=distances, angles=angles, levels=256,\n",
    "                        symmetric=True, normed=True)\n",
    "    \n",
    "    # Calculate GCLM derivatives (contrast, dissimilarity, homogeneity, energy)\n",
    "    contrast = graycoprops(gclm, 'contrast').mean()\n",
    "    dissimilarity = graycoprops(gclm, 'dissimilarity').mean()\n",
    "    homogeneity = graycoprops(gclm, 'homogeneity').mean()\n",
    "    energy = graycoprops(gclm, 'energy').mean()\n",
    "    \n",
    "    return contrast, dissimilarity, homogeneity, energy\n",
    "\n",
    "# Modify the function to use the new texture metrics calculation function\n",
    "def calculate_texture_metrics_for_directory_pca(image_dir, csv_file):\n",
    "    # Initialize an empty dataframe to store the texture metrics\n",
    "    texture_metrics_df = pd.DataFrame()\n",
    "    \n",
    "    # List all files in the specified directory\n",
    "    image_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        try:\n",
    "            # Construct the full path to the image file\n",
    "            image_path = os.path.join(image_dir, image_file)\n",
    "            \n",
    "            # Load the image\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            if image is None:\n",
    "                print(f\"Warning: Image '{image_path}' not found or cannot be loaded.\")\n",
    "                continue\n",
    "            \n",
    "            # Read the CSV file\n",
    "            csv_data = pd.read_csv(csv_file)\n",
    "            \n",
    "            # Find the corresponding image filename\n",
    "            image_filename = os.path.basename(image_path)\n",
    "            \n",
    "            # Filter annotations based on the image filename\n",
    "            annotations = csv_data[csv_data['filename'] == image_filename]\n",
    "            \n",
    "            # Initialize lists to store the texture metrics\n",
    "            bbox_contrast_list = []\n",
    "            bbox_dissimilarity_list = []\n",
    "            bbox_homogeneity_list = []\n",
    "            bbox_energy_list = []\n",
    "            donut_contrast_list = []\n",
    "            donut_dissimilarity_list = []\n",
    "            donut_homogeneity_list = []\n",
    "            donut_energy_list = []\n",
    "            \n",
    "            # Iterate through annotations and calculate texture metrics\n",
    "            for _, row in annotations.iterrows():\n",
    "                bbox = ast.literal_eval(row['bbox'])  # Parse bbox values from string to list\n",
    "                \n",
    "                # Calculate GCLM derivatives for bounding box and donut region\n",
    "                bbox_contrast, bbox_dissimilarity, bbox_homogeneity, bbox_energy = calculate_pca_texture_metrics(image, bbox)\n",
    "                \n",
    "                donut_left = max(0, bbox[0] - 20)  # Adjust the buffer size as needed\n",
    "                donut_top = max(0, bbox[1] - 20)\n",
    "                donut_right = min(image.shape[1], bbox[0] + bbox[2] + 20)\n",
    "                donut_bottom = min(image.shape[0], bbox[1] + bbox[3] + 20)\n",
    "                donut_bbox = [donut_left, donut_top, donut_right - donut_left, donut_bottom - donut_top]\n",
    "                donut_contrast, donut_dissimilarity, donut_homogeneity, donut_energy = calculate_pca_texture_metrics(image, donut_bbox)\n",
    "                \n",
    "                # Append the calculated texture metrics to the lists\n",
    "                bbox_contrast_list.append(bbox_contrast)\n",
    "                bbox_dissimilarity_list.append(bbox_dissimilarity)\n",
    "                bbox_homogeneity_list.append(bbox_homogeneity)\n",
    "                bbox_energy_list.append(bbox_energy)\n",
    "                \n",
    "                donut_contrast_list.append(donut_contrast)\n",
    "                donut_dissimilarity_list.append(donut_dissimilarity)\n",
    "                donut_homogeneity_list.append(donut_homogeneity)\n",
    "                donut_energy_list.append(donut_energy)\n",
    "            \n",
    "            # Add texture metrics as columns to a temporary dataframe\n",
    "            temp_df = pd.DataFrame({\n",
    "                'ID': annotations[\"Unnamed: 0\"],\n",
    "                'filename': [image_filename] * len(annotations),\n",
    "                'bbox_contrast': bbox_contrast_list,\n",
    "                'bbox_dissimilarity': bbox_dissimilarity_list,\n",
    "                'bbox_homogeneity': bbox_homogeneity_list,\n",
    "                'bbox_energy': bbox_energy_list,\n",
    "                'donut_contrast': donut_contrast_list,\n",
    "                'donut_dissimilarity': donut_dissimilarity_list,\n",
    "                'donut_homogeneity': donut_homogeneity_list,\n",
    "                'donut_energy': donut_energy_list\n",
    "            })\n",
    "            \n",
    "            # Append the temporary dataframe to the main dataframe\n",
    "            texture_metrics_df = pd.concat([texture_metrics_df, temp_df], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image '{image_path}': {e}\")\n",
    "    \n",
    "    # Save the main dataframe with texture metrics to a CSV file\n",
    "    texture_metrics_df.to_csv('E:\\\\imagefactors\\\\data\\\\gclm_usfws_pca.csv', index=False)\n",
    "\n",
    "# Example usage with a directory containing images\n",
    "image_dir = 'E:\\\\imagefactors\\\\data\\\\usfws'\n",
    "csv_file = path  # Replace with the actual path to your CSV file containing the annotations\n",
    "\n",
    "calculate_texture_metrics_for_directory_pca(image_dir, csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same as above-- but calculate only on one band \n",
    "\n",
    "# Modify the function to calculate texture metrics based on a specific band\n",
    "def calculate_band_texture_metrics(image, bbox, band):\n",
    "    # Convert bounding box coordinates to integers\n",
    "    x, y, width, height = map(int, bbox)\n",
    "    \n",
    "    # Extract the region of interest (ROI) from the image using the bounding box\n",
    "    roi = image[y:y+height, x:x+width, band]\n",
    "    \n",
    "    # Check if the ROI is empty or None\n",
    "    if roi is None or roi.size == 0:\n",
    "        print(\"Warning: ROI is empty or None\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # Calculate GCLM features for the grayscale ROI\n",
    "    distances = [1, 2]  # Define the distances for GCLM\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]  # Define the angles for GCLM\n",
    "    gclm = graycomatrix(roi, distances=distances, angles=angles, levels=256,\n",
    "                        symmetric=True, normed=True)\n",
    "    \n",
    "    # Calculate GCLM derivatives (contrast, dissimilarity, homogeneity, energy)\n",
    "    contrast = graycoprops(gclm, 'contrast').mean()\n",
    "    dissimilarity = graycoprops(gclm, 'dissimilarity').mean()\n",
    "    homogeneity = graycoprops(gclm, 'homogeneity').mean()\n",
    "    energy = graycoprops(gclm, 'energy').mean()\n",
    "    \n",
    "    return contrast, dissimilarity, homogeneity, energy\n",
    "\n",
    "# Modify the function to use the new texture metrics calculation function\n",
    "def calculate_texture_metrics_for_directory_band(image_dir, csv_file, band):\n",
    "    # Initialize an empty dataframe to store the texture metrics\n",
    "    texture_metrics_df = pd.DataFrame()\n",
    "    \n",
    "    # List all files in the specified directory\n",
    "    image_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        try:\n",
    "            # Construct the full path to the image file\n",
    "            image_path = os.path.join(image_dir, image_file)\n",
    "            \n",
    "            # Load the image\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            if image is None:\n",
    "                print(f\"Warning: Image '{image_path}' not found or cannot be loaded.\")\n",
    "                continue\n",
    "            \n",
    "            # Read the CSV file\n",
    "            csv_data = pd.read_csv(csv_file)\n",
    "            \n",
    "            # Find the corresponding image filename\n",
    "            image_filename = os.path.basename(image_path)\n",
    "            \n",
    "            # Filter annotations based on the image filename\n",
    "            annotations = csv_data[csv_data['filename'] == image_filename]\n",
    "            \n",
    "            # Initialize lists to store the texture metrics\n",
    "            bbox_contrast_list = []\n",
    "            bbox_dissimilarity_list = []\n",
    "            bbox_homogeneity_list = []\n",
    "            bbox_energy_list = []\n",
    "            donut_contrast_list = []\n",
    "            donut_dissimilarity_list = []\n",
    "            donut_homogeneity_list = []\n",
    "            donut_energy_list = []\n",
    "            \n",
    "            # Iterate through annotations and calculate texture metrics\n",
    "            for _, row in annotations.iterrows():\n",
    "                bbox = ast.literal_eval(row['bbox'])  # Parse bbox values from string to list\n",
    "                \n",
    "                # Calculate GCLM derivatives for bounding box and donut region\n",
    "                bbox_contrast, bbox_dissimilarity, bbox_homogeneity, bbox_energy = calculate_band_texture_metrics(image, bbox, band)\n",
    "                \n",
    "                donut_left = max(0, bbox[0] - 20)  # Adjust the buffer size as needed\n",
    "                donut_top = max(0, bbox[1] - 20)\n",
    "                donut_right = min(image.shape[1], bbox[0] + bbox[2] + 20)\n",
    "                donut_bottom = min(image.shape[0], bbox[1] + bbox[3] + 20)\n",
    "                donut_bbox = [donut_left, donut_top, donut_right - donut_left, donut_bottom - donut_top]\n",
    "                donut_contrast, donut_dissimilarity, donut_homogeneity, donut_energy = calculate_band_texture_metrics(image, donut_bbox, band)\n",
    "                \n",
    "                # Append the calculated texture metrics to the lists\n",
    "                bbox_contrast_list.append(bbox_contrast)\n",
    "                bbox_dissimilarity_list.append(bbox_dissimilarity)\n",
    "                bbox_homogeneity_list.append(bbox_homogeneity)\n",
    "                bbox_energy_list.append(bbox_energy)\n",
    "                \n",
    "                donut_contrast_list.append(donut_contrast)\n",
    "                donut_dissimilarity_list.append(donut_dissimilarity)\n",
    "                donut_homogeneity_list.append(donut_homogeneity)\n",
    "                donut_energy_list.append(donut_energy)\n",
    "            \n",
    "            # Add texture metrics as columns to a temporary dataframe\n",
    "            temp_df = pd.DataFrame({\n",
    "                'ID': annotations[\"ID\"],\n",
    "                'filename': [image_filename] * len(annotations),\n",
    "                'bbox_contrast': bbox_contrast_list,\n",
    "                'bbox_dissimilarity': bbox_dissimilarity_list,\n",
    "                'bbox_homogeneity': bbox_homogeneity_list,\n",
    "                'bbox_energy': bbox_energy_list,\n",
    "                'donut_contrast': donut_contrast_list,\n",
    "                'donut_dissimilarity': donut_dissimilarity_list,\n",
    "                'donut_homogeneity': donut_homogeneity_list,\n",
    "                'donut_energy': donut_energy_list\n",
    "            })\n",
    "            \n",
    "            # Append the temporary dataframe to the main dataframe\n",
    "            texture_metrics_df = pd.concat([texture_metrics_df, temp_df], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image '{image_path}': {e}\")\n",
    "    \n",
    "    # Save the main dataframe with texture metrics to a CSV file\n",
    "    texture_metrics_df.to_csv('E:\\\\imagefactors\\\\data\\\\gclm_usfws_blue.csv', index=False)\n",
    "\n",
    "# Example usage with a directory containing images and specifying the band (e.g., band=0 for blue, band=1 for green, band=2 for red)\n",
    "image_dir = 'E:\\\\imagefactors\\\\data\\\\usfws'\n",
    "csv_file = path  # Replace with the actual path to your CSV file containing the annotations\n",
    "band = 0  # Specify the band (0 for blue, 1 for green, 2 for red)\n",
    "\n",
    "calculate_texture_metrics_for_directory_band(image_dir, csv_file, band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge all the texture metric calc sheets together, then to the main dataframe\n",
    "\n",
    "path1 = \"E:\\\\imagefactors\\\\data\\\\gclm_usfws_8angles.csv\"\n",
    "with open(path1) as f1:\n",
    "  gclm_angles = pd.read_csv(f1)\n",
    "\n",
    "path2 = \"E:\\\\imagefactors\\\\data\\\\gclm_usfws_135.csv\"\n",
    "with open(path2) as f2:\n",
    "  gclm_135 = pd.read_csv(f2)\n",
    "\n",
    "path3 = \"E:\\\\imagefactors\\\\data\\\\gclm_usfws_135_8angles.csv\"\n",
    "with open(path3) as f3:\n",
    "  gclm_8angles135 = pd.read_csv(f3)\n",
    "\n",
    "path4 = \"E:\\\\imagefactors\\\\data\\\\gclm_usfws_pca.csv\"\n",
    "with open(path4) as f4:\n",
    "  gclm_pca = pd.read_csv(f4)\n",
    "\n",
    "path5 = \"E:\\\\imagefactors\\\\data\\\\gclm_usfws_blue.csv\"\n",
    "with open(path5) as f5:\n",
    "  gclm_blue = pd.read_csv(f5)\n",
    "\n",
    "path6 = \"E:\\\\imagefactors\\\\data\\\\gclm_usfws_green.csv\"\n",
    "with open(path6) as f6:\n",
    "  gclm_green = pd.read_csv(f6)\n",
    "\n",
    "path7 = \"E:\\\\imagefactors\\\\data\\\\gclm_usfws_red.csv\"\n",
    "with open(path7) as f7:\n",
    "  gclm_red = pd.read_csv(f7)\n",
    "\n",
    "path8 = \"E:\\\\imagefactors\\\\data\\\\gclm_usfws_smallkernel.csv\"\n",
    "with open(path8) as f8:\n",
    "  gclm_smallkernel = pd.read_csv(f8)\n",
    "\n",
    "merged_df = pd.merge(gclm_smallkernel, gclm_red, on=[\"ID\", \"filename\"], how=\"left\")\n",
    "merged_df = pd.merge(merged_df, gclm_green, on=[\"ID\", \"filename\"], how=\"left\")\n",
    "merged_df = pd.merge(merged_df, gclm_blue, on=[\"ID\", \"filename\"], how=\"left\")\n",
    "merged_df = pd.merge(merged_df, gclm_pca, on=[\"ID\", \"filename\"], how=\"left\")\n",
    "merged_df = pd.merge(merged_df, gclm_angles, on=[\"ID\", \"filename\"], how=\"left\")\n",
    "merged_df = pd.merge(merged_df, gclm_135, on=[\"ID\", \"filename\"], how=\"left\")\n",
    "merged_df = pd.merge(merged_df, gclm_8angles135, on=[\"ID\", \"filename\"], how=\"left\")\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examining the different texture values and looking at whether they derive different information\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "# Kruskal-Wallis test\n",
    "statistic, p_value = kruskal(merged_df['bbox_dissimilarity'], merged_df['donut_dissimilarity'])\n",
    "\n",
    "# Print the results\n",
    "print(\"Kruskal-Wallis Statistic:\", statistic)\n",
    "print(\"P-Value:\", p_value)\n",
    "\n",
    "# Check if the p-value is less than your chosen significance level (e.g., 0.05)\n",
    "if p_value < 0.05:\n",
    "    print(\"There are statistically significant differences between at least two groups.\")\n",
    "else:\n",
    "    print(\"There is no significant difference between the groups.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the basic GCLM to the main dataframe\n",
    "df = pd.merge(df, gclm_smallkernel, on=[\"ID\", \"filename\"], how=\"left\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the differences for each GCLM statistic\n",
    "df['contrast_difference'] = df['donut_contrast'] - df['bbox_contrast']\n",
    "df['energy_difference'] = df['donut_energy'] - df['bbox_energy']\n",
    "df['homogeneity_difference'] = df['donut_homogeneity'] - df['bbox_homogeneity']\n",
    "df['dissimilarity_difference'] = df['donut_dissimilarity'] - df['bbox_dissimilarity']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save \n",
    "df.to_csv('E:/imagefactors/data/expert_imagefactors_SPP.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cluster_id_x</th>\n",
       "      <th>filename_x</th>\n",
       "      <th>consensus_class_ID_x</th>\n",
       "      <th>bbox</th>\n",
       "      <th>pielou_index</th>\n",
       "      <th>area</th>\n",
       "      <th>bbox_percent_area</th>\n",
       "      <th>same_class_percent</th>\n",
       "      <th>num_neighbors</th>\n",
       "      <th>...</th>\n",
       "      <th>energy_difference</th>\n",
       "      <th>homogeneity_difference</th>\n",
       "      <th>dissimilarity_difference</th>\n",
       "      <th>cluster_id_y</th>\n",
       "      <th>filename_y</th>\n",
       "      <th>consensus_class_ID_y</th>\n",
       "      <th>consensus_bbox</th>\n",
       "      <th>num_annotations</th>\n",
       "      <th>consensus_guesses</th>\n",
       "      <th>correct_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[4445.5, 2719.5, 95.0, 80.5]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7647.50</td>\n",
       "      <td>0.038311</td>\n",
       "      <td>54.878049</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002017</td>\n",
       "      <td>-0.003060</td>\n",
       "      <td>-0.901467</td>\n",
       "      <td>0</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[4445.5, 2719.5, 95.0, 80.5]</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[4312.5, 2739.5, 98.0, 44.0]</td>\n",
       "      <td>0.468996</td>\n",
       "      <td>4312.00</td>\n",
       "      <td>0.021601</td>\n",
       "      <td>54.878049</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003161</td>\n",
       "      <td>-0.002116</td>\n",
       "      <td>-0.316365</td>\n",
       "      <td>1</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[4312.5, 2739.5, 98.0, 44.0]</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[3725.5, 1779.0, 73.5, 70.5]</td>\n",
       "      <td>0.468996</td>\n",
       "      <td>5181.75</td>\n",
       "      <td>0.025958</td>\n",
       "      <td>54.878049</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003372</td>\n",
       "      <td>-0.012692</td>\n",
       "      <td>1.908553</td>\n",
       "      <td>2</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[3725.5, 1779.0, 73.5, 70.5]</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[3628.0, 1882.0, 92.0, 38.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3496.00</td>\n",
       "      <td>0.017513</td>\n",
       "      <td>54.878049</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006176</td>\n",
       "      <td>-0.013843</td>\n",
       "      <td>0.038127</td>\n",
       "      <td>3</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[3628.0, 1882.0, 92.0, 38.0]</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[3679.0, 1929.0, 65.0, 82.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5330.00</td>\n",
       "      <td>0.026701</td>\n",
       "      <td>54.878049</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002882</td>\n",
       "      <td>-0.005665</td>\n",
       "      <td>1.620205</td>\n",
       "      <td>4</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[3679.0, 1929.0, 65.0, 82.0]</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cluster_id_x              filename_x consensus_class_ID_x  \\\n",
       "0   1             0  BDA_12C_20181127_1.JPG       Canadian Goose   \n",
       "1   2             1  BDA_12C_20181127_1.JPG       Canadian Goose   \n",
       "2   3             2  BDA_12C_20181127_1.JPG       Canadian Goose   \n",
       "3   4             3  BDA_12C_20181127_1.JPG       Canadian Goose   \n",
       "4   5             4  BDA_12C_20181127_1.JPG       Canadian Goose   \n",
       "\n",
       "                           bbox  pielou_index     area  bbox_percent_area  \\\n",
       "0  [4445.5, 2719.5, 95.0, 80.5]      0.000000  7647.50           0.038311   \n",
       "1  [4312.5, 2739.5, 98.0, 44.0]      0.468996  4312.00           0.021601   \n",
       "2  [3725.5, 1779.0, 73.5, 70.5]      0.468996  5181.75           0.025958   \n",
       "3  [3628.0, 1882.0, 92.0, 38.0]      0.000000  3496.00           0.017513   \n",
       "4  [3679.0, 1929.0, 65.0, 82.0]      0.000000  5330.00           0.026701   \n",
       "\n",
       "   same_class_percent  num_neighbors  ...  energy_difference  \\\n",
       "0           54.878049              1  ...          -0.002017   \n",
       "1           54.878049              2  ...          -0.003161   \n",
       "2           54.878049              1  ...          -0.003372   \n",
       "3           54.878049              3  ...          -0.006176   \n",
       "4           54.878049              3  ...          -0.002882   \n",
       "\n",
       "   homogeneity_difference  dissimilarity_difference  cluster_id_y  \\\n",
       "0               -0.003060                 -0.901467             0   \n",
       "1               -0.002116                 -0.316365             1   \n",
       "2               -0.012692                  1.908553             2   \n",
       "3               -0.013843                  0.038127             3   \n",
       "4               -0.005665                  1.620205             4   \n",
       "\n",
       "               filename_y  consensus_class_ID_y                consensus_bbox  \\\n",
       "0  BDA_12C_20181127_1.JPG        Canadian Goose  [4445.5, 2719.5, 95.0, 80.5]   \n",
       "1  BDA_12C_20181127_1.JPG        Canadian Goose  [4312.5, 2739.5, 98.0, 44.0]   \n",
       "2  BDA_12C_20181127_1.JPG        Canadian Goose  [3725.5, 1779.0, 73.5, 70.5]   \n",
       "3  BDA_12C_20181127_1.JPG        Canadian Goose  [3628.0, 1882.0, 92.0, 38.0]   \n",
       "4  BDA_12C_20181127_1.JPG        Canadian Goose  [3679.0, 1929.0, 65.0, 82.0]   \n",
       "\n",
       "   num_annotations  consensus_guesses  correct_fraction  \n",
       "0               10                 10               1.0  \n",
       "1               10                  9               0.9  \n",
       "2               10                  9               0.9  \n",
       "3                9                  9               1.0  \n",
       "4                9                  9               1.0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge with new file that has the simplified dependent variable\n",
    "import pandas as pd\n",
    "\n",
    "path1 = \"E:\\\\imagefactors\\\\data\\\\expert_imagefactors_SPP.csv\"\n",
    "with open(path1) as f1:\n",
    "  img = pd.read_csv(f1)\n",
    "\n",
    "path2 = \"E:\\\\imagefactors\\\\data\\\\expertLabels_simple.csv\"\n",
    "with open(path2) as f2:\n",
    "  simple = pd.read_csv(f2)\n",
    "\n",
    "df = pd.merge(img, simple, on=[\"id\"], how=\"left\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename_x</th>\n",
       "      <th>consensus_class_ID_x</th>\n",
       "      <th>bbox</th>\n",
       "      <th>pielou_index</th>\n",
       "      <th>area</th>\n",
       "      <th>bbox_percent_area</th>\n",
       "      <th>same_class_percent</th>\n",
       "      <th>num_neighbors</th>\n",
       "      <th>agl</th>\n",
       "      <th>...</th>\n",
       "      <th>donut_dissimilarity</th>\n",
       "      <th>donut_homogeneity</th>\n",
       "      <th>donut_energy</th>\n",
       "      <th>contrast_difference</th>\n",
       "      <th>energy_difference</th>\n",
       "      <th>homogeneity_difference</th>\n",
       "      <th>dissimilarity_difference</th>\n",
       "      <th>num_annotations</th>\n",
       "      <th>consensus_guesses</th>\n",
       "      <th>correct_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[4445.5, 2719.5, 95.0, 80.5]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7647.50</td>\n",
       "      <td>0.038311</td>\n",
       "      <td>54.878049</td>\n",
       "      <td>1</td>\n",
       "      <td>41.27</td>\n",
       "      <td>...</td>\n",
       "      <td>20.902788</td>\n",
       "      <td>0.062954</td>\n",
       "      <td>0.010217</td>\n",
       "      <td>-133.499291</td>\n",
       "      <td>-0.002017</td>\n",
       "      <td>-0.003060</td>\n",
       "      <td>-0.901467</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[4312.5, 2739.5, 98.0, 44.0]</td>\n",
       "      <td>0.468996</td>\n",
       "      <td>4312.00</td>\n",
       "      <td>0.021601</td>\n",
       "      <td>54.878049</td>\n",
       "      <td>2</td>\n",
       "      <td>41.27</td>\n",
       "      <td>...</td>\n",
       "      <td>19.516710</td>\n",
       "      <td>0.067360</td>\n",
       "      <td>0.011356</td>\n",
       "      <td>-58.319485</td>\n",
       "      <td>-0.003161</td>\n",
       "      <td>-0.002116</td>\n",
       "      <td>-0.316365</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[3725.5, 1779.0, 73.5, 70.5]</td>\n",
       "      <td>0.468996</td>\n",
       "      <td>5181.75</td>\n",
       "      <td>0.025958</td>\n",
       "      <td>54.878049</td>\n",
       "      <td>1</td>\n",
       "      <td>41.27</td>\n",
       "      <td>...</td>\n",
       "      <td>22.822854</td>\n",
       "      <td>0.058255</td>\n",
       "      <td>0.010184</td>\n",
       "      <td>68.924911</td>\n",
       "      <td>-0.003372</td>\n",
       "      <td>-0.012692</td>\n",
       "      <td>1.908553</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[3628.0, 1882.0, 92.0, 38.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3496.00</td>\n",
       "      <td>0.017513</td>\n",
       "      <td>54.878049</td>\n",
       "      <td>3</td>\n",
       "      <td>41.27</td>\n",
       "      <td>...</td>\n",
       "      <td>22.653116</td>\n",
       "      <td>0.080785</td>\n",
       "      <td>0.014425</td>\n",
       "      <td>-149.563152</td>\n",
       "      <td>-0.006176</td>\n",
       "      <td>-0.013843</td>\n",
       "      <td>0.038127</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[3679.0, 1929.0, 65.0, 82.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5330.00</td>\n",
       "      <td>0.026701</td>\n",
       "      <td>54.878049</td>\n",
       "      <td>3</td>\n",
       "      <td>41.27</td>\n",
       "      <td>...</td>\n",
       "      <td>23.769565</td>\n",
       "      <td>0.064042</td>\n",
       "      <td>0.010392</td>\n",
       "      <td>147.235060</td>\n",
       "      <td>-0.002882</td>\n",
       "      <td>-0.005665</td>\n",
       "      <td>1.620205</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id              filename_x consensus_class_ID_x  \\\n",
       "0   1  BDA_12C_20181127_1.JPG       Canadian Goose   \n",
       "1   2  BDA_12C_20181127_1.JPG       Canadian Goose   \n",
       "2   3  BDA_12C_20181127_1.JPG       Canadian Goose   \n",
       "3   4  BDA_12C_20181127_1.JPG       Canadian Goose   \n",
       "4   5  BDA_12C_20181127_1.JPG       Canadian Goose   \n",
       "\n",
       "                           bbox  pielou_index     area  bbox_percent_area  \\\n",
       "0  [4445.5, 2719.5, 95.0, 80.5]      0.000000  7647.50           0.038311   \n",
       "1  [4312.5, 2739.5, 98.0, 44.0]      0.468996  4312.00           0.021601   \n",
       "2  [3725.5, 1779.0, 73.5, 70.5]      0.468996  5181.75           0.025958   \n",
       "3  [3628.0, 1882.0, 92.0, 38.0]      0.000000  3496.00           0.017513   \n",
       "4  [3679.0, 1929.0, 65.0, 82.0]      0.000000  5330.00           0.026701   \n",
       "\n",
       "   same_class_percent  num_neighbors    agl  ...  donut_dissimilarity  \\\n",
       "0           54.878049              1  41.27  ...            20.902788   \n",
       "1           54.878049              2  41.27  ...            19.516710   \n",
       "2           54.878049              1  41.27  ...            22.822854   \n",
       "3           54.878049              3  41.27  ...            22.653116   \n",
       "4           54.878049              3  41.27  ...            23.769565   \n",
       "\n",
       "   donut_homogeneity  donut_energy  contrast_difference  energy_difference  \\\n",
       "0           0.062954      0.010217          -133.499291          -0.002017   \n",
       "1           0.067360      0.011356           -58.319485          -0.003161   \n",
       "2           0.058255      0.010184            68.924911          -0.003372   \n",
       "3           0.080785      0.014425          -149.563152          -0.006176   \n",
       "4           0.064042      0.010392           147.235060          -0.002882   \n",
       "\n",
       "   homogeneity_difference  dissimilarity_difference  num_annotations  \\\n",
       "0               -0.003060                 -0.901467               10   \n",
       "1               -0.002116                 -0.316365               10   \n",
       "2               -0.012692                  1.908553               10   \n",
       "3               -0.013843                  0.038127                9   \n",
       "4               -0.005665                  1.620205                9   \n",
       "\n",
       "   consensus_guesses  correct_fraction  \n",
       "0                 10               1.0  \n",
       "1                  9               0.9  \n",
       "2                  9               0.9  \n",
       "3                  9               1.0  \n",
       "4                  9               1.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['cluster_id_x', 'cluster_id_y', 'consensus_class_ID_y', 'consensus_bbox', 'filename_y'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>consensus_class_ID</th>\n",
       "      <th>bbox</th>\n",
       "      <th>pielou_index</th>\n",
       "      <th>area</th>\n",
       "      <th>bbox_percent_area</th>\n",
       "      <th>same_class_percent</th>\n",
       "      <th>num_neighbors</th>\n",
       "      <th>agl</th>\n",
       "      <th>...</th>\n",
       "      <th>donut_dissimilarity</th>\n",
       "      <th>donut_homogeneity</th>\n",
       "      <th>donut_energy</th>\n",
       "      <th>contrast_difference</th>\n",
       "      <th>energy_difference</th>\n",
       "      <th>homogeneity_difference</th>\n",
       "      <th>dissimilarity_difference</th>\n",
       "      <th>num_annotations</th>\n",
       "      <th>consensus_guesses</th>\n",
       "      <th>correct_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[4445.5, 2719.5, 95.0, 80.5]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7647.50</td>\n",
       "      <td>0.038311</td>\n",
       "      <td>54.878049</td>\n",
       "      <td>1</td>\n",
       "      <td>41.27</td>\n",
       "      <td>...</td>\n",
       "      <td>20.902788</td>\n",
       "      <td>0.062954</td>\n",
       "      <td>0.010217</td>\n",
       "      <td>-133.499291</td>\n",
       "      <td>-0.002017</td>\n",
       "      <td>-0.003060</td>\n",
       "      <td>-0.901467</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[4312.5, 2739.5, 98.0, 44.0]</td>\n",
       "      <td>0.468996</td>\n",
       "      <td>4312.00</td>\n",
       "      <td>0.021601</td>\n",
       "      <td>54.878049</td>\n",
       "      <td>2</td>\n",
       "      <td>41.27</td>\n",
       "      <td>...</td>\n",
       "      <td>19.516710</td>\n",
       "      <td>0.067360</td>\n",
       "      <td>0.011356</td>\n",
       "      <td>-58.319485</td>\n",
       "      <td>-0.003161</td>\n",
       "      <td>-0.002116</td>\n",
       "      <td>-0.316365</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[3725.5, 1779.0, 73.5, 70.5]</td>\n",
       "      <td>0.468996</td>\n",
       "      <td>5181.75</td>\n",
       "      <td>0.025958</td>\n",
       "      <td>54.878049</td>\n",
       "      <td>1</td>\n",
       "      <td>41.27</td>\n",
       "      <td>...</td>\n",
       "      <td>22.822854</td>\n",
       "      <td>0.058255</td>\n",
       "      <td>0.010184</td>\n",
       "      <td>68.924911</td>\n",
       "      <td>-0.003372</td>\n",
       "      <td>-0.012692</td>\n",
       "      <td>1.908553</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[3628.0, 1882.0, 92.0, 38.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3496.00</td>\n",
       "      <td>0.017513</td>\n",
       "      <td>54.878049</td>\n",
       "      <td>3</td>\n",
       "      <td>41.27</td>\n",
       "      <td>...</td>\n",
       "      <td>22.653116</td>\n",
       "      <td>0.080785</td>\n",
       "      <td>0.014425</td>\n",
       "      <td>-149.563152</td>\n",
       "      <td>-0.006176</td>\n",
       "      <td>-0.013843</td>\n",
       "      <td>0.038127</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[3679.0, 1929.0, 65.0, 82.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5330.00</td>\n",
       "      <td>0.026701</td>\n",
       "      <td>54.878049</td>\n",
       "      <td>3</td>\n",
       "      <td>41.27</td>\n",
       "      <td>...</td>\n",
       "      <td>23.769565</td>\n",
       "      <td>0.064042</td>\n",
       "      <td>0.010392</td>\n",
       "      <td>147.235060</td>\n",
       "      <td>-0.002882</td>\n",
       "      <td>-0.005665</td>\n",
       "      <td>1.620205</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                filename consensus_class_ID  \\\n",
       "0   1  BDA_12C_20181127_1.JPG     Canadian Goose   \n",
       "1   2  BDA_12C_20181127_1.JPG     Canadian Goose   \n",
       "2   3  BDA_12C_20181127_1.JPG     Canadian Goose   \n",
       "3   4  BDA_12C_20181127_1.JPG     Canadian Goose   \n",
       "4   5  BDA_12C_20181127_1.JPG     Canadian Goose   \n",
       "\n",
       "                           bbox  pielou_index     area  bbox_percent_area  \\\n",
       "0  [4445.5, 2719.5, 95.0, 80.5]      0.000000  7647.50           0.038311   \n",
       "1  [4312.5, 2739.5, 98.0, 44.0]      0.468996  4312.00           0.021601   \n",
       "2  [3725.5, 1779.0, 73.5, 70.5]      0.468996  5181.75           0.025958   \n",
       "3  [3628.0, 1882.0, 92.0, 38.0]      0.000000  3496.00           0.017513   \n",
       "4  [3679.0, 1929.0, 65.0, 82.0]      0.000000  5330.00           0.026701   \n",
       "\n",
       "   same_class_percent  num_neighbors    agl  ...  donut_dissimilarity  \\\n",
       "0           54.878049              1  41.27  ...            20.902788   \n",
       "1           54.878049              2  41.27  ...            19.516710   \n",
       "2           54.878049              1  41.27  ...            22.822854   \n",
       "3           54.878049              3  41.27  ...            22.653116   \n",
       "4           54.878049              3  41.27  ...            23.769565   \n",
       "\n",
       "   donut_homogeneity  donut_energy  contrast_difference  energy_difference  \\\n",
       "0           0.062954      0.010217          -133.499291          -0.002017   \n",
       "1           0.067360      0.011356           -58.319485          -0.003161   \n",
       "2           0.058255      0.010184            68.924911          -0.003372   \n",
       "3           0.080785      0.014425          -149.563152          -0.006176   \n",
       "4           0.064042      0.010392           147.235060          -0.002882   \n",
       "\n",
       "   homogeneity_difference  dissimilarity_difference  num_annotations  \\\n",
       "0               -0.003060                 -0.901467               10   \n",
       "1               -0.002116                 -0.316365               10   \n",
       "2               -0.012692                  1.908553               10   \n",
       "3               -0.013843                  0.038127                9   \n",
       "4               -0.005665                  1.620205                9   \n",
       "\n",
       "   consensus_guesses  correct_fraction  \n",
       "0                 10               1.0  \n",
       "1                  9               0.9  \n",
       "2                  9               0.9  \n",
       "3                  9               1.0  \n",
       "4                  9               1.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={'filename_x': 'filename', 'consensus_class_ID_x': 'consensus_class_ID'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>consensus_class_ID</th>\n",
       "      <th>bbox</th>\n",
       "      <th>pielou_index</th>\n",
       "      <th>area</th>\n",
       "      <th>bbox_percent_area</th>\n",
       "      <th>same_class_percent</th>\n",
       "      <th>num_neighbors</th>\n",
       "      <th>agl</th>\n",
       "      <th>...</th>\n",
       "      <th>donut_homogeneity</th>\n",
       "      <th>donut_energy</th>\n",
       "      <th>contrast_difference</th>\n",
       "      <th>energy_difference</th>\n",
       "      <th>homogeneity_difference</th>\n",
       "      <th>dissimilarity_difference</th>\n",
       "      <th>num_annotations</th>\n",
       "      <th>consensus_guesses</th>\n",
       "      <th>correct_fraction</th>\n",
       "      <th>n-k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[4445.5, 2719.5, 95.0, 80.5]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7647.50</td>\n",
       "      <td>0.038311</td>\n",
       "      <td>54.878049</td>\n",
       "      <td>1</td>\n",
       "      <td>41.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062954</td>\n",
       "      <td>0.010217</td>\n",
       "      <td>-133.499291</td>\n",
       "      <td>-0.002017</td>\n",
       "      <td>-0.003060</td>\n",
       "      <td>-0.901467</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[4312.5, 2739.5, 98.0, 44.0]</td>\n",
       "      <td>0.468996</td>\n",
       "      <td>4312.00</td>\n",
       "      <td>0.021601</td>\n",
       "      <td>54.878049</td>\n",
       "      <td>2</td>\n",
       "      <td>41.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067360</td>\n",
       "      <td>0.011356</td>\n",
       "      <td>-58.319485</td>\n",
       "      <td>-0.003161</td>\n",
       "      <td>-0.002116</td>\n",
       "      <td>-0.316365</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[3725.5, 1779.0, 73.5, 70.5]</td>\n",
       "      <td>0.468996</td>\n",
       "      <td>5181.75</td>\n",
       "      <td>0.025958</td>\n",
       "      <td>54.878049</td>\n",
       "      <td>1</td>\n",
       "      <td>41.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058255</td>\n",
       "      <td>0.010184</td>\n",
       "      <td>68.924911</td>\n",
       "      <td>-0.003372</td>\n",
       "      <td>-0.012692</td>\n",
       "      <td>1.908553</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[3628.0, 1882.0, 92.0, 38.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3496.00</td>\n",
       "      <td>0.017513</td>\n",
       "      <td>54.878049</td>\n",
       "      <td>3</td>\n",
       "      <td>41.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080785</td>\n",
       "      <td>0.014425</td>\n",
       "      <td>-149.563152</td>\n",
       "      <td>-0.006176</td>\n",
       "      <td>-0.013843</td>\n",
       "      <td>0.038127</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[3679.0, 1929.0, 65.0, 82.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5330.00</td>\n",
       "      <td>0.026701</td>\n",
       "      <td>54.878049</td>\n",
       "      <td>3</td>\n",
       "      <td>41.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064042</td>\n",
       "      <td>0.010392</td>\n",
       "      <td>147.235060</td>\n",
       "      <td>-0.002882</td>\n",
       "      <td>-0.005665</td>\n",
       "      <td>1.620205</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                filename consensus_class_ID  \\\n",
       "0   1  BDA_12C_20181127_1.JPG     Canadian Goose   \n",
       "1   2  BDA_12C_20181127_1.JPG     Canadian Goose   \n",
       "2   3  BDA_12C_20181127_1.JPG     Canadian Goose   \n",
       "3   4  BDA_12C_20181127_1.JPG     Canadian Goose   \n",
       "4   5  BDA_12C_20181127_1.JPG     Canadian Goose   \n",
       "\n",
       "                           bbox  pielou_index     area  bbox_percent_area  \\\n",
       "0  [4445.5, 2719.5, 95.0, 80.5]      0.000000  7647.50           0.038311   \n",
       "1  [4312.5, 2739.5, 98.0, 44.0]      0.468996  4312.00           0.021601   \n",
       "2  [3725.5, 1779.0, 73.5, 70.5]      0.468996  5181.75           0.025958   \n",
       "3  [3628.0, 1882.0, 92.0, 38.0]      0.000000  3496.00           0.017513   \n",
       "4  [3679.0, 1929.0, 65.0, 82.0]      0.000000  5330.00           0.026701   \n",
       "\n",
       "   same_class_percent  num_neighbors    agl  ...  donut_homogeneity  \\\n",
       "0           54.878049              1  41.27  ...           0.062954   \n",
       "1           54.878049              2  41.27  ...           0.067360   \n",
       "2           54.878049              1  41.27  ...           0.058255   \n",
       "3           54.878049              3  41.27  ...           0.080785   \n",
       "4           54.878049              3  41.27  ...           0.064042   \n",
       "\n",
       "   donut_energy  contrast_difference  energy_difference  \\\n",
       "0      0.010217          -133.499291          -0.002017   \n",
       "1      0.011356           -58.319485          -0.003161   \n",
       "2      0.010184            68.924911          -0.003372   \n",
       "3      0.014425          -149.563152          -0.006176   \n",
       "4      0.010392           147.235060          -0.002882   \n",
       "\n",
       "   homogeneity_difference  dissimilarity_difference  num_annotations  \\\n",
       "0               -0.003060                 -0.901467               10   \n",
       "1               -0.002116                 -0.316365               10   \n",
       "2               -0.012692                  1.908553               10   \n",
       "3               -0.013843                  0.038127                9   \n",
       "4               -0.005665                  1.620205                9   \n",
       "\n",
       "   consensus_guesses  correct_fraction  n-k  \n",
       "0                 10               1.0    0  \n",
       "1                  9               0.9    1  \n",
       "2                  9               0.9    1  \n",
       "3                  9               1.0    0  \n",
       "4                  9               1.0    0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['n-k'] = df['num_annotations'] - df['consensus_guesses']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELING IMPACT OF IMAGE FACTORS ON LABELING DIFFICULTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n-k\n",
       "0    844\n",
       "1    505\n",
       "2    421\n",
       "3    232\n",
       "4    145\n",
       "5     44\n",
       "6     14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['n-k'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>bbox</th>\n",
       "      <th>pielou_index</th>\n",
       "      <th>area</th>\n",
       "      <th>bbox_percent_area</th>\n",
       "      <th>same_class_percent</th>\n",
       "      <th>num_neighbors</th>\n",
       "      <th>agl</th>\n",
       "      <th>gsd</th>\n",
       "      <th>...</th>\n",
       "      <th>n-k</th>\n",
       "      <th>class_American Wigeon</th>\n",
       "      <th>class_Canadian Goose</th>\n",
       "      <th>class_Gadwall</th>\n",
       "      <th>class_Mallard</th>\n",
       "      <th>class_Northern Pintail</th>\n",
       "      <th>class_Northern Shoveler</th>\n",
       "      <th>class_Other</th>\n",
       "      <th>class_Sandhill Crane</th>\n",
       "      <th>class_Teal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>[4445.5, 2719.5, 95.0, 80.5]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7647.50</td>\n",
       "      <td>0.038311</td>\n",
       "      <td>54.878049</td>\n",
       "      <td>1</td>\n",
       "      <td>41.27</td>\n",
       "      <td>0.932734</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>[4312.5, 2739.5, 98.0, 44.0]</td>\n",
       "      <td>0.468996</td>\n",
       "      <td>4312.00</td>\n",
       "      <td>0.021601</td>\n",
       "      <td>54.878049</td>\n",
       "      <td>2</td>\n",
       "      <td>41.27</td>\n",
       "      <td>0.932734</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>[3725.5, 1779.0, 73.5, 70.5]</td>\n",
       "      <td>0.468996</td>\n",
       "      <td>5181.75</td>\n",
       "      <td>0.025958</td>\n",
       "      <td>54.878049</td>\n",
       "      <td>1</td>\n",
       "      <td>41.27</td>\n",
       "      <td>0.932734</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>[3628.0, 1882.0, 92.0, 38.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3496.00</td>\n",
       "      <td>0.017513</td>\n",
       "      <td>54.878049</td>\n",
       "      <td>3</td>\n",
       "      <td>41.27</td>\n",
       "      <td>0.932734</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>[3679.0, 1929.0, 65.0, 82.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5330.00</td>\n",
       "      <td>0.026701</td>\n",
       "      <td>54.878049</td>\n",
       "      <td>3</td>\n",
       "      <td>41.27</td>\n",
       "      <td>0.932734</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                filename                          bbox  pielou_index  \\\n",
       "0   1  BDA_12C_20181127_1.JPG  [4445.5, 2719.5, 95.0, 80.5]      0.000000   \n",
       "1   2  BDA_12C_20181127_1.JPG  [4312.5, 2739.5, 98.0, 44.0]      0.468996   \n",
       "2   3  BDA_12C_20181127_1.JPG  [3725.5, 1779.0, 73.5, 70.5]      0.468996   \n",
       "3   4  BDA_12C_20181127_1.JPG  [3628.0, 1882.0, 92.0, 38.0]      0.000000   \n",
       "4   5  BDA_12C_20181127_1.JPG  [3679.0, 1929.0, 65.0, 82.0]      0.000000   \n",
       "\n",
       "      area  bbox_percent_area  same_class_percent  num_neighbors    agl  \\\n",
       "0  7647.50           0.038311           54.878049              1  41.27   \n",
       "1  4312.00           0.021601           54.878049              2  41.27   \n",
       "2  5181.75           0.025958           54.878049              1  41.27   \n",
       "3  3496.00           0.017513           54.878049              3  41.27   \n",
       "4  5330.00           0.026701           54.878049              3  41.27   \n",
       "\n",
       "        gsd  ...  n-k  class_American Wigeon  class_Canadian Goose  \\\n",
       "0  0.932734  ...    0                  False                  True   \n",
       "1  0.932734  ...    1                  False                  True   \n",
       "2  0.932734  ...    1                  False                  True   \n",
       "3  0.932734  ...    0                  False                  True   \n",
       "4  0.932734  ...    0                  False                  True   \n",
       "\n",
       "   class_Gadwall  class_Mallard  class_Northern Pintail  \\\n",
       "0          False          False                   False   \n",
       "1          False          False                   False   \n",
       "2          False          False                   False   \n",
       "3          False          False                   False   \n",
       "4          False          False                   False   \n",
       "\n",
       "   class_Northern Shoveler  class_Other  class_Sandhill Crane  class_Teal  \n",
       "0                    False        False                 False       False  \n",
       "1                    False        False                 False       False  \n",
       "2                    False        False                 False       False  \n",
       "3                    False        False                 False       False  \n",
       "4                    False        False                 False       False  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dummy variables for class ID\n",
    "df = pd.get_dummies(df, columns=[\"consensus_class_ID\"], prefix=\"class\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>bbox</th>\n",
       "      <th>pielou_index</th>\n",
       "      <th>area</th>\n",
       "      <th>bbox_percent_area</th>\n",
       "      <th>same_class_percent</th>\n",
       "      <th>num_neighbors</th>\n",
       "      <th>agl</th>\n",
       "      <th>gsd</th>\n",
       "      <th>...</th>\n",
       "      <th>n-k</th>\n",
       "      <th>class_American Wigeon</th>\n",
       "      <th>class_Canadian Goose</th>\n",
       "      <th>class_Gadwall</th>\n",
       "      <th>class_Mallard</th>\n",
       "      <th>class_Northern Pintail</th>\n",
       "      <th>class_Northern Shoveler</th>\n",
       "      <th>class_Other</th>\n",
       "      <th>class_Sandhill Crane</th>\n",
       "      <th>class_Teal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>[4445.5, 2719.5, 95.0, 80.5]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7647.50</td>\n",
       "      <td>0.038311</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>41.27</td>\n",
       "      <td>0.932734</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>[4312.5, 2739.5, 98.0, 44.0]</td>\n",
       "      <td>0.468996</td>\n",
       "      <td>4312.00</td>\n",
       "      <td>0.021601</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>41.27</td>\n",
       "      <td>0.932734</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>[3725.5, 1779.0, 73.5, 70.5]</td>\n",
       "      <td>0.468996</td>\n",
       "      <td>5181.75</td>\n",
       "      <td>0.025958</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>41.27</td>\n",
       "      <td>0.932734</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>[3628.0, 1882.0, 92.0, 38.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3496.00</td>\n",
       "      <td>0.017513</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>41.27</td>\n",
       "      <td>0.932734</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>[3679.0, 1929.0, 65.0, 82.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5330.00</td>\n",
       "      <td>0.026701</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>41.27</td>\n",
       "      <td>0.932734</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                filename                          bbox  pielou_index  \\\n",
       "0   1  BDA_12C_20181127_1.JPG  [4445.5, 2719.5, 95.0, 80.5]      0.000000   \n",
       "1   2  BDA_12C_20181127_1.JPG  [4312.5, 2739.5, 98.0, 44.0]      0.468996   \n",
       "2   3  BDA_12C_20181127_1.JPG  [3725.5, 1779.0, 73.5, 70.5]      0.468996   \n",
       "3   4  BDA_12C_20181127_1.JPG  [3628.0, 1882.0, 92.0, 38.0]      0.000000   \n",
       "4   5  BDA_12C_20181127_1.JPG  [3679.0, 1929.0, 65.0, 82.0]      0.000000   \n",
       "\n",
       "      area  bbox_percent_area  same_class_percent  num_neighbors    agl  \\\n",
       "0  7647.50           0.038311                  54              1  41.27   \n",
       "1  4312.00           0.021601                  54              2  41.27   \n",
       "2  5181.75           0.025958                  54              1  41.27   \n",
       "3  3496.00           0.017513                  54              3  41.27   \n",
       "4  5330.00           0.026701                  54              3  41.27   \n",
       "\n",
       "        gsd  ...  n-k  class_American Wigeon  class_Canadian Goose  \\\n",
       "0  0.932734  ...    0                      0                     1   \n",
       "1  0.932734  ...    1                      0                     1   \n",
       "2  0.932734  ...    1                      0                     1   \n",
       "3  0.932734  ...    0                      0                     1   \n",
       "4  0.932734  ...    0                      0                     1   \n",
       "\n",
       "   class_Gadwall  class_Mallard  class_Northern Pintail  \\\n",
       "0              0              0                       0   \n",
       "1              0              0                       0   \n",
       "2              0              0                       0   \n",
       "3              0              0                       0   \n",
       "4              0              0                       0   \n",
       "\n",
       "   class_Northern Shoveler  class_Other  class_Sandhill Crane  class_Teal  \n",
       "0                        0            0                     0           0  \n",
       "1                        0            0                     0           0  \n",
       "2                        0            0                     0           0  \n",
       "3                        0            0                     0           0  \n",
       "4                        0            0                     0           0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for column in data.filter(like='class_'):\n",
    "    data[column] = data[column].astype(int)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('E:/imagefactors/data/expert_IF_SPP_update.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>bbox</th>\n",
       "      <th>pielou_index</th>\n",
       "      <th>area</th>\n",
       "      <th>bbox_percent_area</th>\n",
       "      <th>same_class_percent</th>\n",
       "      <th>num_neighbors</th>\n",
       "      <th>agl</th>\n",
       "      <th>gsd</th>\n",
       "      <th>...</th>\n",
       "      <th>correct_fraction</th>\n",
       "      <th>n-k</th>\n",
       "      <th>class_American Wigeon</th>\n",
       "      <th>class_Canadian Goose</th>\n",
       "      <th>class_Gadwall</th>\n",
       "      <th>class_Mallard</th>\n",
       "      <th>class_Northern Pintail</th>\n",
       "      <th>class_Northern Shoveler</th>\n",
       "      <th>class_Other</th>\n",
       "      <th>class_Sandhill Crane</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>[4445.5, 2719.5, 95.0, 80.5]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7647.50</td>\n",
       "      <td>0.038311</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>41.27</td>\n",
       "      <td>0.932734</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>[4312.5, 2739.5, 98.0, 44.0]</td>\n",
       "      <td>0.468996</td>\n",
       "      <td>4312.00</td>\n",
       "      <td>0.021601</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>41.27</td>\n",
       "      <td>0.932734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>[3725.5, 1779.0, 73.5, 70.5]</td>\n",
       "      <td>0.468996</td>\n",
       "      <td>5181.75</td>\n",
       "      <td>0.025958</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>41.27</td>\n",
       "      <td>0.932734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>[3628.0, 1882.0, 92.0, 38.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3496.00</td>\n",
       "      <td>0.017513</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>41.27</td>\n",
       "      <td>0.932734</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>[3679.0, 1929.0, 65.0, 82.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5330.00</td>\n",
       "      <td>0.026701</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>41.27</td>\n",
       "      <td>0.932734</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                filename                          bbox  pielou_index  \\\n",
       "0   1  BDA_12C_20181127_1.JPG  [4445.5, 2719.5, 95.0, 80.5]      0.000000   \n",
       "1   2  BDA_12C_20181127_1.JPG  [4312.5, 2739.5, 98.0, 44.0]      0.468996   \n",
       "2   3  BDA_12C_20181127_1.JPG  [3725.5, 1779.0, 73.5, 70.5]      0.468996   \n",
       "3   4  BDA_12C_20181127_1.JPG  [3628.0, 1882.0, 92.0, 38.0]      0.000000   \n",
       "4   5  BDA_12C_20181127_1.JPG  [3679.0, 1929.0, 65.0, 82.0]      0.000000   \n",
       "\n",
       "      area  bbox_percent_area  same_class_percent  num_neighbors    agl  \\\n",
       "0  7647.50           0.038311                  54              1  41.27   \n",
       "1  4312.00           0.021601                  54              2  41.27   \n",
       "2  5181.75           0.025958                  54              1  41.27   \n",
       "3  3496.00           0.017513                  54              3  41.27   \n",
       "4  5330.00           0.026701                  54              3  41.27   \n",
       "\n",
       "        gsd  ...  correct_fraction  n-k  class_American Wigeon  \\\n",
       "0  0.932734  ...               1.0    0                      0   \n",
       "1  0.932734  ...               0.9    1                      0   \n",
       "2  0.932734  ...               0.9    1                      0   \n",
       "3  0.932734  ...               1.0    0                      0   \n",
       "4  0.932734  ...               1.0    0                      0   \n",
       "\n",
       "   class_Canadian Goose  class_Gadwall  class_Mallard  class_Northern Pintail  \\\n",
       "0                     1              0              0                       0   \n",
       "1                     1              0              0                       0   \n",
       "2                     1              0              0                       0   \n",
       "3                     1              0              0                       0   \n",
       "4                     1              0              0                       0   \n",
       "\n",
       "   class_Northern Shoveler  class_Other  class_Sandhill Crane  \n",
       "0                        0            0                     0  \n",
       "1                        0            0                     0  \n",
       "2                        0            0                     0  \n",
       "3                        0            0                     0  \n",
       "4                        0            0                     0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"E:/imagefactors/data/expert_IF_SPP_update.csv\"\n",
    "with open(path) as f:\n",
    "  data = pd.read_csv(f)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Generalized Linear Model Regression Results                       \n",
      "========================================================================================\n",
      "Dep. Variable:     ['consensus_guesses', 'n-k']   No. Observations:                 2205\n",
      "Model:                                      GLM   Df Residuals:                     2192\n",
      "Model Family:                          Binomial   Df Model:                           12\n",
      "Link Function:                            Logit   Scale:                          1.0000\n",
      "Method:                                    IRLS   Log-Likelihood:                -3035.7\n",
      "Date:                          Fri, 01 Dec 2023   Deviance:                       3064.2\n",
      "Time:                                  16:09:26   Pearson chi2:                 3.37e+03\n",
      "No. Iterations:                               9   Pseudo R-squ. (CS):             0.4063\n",
      "Covariance Type:                      nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "const                      -0.7993      0.593     -1.347      0.178      -1.962       0.364\n",
      "bbox_percent_area          49.3059      4.216     11.694      0.000      41.042      57.570\n",
      "gsd                         0.1791      0.193      0.926      0.354      -0.200       0.558\n",
      "num_neighbors               0.1777      0.016     11.038      0.000       0.146       0.209\n",
      "contrast_difference        -0.0011      0.000     -9.383      0.000      -0.001      -0.001\n",
      "class_American Wigeon      -0.1561      0.585     -0.267      0.790      -1.303       0.990\n",
      "class_Canadian Goose        2.3332      0.587      3.973      0.000       1.182       3.484\n",
      "class_Gadwall              -0.9604      0.648     -1.481      0.139      -2.231       0.310\n",
      "class_Mallard               0.9945      0.557      1.784      0.074      -0.098       2.087\n",
      "class_Northern Pintail      0.8387      0.561      1.496      0.135      -0.260       1.937\n",
      "class_Northern Shoveler    -0.3329      0.787     -0.423      0.672      -1.876       1.210\n",
      "class_Other                -0.3397      0.564     -0.602      0.547      -1.445       0.766\n",
      "class_Sandhill Crane        4.1295      1.151      3.587      0.000       1.873       6.386\n",
      "===========================================================================================\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Define the independent variables\n",
    "X = data[['bbox_percent_area', 'gsd', 'num_neighbors', 'contrast_difference',\n",
    "          'class_American Wigeon', 'class_Canadian Goose', 'class_Gadwall',\n",
    "          'class_Mallard', 'class_Northern Pintail', 'class_Northern Shoveler', 'class_Other', 'class_Sandhill Crane']]\n",
    "\n",
    "# Add a constant term to the independent variables\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Define the response variable\n",
    "y = data[['consensus_guesses', 'n-k']]\n",
    "\n",
    "# Fit logistic regression model\n",
    "model = sm.GLM(y, X, family=sm.families.Binomial()).fit()\n",
    "\n",
    "# Display the model summary\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Variable        VIF\n",
      "0         bbox_percent_area   4.305665\n",
      "1             num_neighbors   2.433099\n",
      "2                       gsd  16.209672\n",
      "3         energy_difference   1.297712\n",
      "4     class_American Wigeon   1.218786\n",
      "5      class_Canadian Goose   2.612853\n",
      "6             class_Gadwall   1.048773\n",
      "7             class_Mallard  16.435828\n",
      "8    class_Northern Pintail   3.341252\n",
      "9   class_Northern Shoveler   1.022130\n",
      "10     class_Sandhill Crane   3.008661\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Assuming 'data' is your DataFrame with predictor variables\n",
    "predictors = data[[\n",
    " 'bbox_percent_area',\n",
    " #'same_class_percent',\n",
    " 'num_neighbors',\n",
    " #'agl',\n",
    " 'gsd',\n",
    " #'distance_from_center',\n",
    " #'density',\n",
    " #'rarity',\n",
    "# 'bbox_contrast',\n",
    " #'bbox_dissimilarity',\n",
    " #'bbox_homogeneity',\n",
    " #'bbox_energy',\n",
    " #'donut_contrast',\n",
    " #'donut_dissimilarity',\n",
    " #'donut_homogeneity',\n",
    " #'donut_energy',\n",
    " #'contrast_difference',\n",
    " 'energy_difference',\n",
    " #'homogeneity_difference',\n",
    " #'dissimilarity_difference',\n",
    " #'num_annotations',\n",
    " 'class_American Wigeon',\n",
    " 'class_Canadian Goose',\n",
    " 'class_Gadwall',\n",
    " 'class_Mallard',\n",
    " 'class_Northern Pintail',\n",
    " 'class_Northern Shoveler',\n",
    " #'class_Other',\n",
    " 'class_Sandhill Crane']]\n",
    " #'class_Teal']]\n",
    "\n",
    "# Calculate VIF\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = predictors.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(predictors.values, i) for i in range(predictors.shape[1])]\n",
    "\n",
    "# Display the VIF DataFrame\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    n-k   R-squared:                       0.296\n",
      "Model:                            OLS   Adj. R-squared:                  0.290\n",
      "Method:                 Least Squares   F-statistic:                     51.06\n",
      "Date:                Tue, 31 Oct 2023   Prob (F-statistic):          7.84e-152\n",
      "Time:                        11:59:10   Log-Likelihood:                -3482.1\n",
      "No. Observations:                2205   AIC:                             7002.\n",
      "Df Residuals:                    2186   BIC:                             7111.\n",
      "Df Model:                          18                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "============================================================================================\n",
      "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------\n",
      "const                        3.3290      0.317     10.486      0.000       2.706       3.952\n",
      "rarity                       0.0027      0.003      0.816      0.415      -0.004       0.009\n",
      "gsd                          0.6412      0.362      1.772      0.077      -0.068       1.351\n",
      "bbox_percent_area          -26.3488      3.143     -8.385      0.000     -32.511     -20.186\n",
      "same_class_percent          -0.0133      0.002     -7.050      0.000      -0.017      -0.010\n",
      "num_neighbors               -0.1089      0.018     -6.144      0.000      -0.144      -0.074\n",
      "distance_from_center        -0.0010      0.005     -0.202      0.840      -0.010       0.008\n",
      "density                     -0.0024      0.000    -11.993      0.000      -0.003      -0.002\n",
      "contrast_difference          0.0040      0.000      8.355      0.000       0.003       0.005\n",
      "energy_difference            4.5117      7.346      0.614      0.539      -9.894      18.917\n",
      "homogeneity_difference     -11.7603      2.974     -3.955      0.000     -17.592      -5.929\n",
      "dissimilarity_difference    -0.3372      0.047     -7.211      0.000      -0.429      -0.246\n",
      "class_American Wigeon        0.6149      0.273      2.253      0.024       0.080       1.150\n",
      "class_Canadian Goose        -1.4867      0.213     -6.980      0.000      -1.904      -1.069\n",
      "class_Gadwall                2.1655      0.489      4.432      0.000       1.207       3.124\n",
      "class_Mallard                0.1021      0.043      2.379      0.017       0.018       0.186\n",
      "class_Northern Pintail      -0.3838      0.149     -2.574      0.010      -0.676      -0.091\n",
      "class_Northern Shoveler      1.2638      0.746      1.695      0.090      -0.198       2.726\n",
      "class_Other                  1.4697      0.201      7.314      0.000       1.076       1.864\n",
      "class_Sandhill Crane        -0.8618      0.276     -3.127      0.002      -1.402      -0.321\n",
      "class_Teal                   0.4453      0.746      0.597      0.551      -1.017       1.908\n",
      "==============================================================================\n",
      "Omnibus:                      228.825   Durbin-Watson:                   1.296\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              311.171\n",
      "Skew:                           0.828   Prob(JB):                     2.69e-68\n",
      "Kurtosis:                       3.801   Cond. No.                     2.12e+18\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.54e-28. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "#Multiple linear regression \n",
    "\n",
    "y = data['n-k']\n",
    "X = [['rarity', 'gsd', 'bbox_percent_area', 'same_class_percent', 'num_neighbors', 'distance_from_center', 'density', 'contrast_difference', 'energy_difference', 'homogeneity_difference', 'dissimilarity_difference',\n",
    "        'class_American Wigeon', 'class_Canadian Goose', 'class_Gadwall', 'class_Mallard', 'class_Northern Pintail', 'class_Northern Shoveler', 'class_Other', 'class_Sandhill Crane', 'class_Teal']]\n",
    "\n",
    "# Add a constant term to the independent variables (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the regression summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Variable        VIF\n",
      "0                      const   0.000000\n",
      "1                     rarity        inf\n",
      "2                        gsd   7.564173\n",
      "3          bbox_percent_area   3.968870\n",
      "4         same_class_percent   5.266126\n",
      "5              num_neighbors   1.193138\n",
      "6       distance_from_center   1.636949\n",
      "7                    density   3.820140\n",
      "8        contrast_difference  13.907166\n",
      "9          energy_difference   9.113990\n",
      "10    homogeneity_difference  14.967774\n",
      "11  dissimilarity_difference  20.977424\n",
      "12     class_American Wigeon        inf\n",
      "13      class_Canadian Goose        inf\n",
      "14             class_Gadwall        inf\n",
      "15             class_Mallard        inf\n",
      "16    class_Northern Pintail        inf\n",
      "17   class_Northern Shoveler        inf\n",
      "18               class_Other        inf\n",
      "19      class_Sandhill Crane        inf\n",
      "20                class_Teal        inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\yolo\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:1781: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "c:\\ProgramData\\anaconda3\\envs\\yolo\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    }
   ],
   "source": [
    "# Calculate Variance Inflation Factors (VIF) to check for multicollinearity\n",
    "vif = pd.DataFrame()\n",
    "vif[\"Variable\"] = X.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rarity', 'same_class_percent'),\n",
       " ('rarity', 'class_Mallard'),\n",
       " ('gsd', 'density'),\n",
       " ('same_class_percent', 'rarity'),\n",
       " ('same_class_percent', 'class_Mallard'),\n",
       " ('density', 'gsd'),\n",
       " ('contrast_difference', 'dissimilarity_difference'),\n",
       " ('energy_difference', 'homogeneity_difference'),\n",
       " ('homogeneity_difference', 'energy_difference'),\n",
       " ('dissimilarity_difference', 'contrast_difference'),\n",
       " ('class_Mallard', 'rarity'),\n",
       " ('class_Mallard', 'same_class_percent')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix = X.corr()\n",
    "correlated_pairs = [(var1, var2) for var1 in X.columns for var2 in X.columns if var1 != var2 and abs(correlation_matrix.loc[var1, var2]) > 0.7]\n",
    "correlated_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    n-k   R-squared:                       0.225\n",
      "Model:                            OLS   Adj. R-squared:                  0.220\n",
      "Method:                 Least Squares   F-statistic:                     45.31\n",
      "Date:                Tue, 31 Oct 2023   Prob (F-statistic):          3.48e-110\n",
      "Time:                        12:14:51   Log-Likelihood:                -3588.7\n",
      "No. Observations:                2205   AIC:                             7207.\n",
      "Df Residuals:                    2190   BIC:                             7293.\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "const                       3.3843      0.254     13.327      0.000       2.886       3.882\n",
      "gsd                        -0.8546      0.251     -3.399      0.001      -1.348      -0.362\n",
      "bbox_percent_area         -24.7017      3.176     -7.778      0.000     -30.929     -18.474\n",
      "num_neighbors              -0.1736      0.018     -9.855      0.000      -0.208      -0.139\n",
      "distance_from_center        0.0072      0.005      1.564      0.118      -0.002       0.016\n",
      "contrast_difference         0.0007      0.000      4.753      0.000       0.000       0.001\n",
      "energy_difference          -0.4778      3.102     -0.154      0.878      -6.561       5.606\n",
      "class_American Wigeon       0.5767      0.275      2.094      0.036       0.037       1.117\n",
      "class_Canadian Goose       -1.4246      0.189     -7.549      0.000      -1.795      -1.055\n",
      "class_Gadwall               2.4669      0.515      4.791      0.000       1.457       3.477\n",
      "class_Mallard              -0.6716      0.144     -4.651      0.000      -0.955      -0.388\n",
      "class_Northern Pintail     -0.5837      0.158     -3.701      0.000      -0.893      -0.274\n",
      "class_Northern Shoveler     1.2792      0.795      1.608      0.108      -0.280       2.839\n",
      "class_Other                 1.5758      0.196      8.038      0.000       1.191       1.960\n",
      "class_Sandhill Crane       -0.6409      0.276     -2.320      0.020      -1.183      -0.099\n",
      "class_Teal                  0.8066      0.795      1.015      0.310      -0.752       2.366\n",
      "==============================================================================\n",
      "Omnibus:                      264.688   Durbin-Watson:                   1.244\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              371.641\n",
      "Skew:                           0.920   Prob(JB):                     1.99e-81\n",
      "Kurtosis:                       3.814   Cond. No.                     4.30e+18\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.32e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "y = data['n-k']\n",
    "X = data[['gsd', 'bbox_percent_area', 'num_neighbors', 'distance_from_center', 'contrast_difference', 'energy_difference',\n",
    "        'class_American Wigeon', 'class_Canadian Goose', 'class_Gadwall', 'class_Mallard', 'class_Northern Pintail', 'class_Northern Shoveler', 'class_Other', 'class_Sandhill Crane', 'class_Teal']]\n",
    "\n",
    "# Add a constant term to the independent variables (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the regression summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Variable       VIF\n",
      "0                     const  0.000000\n",
      "1                       gsd  3.321961\n",
      "2         bbox_percent_area  3.686422\n",
      "3             num_neighbors  1.072452\n",
      "4      distance_from_center  1.383715\n",
      "5       contrast_difference  1.343970\n",
      "6         energy_difference  1.478396\n",
      "7     class_American Wigeon       inf\n",
      "8      class_Canadian Goose       inf\n",
      "9             class_Gadwall       inf\n",
      "10            class_Mallard       inf\n",
      "11   class_Northern Pintail       inf\n",
      "12  class_Northern Shoveler       inf\n",
      "13              class_Other       inf\n",
      "14     class_Sandhill Crane       inf\n",
      "15               class_Teal       inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\yolo\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:1781: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "c:\\ProgramData\\anaconda3\\envs\\yolo\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    }
   ],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif[\"Variable\"] = X.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    n-k   R-squared:                       0.115\n",
      "Model:                            OLS   Adj. R-squared:                  0.112\n",
      "Method:                 Least Squares   F-statistic:                     47.52\n",
      "Date:                Tue, 31 Oct 2023   Prob (F-statistic):           4.97e-55\n",
      "Time:                        12:52:45   Log-Likelihood:                -3734.6\n",
      "No. Observations:                2205   AIC:                             7483.\n",
      "Df Residuals:                    2198   BIC:                             7523.\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                    3.0249      0.188     16.094      0.000       2.656       3.393\n",
      "gsd                     -1.0520      0.229     -4.584      0.000      -1.502      -0.602\n",
      "bbox_percent_area      -28.7322      2.282    -12.593      0.000     -33.207     -24.258\n",
      "num_neighbors           -0.1998      0.019    -10.745      0.000      -0.236      -0.163\n",
      "distance_from_center     0.0084      0.005      1.724      0.085      -0.001       0.018\n",
      "contrast_difference      0.0007      0.000      4.663      0.000       0.000       0.001\n",
      "energy_difference       -6.5735      3.189     -2.061      0.039     -12.827      -0.320\n",
      "==============================================================================\n",
      "Omnibus:                      242.843   Durbin-Watson:                   1.165\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              325.856\n",
      "Skew:                           0.915   Prob(JB):                     1.74e-71\n",
      "Kurtosis:                       3.446   Cond. No.                     3.78e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.78e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "y = data['n-k']\n",
    "X = data[['gsd', 'bbox_percent_area', 'num_neighbors', 'distance_from_center', 'contrast_difference', 'energy_difference']]\n",
    "\n",
    "# Add a constant term to the independent variables (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the regression summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix = X.corr()\n",
    "correlated_pairs = [(var1, var2) for var1 in X.columns for var2 in X.columns if var1 != var2 and abs(correlation_matrix.loc[var1, var2]) > 0.7]\n",
    "correlated_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    n-k   R-squared:                       0.225\n",
      "Model:                            OLS   Adj. R-squared:                  0.220\n",
      "Method:                 Least Squares   F-statistic:                     45.31\n",
      "Date:                Thu, 02 Nov 2023   Prob (F-statistic):          3.48e-110\n",
      "Time:                        12:41:00   Log-Likelihood:                -3588.7\n",
      "No. Observations:                2205   AIC:                             7207.\n",
      "Df Residuals:                    2190   BIC:                             7293.\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "const                       4.1908      0.901      4.651      0.000       2.424       5.958\n",
      "gsd                        -0.8546      0.251     -3.399      0.001      -1.348      -0.362\n",
      "bbox_percent_area         -24.7017      3.176     -7.778      0.000     -30.929     -18.474\n",
      "num_neighbors              -0.1736      0.018     -9.855      0.000      -0.208      -0.139\n",
      "distance_from_center        0.0072      0.005      1.564      0.118      -0.002       0.016\n",
      "contrast_difference         0.0007      0.000      4.753      0.000       0.000       0.001\n",
      "energy_difference          -0.4778      3.102     -0.154      0.878      -6.561       5.606\n",
      "class_American Wigeon      -0.2299      0.913     -0.252      0.801      -2.021       1.561\n",
      "class_Canadian Goose       -2.2312      0.885     -2.520      0.012      -3.967      -0.495\n",
      "class_Gadwall               1.6604      1.035      1.604      0.109      -0.369       3.690\n",
      "class_Mallard              -1.4782      0.875     -1.689      0.091      -3.194       0.238\n",
      "class_Northern Pintail     -1.3902      0.878     -1.583      0.114      -3.113       0.332\n",
      "class_Northern Shoveler     0.4726      1.236      0.382      0.702      -1.952       2.897\n",
      "class_Other                 0.7692      0.887      0.867      0.386      -0.970       2.508\n",
      "class_Sandhill Crane       -1.4475      0.912     -1.587      0.113      -3.236       0.341\n",
      "==============================================================================\n",
      "Omnibus:                      264.688   Durbin-Watson:                   1.244\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              371.641\n",
      "Skew:                           0.920   Prob(JB):                     1.99e-81\n",
      "Kurtosis:                       3.814   Cond. No.                     4.11e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.11e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "y = data['n-k']\n",
    "X = data[['gsd', 'bbox_percent_area', 'num_neighbors', 'distance_from_center', 'contrast_difference', 'energy_difference',\n",
    "          'class_American Wigeon', 'class_Canadian Goose', 'class_Gadwall', 'class_Mallard', 'class_Northern Pintail', 'class_Northern Shoveler', 'class_Other', 'class_Sandhill Crane']]\n",
    "\n",
    "# Add a constant term to the independent variables (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the regression summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Get the predicted values from the model\n",
    "predicted_values = model.predict(X)\n",
    "\n",
    "# Calculate the residuals\n",
    "residuals = y - predicted_values\n",
    "\n",
    "# Perform the Shapiro-Wilk test\n",
    "shapiro_test_statistic, shapiro_p_value = stats.shapiro(residuals)\n",
    "\n",
    "# Check the p-value\n",
    "if shapiro_p_value < 0.05:\n",
    "    print(\"The residuals are not normally distributed (p < 0.05). Consider nonparametric methods.\")\n",
    "else:\n",
    "    print(\"The residuals appear to be normally distributed (p >= 0.05). OLS may be appropriate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Pandas data cast to numpy dtype of object. Check input data with np.asarray(data).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\drones4ducks-optimizing\\utils\\texture\\annotationfactors_expert.ipynb Cell 30\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/drones4ducks-optimizing/utils/texture/annotationfactors_expert.ipynb#X44sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m X \u001b[39m=\u001b[39m sm\u001b[39m.\u001b[39madd_constant(X)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/drones4ducks-optimizing/utils/texture/annotationfactors_expert.ipynb#X44sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Fit a logistic regression model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/drones4ducks-optimizing/utils/texture/annotationfactors_expert.ipynb#X44sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m model \u001b[39m=\u001b[39m sm\u001b[39m.\u001b[39;49mLogit(y, X)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/drones4ducks-optimizing/utils/texture/annotationfactors_expert.ipynb#X44sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/drones4ducks-optimizing/utils/texture/annotationfactors_expert.ipynb#X44sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Print the summary\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\yolo\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:475\u001b[0m, in \u001b[0;36mBinaryModel.__init__\u001b[1;34m(self, endog, exog, offset, check_rank, **kwargs)\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, endog, exog, offset\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_rank\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    473\u001b[0m     \u001b[39m# unconditional check, requires no extra kwargs added by subclasses\u001b[39;00m\n\u001b[0;32m    474\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_kwargs(kwargs)\n\u001b[1;32m--> 475\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(endog, exog, offset\u001b[39m=\u001b[39;49moffset, check_rank\u001b[39m=\u001b[39;49mcheck_rank,\n\u001b[0;32m    476\u001b[0m                      \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    477\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m, MultinomialModel):\n\u001b[0;32m    478\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mall((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendog \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m) \u001b[39m&\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendog \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)):\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\yolo\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:185\u001b[0m, in \u001b[0;36mDiscreteModel.__init__\u001b[1;34m(self, endog, exog, check_rank, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, endog, exog, check_rank\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    184\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_rank \u001b[39m=\u001b[39m check_rank\n\u001b[1;32m--> 185\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(endog, exog, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    186\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraise_on_perfect_prediction \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# keep for backwards compat\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_extra \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\yolo\\Lib\\site-packages\\statsmodels\\base\\model.py:270\u001b[0m, in \u001b[0;36mLikelihoodModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, endog, exog\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 270\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(endog, exog, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    271\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialize()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\yolo\\Lib\\site-packages\\statsmodels\\base\\model.py:95\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m missing \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mmissing\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     94\u001b[0m hasconst \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mhasconst\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m---> 95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_data(endog, exog, missing, hasconst,\n\u001b[0;32m     96\u001b[0m                               \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_constant \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mk_constant\n\u001b[0;32m     98\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexog \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mexog\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\yolo\\Lib\\site-packages\\statsmodels\\base\\model.py:135\u001b[0m, in \u001b[0;36mModel._handle_data\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_handle_data\u001b[39m(\u001b[39mself\u001b[39m, endog, exog, missing, hasconst, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 135\u001b[0m     data \u001b[39m=\u001b[39m handle_data(endog, exog, missing, hasconst, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    136\u001b[0m     \u001b[39m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m kwargs:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\yolo\\Lib\\site-packages\\statsmodels\\base\\data.py:675\u001b[0m, in \u001b[0;36mhandle_data\u001b[1;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    672\u001b[0m     exog \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(exog)\n\u001b[0;32m    674\u001b[0m klass \u001b[39m=\u001b[39m handle_data_class_factory(endog, exog)\n\u001b[1;32m--> 675\u001b[0m \u001b[39mreturn\u001b[39;00m klass(endog, exog\u001b[39m=\u001b[39;49mexog, missing\u001b[39m=\u001b[39;49mmissing, hasconst\u001b[39m=\u001b[39;49mhasconst,\n\u001b[0;32m    676\u001b[0m              \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\yolo\\Lib\\site-packages\\statsmodels\\base\\data.py:84\u001b[0m, in \u001b[0;36mModelData.__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morig_endog \u001b[39m=\u001b[39m endog\n\u001b[0;32m     83\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morig_exog \u001b[39m=\u001b[39m exog\n\u001b[1;32m---> 84\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendog, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexog \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_endog_exog(endog, exog)\n\u001b[0;32m     86\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconst_idx \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_constant \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\yolo\\Lib\\site-packages\\statsmodels\\base\\data.py:509\u001b[0m, in \u001b[0;36mPandasData._convert_endog_exog\u001b[1;34m(self, endog, exog)\u001b[0m\n\u001b[0;32m    507\u001b[0m exog \u001b[39m=\u001b[39m exog \u001b[39mif\u001b[39;00m exog \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m np\u001b[39m.\u001b[39masarray(exog)\n\u001b[0;32m    508\u001b[0m \u001b[39mif\u001b[39;00m endog\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m \u001b[39mor\u001b[39;00m exog \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m exog\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[1;32m--> 509\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPandas data cast to numpy dtype of object. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    510\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mCheck input data with np.asarray(data).\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    511\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m(PandasData, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m_convert_endog_exog(endog, exog)\n",
      "\u001b[1;31mValueError\u001b[0m: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data)."
     ]
    }
   ],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Define the dependent and independent variables\n",
    "y = df[['consensus_guesses', 'n-k']]\n",
    "X = df[['consensus_class_ID', 'gsd', 'bbox_percent_area', 'same_class_percent',\n",
    "          'num_neighbors', 'distance_from_center', 'energy_difference', 'contrast_difference', \n",
    "          'homogeneity_difference', 'dissimilarity_difference']]\n",
    "\n",
    "# Add a constant term to the independent variables (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit a logistic regression model\n",
    "model = sm.Logit(y, X)\n",
    "result = model.fit()\n",
    "\n",
    "# Print the summary\n",
    "print(result.summary())\n",
    "\n",
    "# Calculate Variance Inflation Factors (VIF) to check for multicollinearity\n",
    "vif = pd.DataFrame()\n",
    "vif[\"Variable\"] = X.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISUALIZATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample visualization of \"donuts\" + bounding boxes\n",
    "\n",
    "def visualize_bounding_boxes_with_donuts(image_path, csv_file):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB\n",
    "    \n",
    "    # Read the CSV file\n",
    "    csv_data = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Find the corresponding image filename\n",
    "    image_filename = os.path.basename(image_path)\n",
    "    \n",
    "    # Filter annotations based on the image filename\n",
    "    annotations = csv_data[csv_data['filename'] == image_filename]\n",
    "    \n",
    "    # Plot the image with bounding boxes and donut regions\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Iterate through annotations and draw bounding boxes and donut regions\n",
    "    for _, row in annotations.iterrows():\n",
    "        bbox = ast.literal_eval(row['bbox'])  # Parse bbox values from string to list\n",
    "        #bbox = row['bbox']\n",
    "        # Draw bounding box\n",
    "        rectangle = Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rectangle)\n",
    "        \n",
    "        # Draw donut region\n",
    "        donut_left = max(0, bbox[0] - 20)  # Adjust the buffer size as needed\n",
    "        donut_top = max(0, bbox[1] - 20)\n",
    "        donut_right = min(image.shape[1], bbox[0] + bbox[2] + 20)\n",
    "        donut_bottom = min(image.shape[0], bbox[1] + bbox[3] + 20)\n",
    "        donut_rectangle = Rectangle((donut_left, donut_top), (donut_right - donut_left),\n",
    "                                   (donut_bottom - donut_top), linewidth=1, edgecolor='g', facecolor='none')\n",
    "        ax.add_patch(donut_rectangle)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "image_path = 'E:\\\\imagefactors\\\\data\\\\usfws\\\\BDA_18A4_20181107_4.JPG'\n",
    "csv_file = path\n",
    "\n",
    "visualize_bounding_boxes_with_donuts(image_path, csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pairplot with regression lines\n",
    "sns.pairplot(df, x_vars=['gsd', 'bbox_percent_area', 'same_class_percent', 'num_neighbors', 'distance_from_center', 'density'], y_vars=['pielou_index'], kind='reg', height=4)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dronesforducks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
