{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Power Analysis Data Prep Sequence\n",
    "Rowan Converse, last update 10/17/2023\n",
    "\n",
    "Requirements: \n",
    "Drone image directory\n",
    "A GIS software or Agisoft Metashape\n",
    "DJI Drones only: EXIF CSV output from EXIFTOOL\n",
    "\n",
    "Manual steps will be noted in markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1: Clip circles (detection radius) from all images; preserve original image metadata\n",
    "\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def clip_circle(input_image_path, output_dir):\n",
    "    # Open the input image\n",
    "    image = Image.open(input_image_path)\n",
    "\n",
    "    # Get image dimensions\n",
    "    width, height = image.size\n",
    "\n",
    "    # Calculate the center of the image\n",
    "    center_x = width // 2\n",
    "    center_y = height // 2\n",
    "\n",
    "    # Calculate the radius as the shortest distance to the image edge\n",
    "    radius = min(center_x, center_y)\n",
    "\n",
    "    # Create a mask to represent the circular clip\n",
    "    mask = Image.new('L', (width, height), 0)\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "    draw.ellipse((center_x - radius, center_y - radius, center_x + radius, center_y + radius), fill=255)\n",
    "\n",
    "    # Apply the circular mask to the image\n",
    "    result = Image.new('RGB', (width, height))\n",
    "    result.paste(image, mask=mask)\n",
    "\n",
    "    # Preserve EXIF data\n",
    "    result.info = image.info\n",
    "\n",
    "    # Construct the output image name\n",
    "    output_image_name = os.path.splitext(os.path.basename(input_image_path))[0] + \".jpg\"\n",
    "    output_image_path = os.path.join(output_dir, output_image_name)\n",
    "\n",
    "    # Save the result with preserved EXIF data\n",
    "    result.save(output_image_path, exif=result.info['exif'])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_dir = \"E:\\\\poweranalysis\\\\data\\\\18a03\\\\\"\n",
    "    output_dir = \"E:\\\\poweranalysis\\\\data\\\\18a03_circle\\\\\"\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # List all files in the input directory\n",
    "    image_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif'))]\n",
    "\n",
    "    for image_file in image_files:\n",
    "        input_image_path = os.path.join(input_dir, image_file)\n",
    "        clip_circle(input_image_path, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2a- Derive image metadata (AGL + GSD): DJI drones \n",
    "\n",
    "#Using a csv output from ExifTool that contains Relative Altitude (DJI drones only, so far)\n",
    "import csv\n",
    "# Define sensor parameters (in millimeters)-- this is Mavic 2 Pro\n",
    "image_width = 5472  # Example image width in pixels\n",
    "image_height = 3648  # Example image height in pixels\n",
    "sensor_width = 0.0128  # Make sure this is converted to meters!\n",
    "sensor_height = 0.0096  # Make sure this is converted to meters!\n",
    "focal_length = 0.01035  # Make sure this is converted to meters!\n",
    "\n",
    "altitude_data = []  # List to store extracted altitude values\n",
    "\n",
    "#Requires CSV output from ExifTool\n",
    "with open('exif.csv', mode='r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    \n",
    "    for row in csv_reader:\n",
    "        # Extract the \"RelativeAltitude\" and \"FileName\" values\n",
    "        relative_altitude = row.get(\"RelativeAltitude\", None)\n",
    "        image_filename = row.get(\"FileName\", None)\n",
    "\n",
    "        if relative_altitude is not None and relative_altitude.strip() != '' and image_filename is not None:\n",
    "            try:\n",
    "                relative_altitude = float(relative_altitude)\n",
    "                if relative_altitude > 120:\n",
    "                    # Flag values exceeding 120 as likely absolute altitudes\n",
    "                    print(f\"Skipped: {image_filename} - RelativeAltitude exceeds legal flight ceiling: {relative_altitude}\")\n",
    "                else:\n",
    "                    altitude_data.append((image_filename, relative_altitude, None))\n",
    "            except ValueError:\n",
    "                print(f\"Skipping: {image_filename} - Invalid RelativeAltitude value: {relative_altitude}\")\n",
    "\n",
    "# Calculate GSD and write data to a new CSV file\n",
    "with open('output.csv', mode='w', newline='') as csv_output:\n",
    "    csv_writer = csv.writer(csv_output)\n",
    "    csv_writer.writerow([\"filename\", \"agl\", \"gsd\"])\n",
    "    \n",
    "    for image_filename, relative_altitude in altitude_data:\n",
    "        # Calculate GSD (in cm)\n",
    "        gsd_m = (sensor_width * relative_altitude) / (focal_length * image_width)\n",
    "        gsd_cm = gsd_m * 100  # Convert to cm\n",
    "\n",
    "        # Write data to the new CSV file\n",
    "        csv_writer.writerow([image_filename, relative_altitude, gsd_cm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2b: Derive AGL/GSD, all other drones\n",
    "\n",
    "master_directory = \"\"\n",
    "csv_file = \"output.csv\"\n",
    "\n",
    "csv_header = [\"filename\", \"altitude\", \"gsd\"]\n",
    "\n",
    "with open(csv_file, mode='w', newline='') as csv_output:\n",
    "    csv_writer = csv.writer(csv_output)\n",
    "    csv_writer.writerow(csv_header)\n",
    "\n",
    "ground_elevation = 1844 #Adjust to the appropriate value for your study area\n",
    "\n",
    "# Define sensor parameters (in millimeters)-- this is Mavic 2 Pro\n",
    "image_width = 5472  # Example image width in pixels\n",
    "image_height = 3648  # Example image height in pixels\n",
    "sensor_width = 0.0128  # Make sure this is converted to meters!\n",
    "sensor_height = 0.0096  # Make sure this is converted to meters!\n",
    "focal_length = 0.01035  # Make sure this is converted to meters!\n",
    "\n",
    "altitude_data = []  # List to store extracted altitude values\n",
    "\n",
    "for transect_id in os.listdir(master_directory):\n",
    "    transect_dir = os.path.join(master_directory, transect_id)\n",
    "    \n",
    "    if os.path.isdir(transect_dir):\n",
    "        for image_filename in os.listdir(transect_dir):\n",
    "            if image_filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                image_path = os.path.join(transect_dir, image_filename)\n",
    "                    \n",
    "                # Open the image and extract EXIF data\n",
    "                with open(image_path, 'rb') as src:\n",
    "                    img = Image(src)\n",
    "    \n",
    "                    altitude = img.get(\"gps_altitude\")\n",
    "                # Calculate altitude above ground level\n",
    "                agl_altitude = altitude - ground_elevation if altitude is not None else None\n",
    "                altitude_data.append((image_filename, agl_altitude))\n",
    "\n",
    "# Calculate GSD and write data to CSV\n",
    "with open(csv_file, mode='a', newline='') as csv_output:\n",
    "    csv_writer = csv.writer(csv_output)\n",
    "    \n",
    "    for image_filename, transect_id, agl_altitude in altitude_data:\n",
    "        if agl_altitude is not None:\n",
    "            # Calculate ground sampling distance (in meters/px)\n",
    "            gsd_m = (sensor_width * agl_altitude) / (focal_length * image_width)\n",
    "            gsd = gsd_m*100 #convert to cm-- optional\n",
    "        else:\n",
    "            gsd = None\n",
    "\n",
    "        # Write data to CSV\n",
    "        csv_writer.writerow([image_filename, agl_altitude, gsd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual step: derive transect IDs\n",
    "In Agisoft, add the images and align them\n",
    "Alternately, in a GIS, add the EXIF csv and add the image centers as XY data\n",
    "Add a new column for transect ID to the output of step 2\n",
    "Manually note the image names of the start and end of each flightline; use this to designate a transect ID for all images\n",
    "\n",
    "Use an image select script to separate out the circle clips into folders based off transects\n",
    "With the known side overlap (flightplan, or manually derived from Agisoft footprints_to_shapes.py + GIS overlap of sample image footprints), preserve the appropriate number of independent side-lap transects before moving on to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3- Derive independent forward overlap images and copy to folders based on transect ID\n",
    "\n",
    "#Creates a CSV file of independent image names (ie, no forward overlap)\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a pandas dataframe\n",
    "input_file = ''  # CSV file that includes image names and transect numbers, ideally filtered by desired transects\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Create a new dataframe with every other row from the original dataframe; can replace \"2\" with any n value of images to preserve\n",
    "subset_df = df.iloc[::2].copy()\n",
    "\n",
    "# Optional: Reset the index of the new dataframe\n",
    "subset_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save the subset dataframe to a new CSV file\n",
    "output_file = 'independent_imgs.csv'  # Replace with the desired filename\n",
    "subset_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4- Batch detections using SAHI \n",
    "\n",
    "import os\n",
    "from sahi.utils.yolov5 import download_yolov5s6_model\n",
    "from sahi import AutoDetectionModel\n",
    "from sahi.utils.cv import read_image\n",
    "from sahi.utils.file import download_from_url\n",
    "from sahi.predict import get_prediction, get_sliced_prediction, predict\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "\n",
    "def process_images_in_directory(image_directory, save_directory):\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "    yolov5_model_path = 'E:\\\\training\\\\Base\\\\YOLOweights\\\\zooniverse_3class_150epc\\\\weights\\\\best.pt' #specify full model path\n",
    "    download_yolov5s6_model(destination_path=yolov5_model_path)\n",
    "\n",
    "    detection_model = AutoDetectionModel.from_pretrained(\n",
    "        model_type='yolov5', #can accommodate other architectures\n",
    "        model_path=yolov5_model_path,\n",
    "        confidence_threshold=0.8, #specify confidence threshold as desired\n",
    "        device=\"cuda:0\" #to use GPU\n",
    "    )\n",
    "\n",
    "    all_anns = []\n",
    "\n",
    "    for img_filename in os.listdir(image_directory):\n",
    "        if img_filename.lower().endswith(('.tif','.jpg', '.jpeg', '.png', '.bmp')):\n",
    "            img_path = os.path.join(image_directory, img_filename)\n",
    "\n",
    "            result = get_sliced_prediction(\n",
    "                img_path,\n",
    "                detection_model,\n",
    "                slice_height=640, #Can adjust tile size \n",
    "                slice_width=640,\n",
    "                overlap_height_ratio=0.1, #Can adjust tile overlap\n",
    "                overlap_width_ratio=0.1\n",
    "            )\n",
    "\n",
    "            coco = result.to_coco_annotations()\n",
    "            for annotation in coco:\n",
    "                annotation['image_id'] = img_filename\n",
    "\n",
    "            all_anns.extend(coco)\n",
    "\n",
    "        df = pd.DataFrame(all_anns)\n",
    "        savepath = os.path.join(save_directory, \"12c01_unproj_coco_detections.csv\") #change name if desired\n",
    "        df.to_csv(savepath, index=False)\n",
    "\n",
    "image_directory = \"E:\\\\poweranalysis\\\\data\\\\circles\\\\12c01_subset\"  # Replace with the path to the directory containing images\n",
    "save_directory = \"E:\\\\poweranalysis\\\\data\"  # Replace with the desired output directory for the COCO annotations\n",
    "process_images_in_directory(image_directory, save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5- Distance from bird detections to the drone\n",
    "\n",
    "#Fixed to use altitude/GSD from each individual image to calculate ground distance from drone of individual annotations\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Read the two CSV files\n",
    "df_annotations = pd.read_csv(\"C:\\\\...\\site_anns.csv\") #COCO format SAHI outputs\n",
    "df_annotations['bbox'] = df_annotations['bbox'].apply(ast.literal_eval)\n",
    "df_resolution = pd.read_csv(\"C:\\\\...\\\\site_metadata.csv\") # output from step 2\n",
    "\n",
    "# Merge the two dataframes based on the 'filename' column\n",
    "merged_df = df_annotations.merge(df_resolution, on='filename', how='inner')\n",
    "\n",
    "# Image center in pixels\n",
    "center_x_px, center_y_px = 2736, 1824  # Specify according to your image set\n",
    "\n",
    "# Calculate the center point in meters\n",
    "merged_df['center_x_m'] = center_x_px * merged_df['gsd']\n",
    "merged_df['center_y_m'] = center_y_px * merged_df['gsd']\n",
    "\n",
    "# Function to calculate distance from center\n",
    "def calculate_distance_from_center(row):\n",
    "    # Get the coordinates of the bounding box (x, y, width, height)\n",
    "    x, y, width, height = row['bbox']\n",
    "\n",
    "    # Calculate the center point of the bounding box in pixels\n",
    "    bbox_center_x_px = x + (width / 2)\n",
    "    bbox_center_y_px = y + (height / 2)\n",
    "\n",
    "    # Calculate the center point of the bounding box in meters\n",
    "    bbox_center_x_m = bbox_center_x_px * row['gsd']\n",
    "    bbox_center_y_m = bbox_center_y_px * row['gsd']\n",
    "\n",
    "    # Calculate the distance from the center of the image in meters\n",
    "    distance_m = ((row['center_x_m'] - bbox_center_x_m)**2 + (row['center_y_m'] - bbox_center_y_m)**2)**0.5\n",
    "\n",
    "    return distance_m\n",
    "\n",
    "# Apply the function to the merged dataframe\n",
    "merged_df['distance_from_center'] = merged_df.apply(calculate_distance_from_center, axis=1)\n",
    "\n",
    "# Export the modified dataframe to CSV\n",
    "savepath = \"C:\\\\...\\\\\"  # Desired output directory\n",
    "merged_df.to_csv(savepath + \"distance_anns.csv\", index=False)  # Desired filename\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAST MANUAL STEP: Land/no land\n",
    "2 ways to do this\n",
    "\n",
    "1- If there are a lot of images: Build an orthomosaic in Agisoft with all images. Then project the ortho in a GIS, digitize a boundary of the shoreline. Project the image center XY data. Derive an average image height using the average GSD. Using this info, create an interior buffer from the polygon using that measurement. Select all image centers within the buffer. Export this information-- this is your \"no land\" set\n",
    "\n",
    "2- If there aren't a lot of images: just examine the circle clip thumbnails in the Windows Explorer and note any with land in the CSV manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BELOW: Attempts on the process to use projected images for this process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Independent tile paths have been copied to: E:\\poweranalysis\\18a03_tiles\n"
     ]
    }
   ],
   "source": [
    "#Derive independent (ie, non-overlapping) projected image footprints (whole image-- not the detection radius)\n",
    "#This script works\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from osgeo import gdal, osr\n",
    "\n",
    "def calculate_overlap(tile1_path, tile2_path):\n",
    "    # Open the raster datasets\n",
    "    tile1_dataset = gdal.Open(tile1_path)\n",
    "    tile2_dataset = gdal.Open(tile2_path)\n",
    "\n",
    "    # Get the geotransform information (bounding box) of the tiles\n",
    "    geotransform1 = tile1_dataset.GetGeoTransform()\n",
    "    geotransform2 = tile2_dataset.GetGeoTransform()\n",
    "\n",
    "    # Calculate overlapping area\n",
    "    x_min1, y_max1 = geotransform1[0], geotransform1[3]\n",
    "    x_max1, y_min1 = x_min1 + geotransform1[1] * tile1_dataset.RasterXSize, y_max1 + geotransform1[5] * tile1_dataset.RasterYSize\n",
    "\n",
    "    x_min2, y_max2 = geotransform2[0], geotransform2[3]\n",
    "    x_max2, y_min2 = x_min2 + geotransform2[1] * tile2_dataset.RasterXSize, y_max2 + geotransform2[5] * tile2_dataset.RasterYSize\n",
    "\n",
    "    x_overlap = max(0, min(x_max1, x_max2) - max(x_min1, x_min2))\n",
    "    y_overlap = max(0, min(y_max1, y_max2) - max(y_min1, y_min2))\n",
    "\n",
    "    return x_overlap * y_overlap\n",
    "\n",
    "def is_overlapping(tile_path, independent_tiles):\n",
    "    for independent_tile_path in independent_tiles:\n",
    "        if calculate_overlap(tile_path, independent_tile_path) > 0:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def find_non_overlapping_tiles(tile_directory):\n",
    "    all_tile_paths = [os.path.join(tile_directory, file) for file in os.listdir(tile_directory) if file.endswith(\".tif\")]\n",
    "    independent_tile_paths = [all_tile_paths[0]]\n",
    "\n",
    "    for tile_path in all_tile_paths[1:]:\n",
    "        if not is_overlapping(tile_path, independent_tile_paths):\n",
    "            independent_tile_paths.append(tile_path)\n",
    "\n",
    "    return independent_tile_paths\n",
    "\n",
    "tile_directory = \"E:\\\\poweranalysis\\\\data\\\\18a03\"\n",
    "independent_tile_paths = find_non_overlapping_tiles(tile_directory)\n",
    "\n",
    "# Create a new directory for independent tiles\n",
    "output_directory = \"E:\\\\poweranalysis\\\\18a03_tiles\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Copy independent tiles to the output directory\n",
    "for tile_path in independent_tile_paths:\n",
    "    tile_filename = os.path.basename(tile_path)\n",
    "    output_path = os.path.join(output_directory, tile_filename)\n",
    "    shutil.copy(tile_path, output_path)\n",
    "\n",
    "print(\"Independent tile paths have been copied to:\", output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Translate image coordinates of SAHI detections to geographic ones \n",
    "#This still produces incorrect values :/\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json  # Import the json module\n",
    "from osgeo import gdal, osr\n",
    "\n",
    "# Directory containing the GeoTIFF rasters\n",
    "raster_dir = \"E:\\\\poweranalysis\\\\data\\\\12c01_tiles\\\\\"\n",
    "\n",
    "# Define a function to convert image coordinates to geographic coordinates\n",
    "def image_to_geographic_coordinates(image_x, image_y, geo_transform):\n",
    "    x = geo_transform[0] + image_x * geo_transform[1]\n",
    "    y = geo_transform[3] + image_y * geo_transform[5]\n",
    "    return x, y\n",
    "\n",
    "# Read the CSV file with bounding boxes\n",
    "csv_file = \"E:\\\\poweranalysis\\\\data\\\\12c01_coco_detections.csv\"\n",
    "output_csv_file = \"E:\\\\poweranalysis\\\\data\\\\12c01_coco_detections_dist.csv\"\n",
    "\n",
    "with open(csv_file, \"r\") as file, open(output_csv_file, \"w\", newline='') as output_file:\n",
    "    reader = csv.DictReader(file)\n",
    "    fieldnames = reader.fieldnames + [\"geo_x\", \"geo_y\", \"dist_m\"]\n",
    "    writer = csv.DictWriter(output_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for row in reader:\n",
    "        image_id = row[\"image_id\"]\n",
    "        raster_filename = os.path.join(raster_dir, f\"{image_id}\")  # Construct raster filename from directory and image ID\n",
    "\n",
    "        if not os.path.exists(raster_filename):\n",
    "            print(f\"Warning: Raster file '{raster_filename}' does not exist for Image ID '{image_id}'. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Load the GeoTIFF raster\n",
    "        ds = gdal.Open(raster_filename)\n",
    "\n",
    "        # Extract bounding box coordinates from the \"bbox\" column\n",
    "        bbox_str = row[\"bbox\"]\n",
    "        bbox = json.loads(bbox_str)\n",
    "        xmin, ymin, width, height = map(float, bbox)\n",
    "\n",
    "        # Calculate the center of the bounding box in image coordinates\n",
    "        center_x = xmin + (width / 2)\n",
    "        center_y = ymin + (height / 2)\n",
    "\n",
    "        # Calculate the geographic coordinates of the pixel corresponding to the bounding box center\n",
    "        geo_transform = ds.GetGeoTransform()\n",
    "        geo_x, geo_y = image_to_geographic_coordinates(center_x, center_y, geo_transform)\n",
    "\n",
    "        # Calculate the distance between the geographic center and raster center\n",
    "        raster_center_x = geo_transform[0] + (ds.RasterXSize / 2) * geo_transform[1]\n",
    "        raster_center_y = geo_transform[3] + (ds.RasterYSize / 2) * geo_transform[5]\n",
    "        distance = np.sqrt((geo_x - raster_center_x) ** 2 + (geo_y - raster_center_y) ** 2)\n",
    "\n",
    "        # Add the new columns to the row\n",
    "        row[\"geo_x\"] = geo_x\n",
    "        row[\"geo_y\"] = geo_y\n",
    "        row[\"dist_m\"] = distance\n",
    "\n",
    "        # Write the updated row to the new CSV\n",
    "        writer.writerow(row)\n",
    "\n",
    "        # Close the GeoTIFF dataset\n",
    "        ds = None\n",
    "\n",
    "# Optionally, you can rename the new CSV file to the original filename if desired\n",
    "if os.path.exists(csv_file):\n",
    "    os.remove(csv_file)  # Remove the original file if it exists\n",
    "os.rename(output_csv_file, csv_file)  # Rename the new CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete. Output saved to E:\\poweranalysis\\data\\output.csv\n"
     ]
    }
   ],
   "source": [
    "#Translate outputs of SAHI detections to conform to the former YOLOv3 format used in Sa'doun's projection script\n",
    "#This works\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Input CSV file path\n",
    "input_csv_file = \"E:\\\\poweranalysis\\\\data\\\\12c01_unproj_coco_detections.csv\"\n",
    "\n",
    "# Output CSV file path\n",
    "output_csv_file = \"E:\\\\poweranalysis\\\\data\\\\output.csv\"\n",
    "\n",
    "# Directory where the images are located\n",
    "image_directory = \"E:\\\\poweranalysis\\\\data\\\\circles\\\\12c01_subset\\\\\"\n",
    "\n",
    "# Read the input CSV file into a DataFrame\n",
    "df = pd.read_csv(input_csv_file)\n",
    "\n",
    "# Define a function to parse the \"bbox\" column\n",
    "def parse_bbox(bbox_str):\n",
    "    bbox = eval(bbox_str)\n",
    "    xmin, ymin, width, height = bbox\n",
    "    xmax = xmin + width\n",
    "    ymax = ymin + height\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "# Apply the parsing function to the \"bbox\" column\n",
    "df[\"xmin\"], df[\"ymin\"], df[\"xmax\"], df[\"ymax\"] = zip(*df[\"bbox\"].apply(parse_bbox))\n",
    "\n",
    "# Derive the \"image_path\" by adding \"image_id\" to the image directory\n",
    "df[\"image_path\"] = image_directory + df[\"image_id\"]\n",
    "\n",
    "# Use \"category_id\" for \"label\" and \"score\" for \"confidence\"\n",
    "df.rename(columns={\"category_id\": \"label\", \"score\": \"confidence\"}, inplace=True)\n",
    "\n",
    "# Extract \"x_size\" and \"y_size\" by opening each image\n",
    "def get_image_size(image_path):\n",
    "    with Image.open(image_path) as img:\n",
    "        return img.size\n",
    "\n",
    "df[\"x_size\"], df[\"y_size\"] = zip(*df[\"image_path\"].apply(get_image_size))\n",
    "\n",
    "# Create the output DataFrame with the desired columns\n",
    "output_df = df[[\"image_id\", \"image_path\", \"xmin\", \"ymin\", \"xmax\", \"ymax\", \"label\", \"confidence\", \"x_size\", \"y_size\"]]\n",
    "output_df.columns = [\"image\", \"image_path\", \"xmin\", \"ymin\", \"xmax\", \"ymax\", \"label\", \"confidence\", \"x_size\", \"y_size\"]\n",
    "\n",
    "# Save the output DataFrame to a new CSV file\n",
    "output_df.to_csv(output_csv_file, index=False)\n",
    "\n",
    "print(f\"Conversion complete. Output saved to {output_csv_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
